{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14b2b6f-8f38-4613-bed0-d95119630a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9228bb6-4be7-49cd-b344-83dee500f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_27</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.373246</td>\n",
       "      <td>0.238887</td>\n",
       "      <td>-0.243376</td>\n",
       "      <td>0.567405</td>\n",
       "      <td>-0.647715</td>\n",
       "      <td>0.839326</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.540739</td>\n",
       "      <td>0.766952</td>\n",
       "      <td>-2.730628</td>\n",
       "      <td>-0.208177</td>\n",
       "      <td>1.363402</td>\n",
       "      <td>ABABDADBAB</td>\n",
       "      <td>67.609153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.697021</td>\n",
       "      <td>-1.710322</td>\n",
       "      <td>-2.230332</td>\n",
       "      <td>-0.545661</td>\n",
       "      <td>1.113173</td>\n",
       "      <td>-1.552175</td>\n",
       "      <td>0.447825</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.278315</td>\n",
       "      <td>-0.633658</td>\n",
       "      <td>-1.217077</td>\n",
       "      <td>-3.782194</td>\n",
       "      <td>-0.058316</td>\n",
       "      <td>ACACCADCEB</td>\n",
       "      <td>377.096415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.681726</td>\n",
       "      <td>0.616746</td>\n",
       "      <td>-1.027689</td>\n",
       "      <td>0.810492</td>\n",
       "      <td>-0.609086</td>\n",
       "      <td>0.113965</td>\n",
       "      <td>-0.708660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.385775</td>\n",
       "      <td>-0.520558</td>\n",
       "      <td>-0.009121</td>\n",
       "      <td>2.788536</td>\n",
       "      <td>-3.703488</td>\n",
       "      <td>AAAEABCKAD</td>\n",
       "      <td>-195.599702</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.118172</td>\n",
       "      <td>-0.587835</td>\n",
       "      <td>-0.804638</td>\n",
       "      <td>2.086822</td>\n",
       "      <td>0.371005</td>\n",
       "      <td>-0.128831</td>\n",
       "      <td>-0.282575</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572594</td>\n",
       "      <td>-1.653213</td>\n",
       "      <td>1.686035</td>\n",
       "      <td>-2.533098</td>\n",
       "      <td>-0.608601</td>\n",
       "      <td>BDBBAACBCB</td>\n",
       "      <td>210.826205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.148481</td>\n",
       "      <td>-0.176567</td>\n",
       "      <td>-0.664871</td>\n",
       "      <td>-1.101343</td>\n",
       "      <td>0.467875</td>\n",
       "      <td>0.500117</td>\n",
       "      <td>0.407515</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.912929</td>\n",
       "      <td>-1.430366</td>\n",
       "      <td>2.127649</td>\n",
       "      <td>-3.306784</td>\n",
       "      <td>4.371371</td>\n",
       "      <td>BDBCBBCHFE</td>\n",
       "      <td>-217.211798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>1.380145</td>\n",
       "      <td>-0.038884</td>\n",
       "      <td>0.597111</td>\n",
       "      <td>0.854560</td>\n",
       "      <td>0.684301</td>\n",
       "      <td>-1.058618</td>\n",
       "      <td>1.310699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.594744</td>\n",
       "      <td>0.522019</td>\n",
       "      <td>0.833047</td>\n",
       "      <td>2.714125</td>\n",
       "      <td>1.290094</td>\n",
       "      <td>BABBCBBBED</td>\n",
       "      <td>455.033851</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>-1.369789</td>\n",
       "      <td>0.044841</td>\n",
       "      <td>0.015458</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>-0.380529</td>\n",
       "      <td>-0.830815</td>\n",
       "      <td>-1.798458</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.413899</td>\n",
       "      <td>-0.674942</td>\n",
       "      <td>-0.412111</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>-3.144047</td>\n",
       "      <td>BBBGBBDQBE</td>\n",
       "      <td>134.703577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>1.386201</td>\n",
       "      <td>-0.961150</td>\n",
       "      <td>0.725994</td>\n",
       "      <td>-0.132844</td>\n",
       "      <td>0.873911</td>\n",
       "      <td>-0.245339</td>\n",
       "      <td>-1.045786</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151930</td>\n",
       "      <td>-4.560773</td>\n",
       "      <td>-1.249154</td>\n",
       "      <td>1.793535</td>\n",
       "      <td>2.253696</td>\n",
       "      <td>AEBEDBBHBA</td>\n",
       "      <td>-99.536313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>-1.590572</td>\n",
       "      <td>-0.509938</td>\n",
       "      <td>-1.715397</td>\n",
       "      <td>-0.249988</td>\n",
       "      <td>1.359933</td>\n",
       "      <td>1.650808</td>\n",
       "      <td>-0.058592</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.423670</td>\n",
       "      <td>2.110008</td>\n",
       "      <td>0.561271</td>\n",
       "      <td>-2.149610</td>\n",
       "      <td>1.019982</td>\n",
       "      <td>ADBAAADDAE</td>\n",
       "      <td>47.823039</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>-0.636210</td>\n",
       "      <td>-0.425986</td>\n",
       "      <td>-1.826699</td>\n",
       "      <td>-0.598797</td>\n",
       "      <td>1.589577</td>\n",
       "      <td>-0.482298</td>\n",
       "      <td>-0.214093</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340696</td>\n",
       "      <td>3.762351</td>\n",
       "      <td>1.797137</td>\n",
       "      <td>-0.412837</td>\n",
       "      <td>2.090440</td>\n",
       "      <td>BCAACADSCE</td>\n",
       "      <td>-44.559296</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n",
       "id                                                                             \n",
       "0      -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n",
       "1       1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n",
       "2       1.681726  0.616746 -1.027689  0.810492 -0.609086  0.113965 -0.708660   \n",
       "3      -0.118172 -0.587835 -0.804638  2.086822  0.371005 -0.128831 -0.282575   \n",
       "4       1.148481 -0.176567 -0.664871 -1.101343  0.467875  0.500117  0.407515   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "899995  1.380145 -0.038884  0.597111  0.854560  0.684301 -1.058618  1.310699   \n",
       "899996 -1.369789  0.044841  0.015458  0.376565 -0.380529 -0.830815 -1.798458   \n",
       "899997  1.386201 -0.961150  0.725994 -0.132844  0.873911 -0.245339 -1.045786   \n",
       "899998 -1.590572 -0.509938 -1.715397 -0.249988  1.359933  1.650808 -0.058592   \n",
       "899999 -0.636210 -0.425986 -1.826699 -0.598797  1.589577 -0.482298 -0.214093   \n",
       "\n",
       "        f_07  f_08  f_09  ...      f_22      f_23      f_24      f_25  \\\n",
       "id                        ...                                           \n",
       "0          1     5     1  ... -2.540739  0.766952 -2.730628 -0.208177   \n",
       "1          1     3     4  ...  2.278315 -0.633658 -1.217077 -3.782194   \n",
       "2          1     0     2  ... -1.385775 -0.520558 -0.009121  2.788536   \n",
       "3          3     2     1  ...  0.572594 -1.653213  1.686035 -2.533098   \n",
       "4          3     3     0  ... -3.912929 -1.430366  2.127649 -3.306784   \n",
       "...      ...   ...   ...  ...       ...       ...       ...       ...   \n",
       "899995     2     1     2  ... -1.594744  0.522019  0.833047  2.714125   \n",
       "899996     4     1     2  ...  2.413899 -0.674942 -0.412111 -0.030436   \n",
       "899997     0     0     6  ... -0.151930 -4.560773 -1.249154  1.793535   \n",
       "899998     0     2     2  ...  2.423670  2.110008  0.561271 -2.149610   \n",
       "899999     7     1     4  ...  1.340696  3.762351  1.797137 -0.412837   \n",
       "\n",
       "            f_26        f_27        f_28  f_29  f_30  target  \n",
       "id                                                            \n",
       "0       1.363402  ABABDADBAB   67.609153     0     0       0  \n",
       "1      -0.058316  ACACCADCEB  377.096415     0     0       1  \n",
       "2      -3.703488  AAAEABCKAD -195.599702     0     2       1  \n",
       "3      -0.608601  BDBBAACBCB  210.826205     0     0       1  \n",
       "4       4.371371  BDBCBBCHFE -217.211798     0     1       1  \n",
       "...          ...         ...         ...   ...   ...     ...  \n",
       "899995  1.290094  BABBCBBBED  455.033851     0     2       1  \n",
       "899996 -3.144047  BBBGBBDQBE  134.703577     0     1       0  \n",
       "899997  2.253696  AEBEDBBHBA  -99.536313     0     1       0  \n",
       "899998  1.019982  ADBAAADDAE   47.823039     1     2       0  \n",
       "899999  2.090440  BCAACADSCE  -44.559296     0     2       1  \n",
       "\n",
       "[900000 rows x 32 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/tabular_playground_may_2022/train.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168984ca-dcf2-4f35-887a-03fdc994f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32579478-1474-4e1f-bce2-eb9624180e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_00</th>\n",
       "      <th>f_01</th>\n",
       "      <th>f_02</th>\n",
       "      <th>f_03</th>\n",
       "      <th>f_04</th>\n",
       "      <th>f_05</th>\n",
       "      <th>f_06</th>\n",
       "      <th>f_07</th>\n",
       "      <th>f_08</th>\n",
       "      <th>f_09</th>\n",
       "      <th>...</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>f_26</th>\n",
       "      <th>f_28</th>\n",
       "      <th>f_29</th>\n",
       "      <th>f_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "      <td>900000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>2.031460</td>\n",
       "      <td>2.057998</td>\n",
       "      <td>2.362431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156307</td>\n",
       "      <td>-0.009273</td>\n",
       "      <td>-0.369459</td>\n",
       "      <td>-0.342738</td>\n",
       "      <td>0.176549</td>\n",
       "      <td>0.357591</td>\n",
       "      <td>-0.380876</td>\n",
       "      <td>0.345661</td>\n",
       "      <td>1.002654</td>\n",
       "      <td>0.486488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.998888</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>1.000514</td>\n",
       "      <td>1.000175</td>\n",
       "      <td>1.000167</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>1.656172</td>\n",
       "      <td>1.590955</td>\n",
       "      <td>1.637706</td>\n",
       "      <td>...</td>\n",
       "      <td>2.484706</td>\n",
       "      <td>2.450797</td>\n",
       "      <td>2.453405</td>\n",
       "      <td>2.386941</td>\n",
       "      <td>2.416959</td>\n",
       "      <td>2.476020</td>\n",
       "      <td>238.773054</td>\n",
       "      <td>0.475584</td>\n",
       "      <td>0.818989</td>\n",
       "      <td>0.499818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.599856</td>\n",
       "      <td>-4.682199</td>\n",
       "      <td>-4.642676</td>\n",
       "      <td>-4.658816</td>\n",
       "      <td>-4.748501</td>\n",
       "      <td>-4.750214</td>\n",
       "      <td>-4.842919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.310146</td>\n",
       "      <td>-11.853530</td>\n",
       "      <td>-12.301097</td>\n",
       "      <td>-11.416189</td>\n",
       "      <td>-11.918306</td>\n",
       "      <td>-14.300577</td>\n",
       "      <td>-1229.753052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.675490</td>\n",
       "      <td>-0.675162</td>\n",
       "      <td>-0.674369</td>\n",
       "      <td>-0.676114</td>\n",
       "      <td>-0.675909</td>\n",
       "      <td>-0.673437</td>\n",
       "      <td>-0.674876</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.820063</td>\n",
       "      <td>-1.645585</td>\n",
       "      <td>-2.019739</td>\n",
       "      <td>-1.955956</td>\n",
       "      <td>-1.440424</td>\n",
       "      <td>-1.261598</td>\n",
       "      <td>-159.427418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.001492</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152668</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>-0.390966</td>\n",
       "      <td>-0.340746</td>\n",
       "      <td>0.160912</td>\n",
       "      <td>0.404212</td>\n",
       "      <td>-0.519808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.674337</td>\n",
       "      <td>0.675021</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.672544</td>\n",
       "      <td>0.673789</td>\n",
       "      <td>0.675028</td>\n",
       "      <td>0.674749</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507071</td>\n",
       "      <td>1.661676</td>\n",
       "      <td>1.255408</td>\n",
       "      <td>1.266673</td>\n",
       "      <td>1.795928</td>\n",
       "      <td>2.028219</td>\n",
       "      <td>158.987357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.749301</td>\n",
       "      <td>4.815699</td>\n",
       "      <td>4.961982</td>\n",
       "      <td>4.454920</td>\n",
       "      <td>4.948983</td>\n",
       "      <td>4.971881</td>\n",
       "      <td>4.822668</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.455426</td>\n",
       "      <td>11.344080</td>\n",
       "      <td>12.247100</td>\n",
       "      <td>12.389844</td>\n",
       "      <td>12.529179</td>\n",
       "      <td>12.913041</td>\n",
       "      <td>1229.562577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f_00           f_01           f_02           f_03  \\\n",
       "count  900000.000000  900000.000000  900000.000000  900000.000000   \n",
       "mean       -0.000286       0.001165       0.001174      -0.001368   \n",
       "std         0.998888       0.999193       1.000514       1.000175   \n",
       "min        -4.599856      -4.682199      -4.642676      -4.658816   \n",
       "25%        -0.675490      -0.675162      -0.674369      -0.676114   \n",
       "50%         0.001144       0.002014       0.002218      -0.002227   \n",
       "75%         0.674337       0.675021       0.677505       0.672544   \n",
       "max         4.749301       4.815699       4.961982       4.454920   \n",
       "\n",
       "                f_04           f_05           f_06           f_07  \\\n",
       "count  900000.000000  900000.000000  900000.000000  900000.000000   \n",
       "mean       -0.000571       0.000284      -0.000709       2.031460   \n",
       "std         1.000167       0.999875       0.999942       1.656172   \n",
       "min        -4.748501      -4.750214      -4.842919       0.000000   \n",
       "25%        -0.675909      -0.673437      -0.674876       1.000000   \n",
       "50%        -0.001662      -0.000438      -0.001492       2.000000   \n",
       "75%         0.673789       0.675028       0.674749       3.000000   \n",
       "max         4.948983       4.971881       4.822668      15.000000   \n",
       "\n",
       "                f_08           f_09  ...           f_21           f_22  \\\n",
       "count  900000.000000  900000.000000  ...  900000.000000  900000.000000   \n",
       "mean        2.057998       2.362431  ...      -0.156307      -0.009273   \n",
       "std         1.590955       1.637706  ...       2.484706       2.450797   \n",
       "min         0.000000       0.000000  ...     -13.310146     -11.853530   \n",
       "25%         1.000000       1.000000  ...      -1.820063      -1.645585   \n",
       "50%         2.000000       2.000000  ...      -0.152668       0.030850   \n",
       "75%         3.000000       3.000000  ...       1.507071       1.661676   \n",
       "max        16.000000      14.000000  ...      14.455426      11.344080   \n",
       "\n",
       "                f_23           f_24           f_25           f_26  \\\n",
       "count  900000.000000  900000.000000  900000.000000  900000.000000   \n",
       "mean       -0.369459      -0.342738       0.176549       0.357591   \n",
       "std         2.453405       2.386941       2.416959       2.476020   \n",
       "min       -12.301097     -11.416189     -11.918306     -14.300577   \n",
       "25%        -2.019739      -1.955956      -1.440424      -1.261598   \n",
       "50%        -0.390966      -0.340746       0.160912       0.404212   \n",
       "75%         1.255408       1.266673       1.795928       2.028219   \n",
       "max        12.247100      12.389844      12.529179      12.913041   \n",
       "\n",
       "                f_28           f_29           f_30         target  \n",
       "count  900000.000000  900000.000000  900000.000000  900000.000000  \n",
       "mean       -0.380876       0.345661       1.002654       0.486488  \n",
       "std       238.773054       0.475584       0.818989       0.499818  \n",
       "min     -1229.753052       0.000000       0.000000       0.000000  \n",
       "25%      -159.427418       0.000000       0.000000       0.000000  \n",
       "50%        -0.519808       0.000000       1.000000       0.000000  \n",
       "75%       158.987357       1.000000       2.000000       1.000000  \n",
       "max      1229.562577       1.000000       2.000000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b29e3c-e0db-44b0-9df5-dd25af8c38ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BBBBBBCJBC    12\n",
       "BCBBBBCLBC    12\n",
       "BBBBBABLCB    10\n",
       "BBBBBBDPCB    10\n",
       "ADBBBACQBC    10\n",
       "              ..\n",
       "AEADBBAOCA     1\n",
       "BBBCABDDCI     1\n",
       "BCBECBAPCA     1\n",
       "ACBBDAADBD     1\n",
       "ADBFBABHEE     1\n",
       "Name: f_27, Length: 741354, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f_27'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fae625d2-7f9c-40d2-add2-53da3c59d380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    900000\n",
       "Name: f_27, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['f_27'].str.len().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5997f14-ea3a-4820-b534-7166fa0852cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0         ABABDADBAB\n",
       "1         ACACCADCEB\n",
       "2         AAAEABCKAD\n",
       "3         BDBBAACBCB\n",
       "4         BDBCBBCHFE\n",
       "             ...    \n",
       "899995    BABBCBBBED\n",
       "899996    BBBGBBDQBE\n",
       "899997    AEBEDBBHBA\n",
       "899998    ADBAAADDAE\n",
       "899999    BCAACADSCE\n",
       "Name: f_27, Length: 900000, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop('f_27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e712a15f-6271-4655-8695-a516d78c0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('target')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "938c60e6-f8c5-423c-aeb3-99bf5c3e32a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    462161\n",
       "1    437839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "809663bb-b45f-4208-9f84-4346cd6fdbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a7f7b39-712e-4978-8cad-c61c6eb203ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('sgdclassifier', SGDClassifier(loss='log'))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = make_pipeline(StandardScaler(), SGDClassifier(loss='log'))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "180d2edf-e24c-4fdb-a4b1-23c65b906f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67914432, 0.39688253, 0.61015596, ..., 0.71391864, 0.54560309,\n",
       "       0.18250122])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1878f604-8c22-426e-9155-f55de816ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, RocCurveDisplay, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "018ee898-9f60-4867-bc57-01e8a59d7d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093055555555555"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa431dfa-4586-4246-92bd-121ce8f8944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6521243844955168"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c379be59-f2a4-479f-84e5-033466144077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x106db14dca0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='example estimator')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98458147-4fc9-4139-b0ff-f0ee59a0227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 103.92, NNZs: 30, Bias: -32.060376, T: 518400, Avg. loss: 1512.995392\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 56.59, NNZs: 30, Bias: -22.362576, T: 1036800, Avg. loss: 165.956045\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.65, NNZs: 30, Bias: -16.726444, T: 1555200, Avg. loss: 97.334451\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.96, NNZs: 30, Bias: -12.431995, T: 2073600, Avg. loss: 69.894796\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.63, NNZs: 30, Bias: -9.164200, T: 2592000, Avg. loss: 54.047380\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.47, NNZs: 30, Bias: -7.432693, T: 3110400, Avg. loss: 44.141208\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 17.02, NNZs: 30, Bias: -5.527690, T: 3628800, Avg. loss: 37.662329\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.45, NNZs: 30, Bias: -4.433961, T: 4147200, Avg. loss: 32.484240\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 8 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 100.08, NNZs: 30, Bias: -14.112041, T: 518400, Avg. loss: 1500.025169\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 56.17, NNZs: 30, Bias: -12.040729, T: 1036800, Avg. loss: 166.426578\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.59, NNZs: 30, Bias: -9.702675, T: 1555200, Avg. loss: 97.481116\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.23, NNZs: 30, Bias: -7.619740, T: 2073600, Avg. loss: 69.527532\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.78, NNZs: 30, Bias: -5.708305, T: 2592000, Avg. loss: 54.233058\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.64, NNZs: 30, Bias: -4.735503, T: 3110400, Avg. loss: 44.161487\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16.92, NNZs: 30, Bias: -3.537827, T: 3628800, Avg. loss: 37.374746\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.26, NNZs: 30, Bias: -3.030633, T: 4147200, Avg. loss: 32.530652\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12.74, NNZs: 30, Bias: -2.609821, T: 4665600, Avg. loss: 28.806161\n",
      "Total training time: 1.82 seconds.\n",
      "Convergence after 9 epochs took 1.91 seconds\n",
      "-- Epoch 1\n",
      "Norm: 106.97, NNZs: 30, Bias: -41.128416, T: 518400, Avg. loss: 1490.844666\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57.10, NNZs: 30, Bias: -30.746436, T: 1036800, Avg. loss: 166.548598\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.45, NNZs: 30, Bias: -22.839382, T: 1555200, Avg. loss: 97.886389\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.33, NNZs: 30, Bias: -16.843919, T: 2073600, Avg. loss: 69.443256\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.75, NNZs: 30, Bias: -12.329846, T: 2592000, Avg. loss: 54.265926\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.38, NNZs: 30, Bias: -9.491929, T: 3110400, Avg. loss: 44.524804\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 102.67, NNZs: 30, Bias: 23.146022, T: 518400, Avg. loss: 1474.935098\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.01, NNZs: 30, Bias: 11.992059, T: 1036800, Avg. loss: 166.017700\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.62, NNZs: 30, Bias: 7.005542, T: 1555200, Avg. loss: 97.193694\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.37, NNZs: 30, Bias: 3.689999, T: 2073600, Avg. loss: 69.767598\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.06, NNZs: 30, Bias: 1.530091, T: 2592000, Avg. loss: 53.980882\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.11, NNZs: 30, Bias: -0.200032, T: 3110400, Avg. loss: 44.248901\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 107.60, NNZs: 30, Bias: -57.145306, T: 518400, Avg. loss: 1514.909628\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 58.54, NNZs: 30, Bias: -41.082726, T: 1036800, Avg. loss: 167.205643\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38.50, NNZs: 30, Bias: -30.797010, T: 1555200, Avg. loss: 98.103539\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 29.38, NNZs: 30, Bias: -21.912736, T: 2073600, Avg. loss: 69.551642\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23.61, NNZs: 30, Bias: -15.783050, T: 2592000, Avg. loss: 54.270876\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.64, NNZs: 30, Bias: -11.586341, T: 3110400, Avg. loss: 44.426310\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16.71, NNZs: 30, Bias: -9.101387, T: 3628800, Avg. loss: 37.575767\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14.84, NNZs: 30, Bias: -6.953144, T: 4147200, Avg. loss: 32.956929\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12.69, NNZs: 30, Bias: -5.072802, T: 4665600, Avg. loss: 28.892438\n",
      "Total training time: 1.73 seconds.\n",
      "Convergence after 9 epochs took 1.82 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4915.90, NNZs: 15, Bias: -0.340919, T: 518400, Avg. loss: 1311.332647\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5164.24, NNZs: 16, Bias: -0.050879, T: 1036800, Avg. loss: 47.116116\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5264.36, NNZs: 16, Bias: -0.228974, T: 1555200, Avg. loss: 18.796436\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5319.11, NNZs: 18, Bias: -0.001122, T: 2073600, Avg. loss: 10.282747\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5353.55, NNZs: 21, Bias: -0.126611, T: 2592000, Avg. loss: 6.646933\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5377.32, NNZs: 17, Bias: -0.197494, T: 3110400, Avg. loss: 4.699821\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5394.74, NNZs: 21, Bias: -0.218891, T: 3628800, Avg. loss: 3.463249\n",
      "Total training time: 1.89 seconds.\n",
      "Convergence after 7 epochs took 1.99 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4941.42, NNZs: 19, Bias: 0.027566, T: 518400, Avg. loss: 1305.791273\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5188.32, NNZs: 19, Bias: -0.037086, T: 1036800, Avg. loss: 46.991069\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5287.58, NNZs: 19, Bias: 0.031769, T: 1555200, Avg. loss: 18.535066\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5341.84, NNZs: 17, Bias: -0.115648, T: 2073600, Avg. loss: 10.304215\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5376.15, NNZs: 17, Bias: -0.118407, T: 2592000, Avg. loss: 6.532458\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5399.71, NNZs: 21, Bias: 0.000690, T: 3110400, Avg. loss: 4.728513\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4925.51, NNZs: 16, Bias: -0.413922, T: 518400, Avg. loss: 1297.545847\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5171.50, NNZs: 21, Bias: -0.107826, T: 1036800, Avg. loss: 47.184380\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5271.40, NNZs: 18, Bias: -0.040048, T: 1555200, Avg. loss: 18.901983\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5326.07, NNZs: 22, Bias: -0.200732, T: 2073600, Avg. loss: 10.138313\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5360.36, NNZs: 22, Bias: -0.053866, T: 2592000, Avg. loss: 6.628923\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5384.06, NNZs: 18, Bias: -0.045744, T: 3110400, Avg. loss: 4.759846\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4937.69, NNZs: 18, Bias: -0.015832, T: 518400, Avg. loss: 1290.359693\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5185.85, NNZs: 17, Bias: -0.144460, T: 1036800, Avg. loss: 46.561030\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5286.26, NNZs: 20, Bias: -0.003234, T: 1555200, Avg. loss: 18.821847\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5340.75, NNZs: 20, Bias: -0.192813, T: 2073600, Avg. loss: 10.257003\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5375.12, NNZs: 20, Bias: -0.093694, T: 2592000, Avg. loss: 6.596999\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5398.80, NNZs: 23, Bias: -0.108905, T: 3110400, Avg. loss: 4.686857\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5416.16, NNZs: 22, Bias: -0.089128, T: 3628800, Avg. loss: 3.494673\n",
      "Total training time: 1.88 seconds.\n",
      "Convergence after 7 epochs took 1.97 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4942.54, NNZs: 13, Bias: -0.217621, T: 518400, Avg. loss: 1316.550172\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5190.48, NNZs: 16, Bias: -0.154349, T: 1036800, Avg. loss: 46.421036\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5290.62, NNZs: 19, Bias: -0.202077, T: 1555200, Avg. loss: 18.875150\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5345.28, NNZs: 20, Bias: -0.210877, T: 2073600, Avg. loss: 10.159728\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5379.62, NNZs: 18, Bias: -0.105051, T: 2592000, Avg. loss: 6.587841\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5403.26, NNZs: 19, Bias: -0.057584, T: 3110400, Avg. loss: 4.702694\n",
      "Total training time: 1.58 seconds.\n",
      "Convergence after 6 epochs took 1.68 seconds\n",
      "-- Epoch 1\n",
      "Norm: 860.62, NNZs: 28, Bias: -21.821532, T: 518400, Avg. loss: 1432.739143\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 851.03, NNZs: 25, Bias: -1.528728, T: 1036800, Avg. loss: 108.818939\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 831.91, NNZs: 19, Bias: 0.090430, T: 1555200, Avg. loss: 52.940034\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 811.80, NNZs: 23, Bias: -0.139519, T: 2073600, Avg. loss: 33.071488\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 791.68, NNZs: 23, Bias: -0.140155, T: 2592000, Avg. loss: 22.929621\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 772.21, NNZs: 22, Bias: -0.261642, T: 3110400, Avg. loss: 16.921663\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 753.14, NNZs: 19, Bias: -0.156747, T: 3628800, Avg. loss: 13.206258\n",
      "Total training time: 1.77 seconds.\n",
      "Convergence after 7 epochs took 1.87 seconds\n",
      "-- Epoch 1\n",
      "Norm: 856.82, NNZs: 29, Bias: 44.276778, T: 518400, Avg. loss: 1462.423644\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 850.21, NNZs: 23, Bias: 0.934375, T: 1036800, Avg. loss: 109.265065\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 832.53, NNZs: 22, Bias: -0.312904, T: 1555200, Avg. loss: 52.879497\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 812.57, NNZs: 23, Bias: -0.134276, T: 2073600, Avg. loss: 33.034894\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 791.82, NNZs: 22, Bias: 0.046599, T: 2592000, Avg. loss: 23.009535\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 772.21, NNZs: 19, Bias: -0.188298, T: 3110400, Avg. loss: 17.065712\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 861.38, NNZs: 28, Bias: 17.222786, T: 518400, Avg. loss: 1443.447814\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 852.56, NNZs: 22, Bias: 0.055291, T: 1036800, Avg. loss: 108.714505\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 832.74, NNZs: 22, Bias: -0.146469, T: 1555200, Avg. loss: 52.760768\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 812.98, NNZs: 22, Bias: 0.000774, T: 2073600, Avg. loss: 33.182154\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 792.96, NNZs: 22, Bias: -0.249779, T: 2592000, Avg. loss: 22.953942\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 773.15, NNZs: 23, Bias: -0.235411, T: 3110400, Avg. loss: 16.991318\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 863.05, NNZs: 29, Bias: -52.805814, T: 518400, Avg. loss: 1468.695838\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 852.39, NNZs: 22, Bias: -3.012848, T: 1036800, Avg. loss: 109.018283\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 832.07, NNZs: 21, Bias: -0.210385, T: 1555200, Avg. loss: 53.217431\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 812.41, NNZs: 20, Bias: -0.224881, T: 2073600, Avg. loss: 33.152557\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 791.94, NNZs: 19, Bias: -0.066944, T: 2592000, Avg. loss: 23.000153\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 772.30, NNZs: 22, Bias: -0.125712, T: 3110400, Avg. loss: 16.957754\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 753.17, NNZs: 20, Bias: -0.155347, T: 3628800, Avg. loss: 13.263231\n",
      "Total training time: 1.79 seconds.\n",
      "Convergence after 7 epochs took 1.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 858.05, NNZs: 28, Bias: 3.776788, T: 518400, Avg. loss: 1469.166600\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 851.62, NNZs: 20, Bias: -0.330919, T: 1036800, Avg. loss: 108.993486\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 833.49, NNZs: 22, Bias: -0.267982, T: 1555200, Avg. loss: 53.047218\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 813.70, NNZs: 21, Bias: -0.100991, T: 2073600, Avg. loss: 33.322381\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 793.16, NNZs: 20, Bias: -0.121686, T: 2592000, Avg. loss: 22.966114\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 773.35, NNZs: 21, Bias: -0.152322, T: 3110400, Avg. loss: 16.914269\n",
      "Total training time: 1.51 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 754.19, NNZs: 23, Bias: -0.126301, T: 3628800, Avg. loss: 13.112775\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 736.32, NNZs: 17, Bias: -0.178714, T: 4147200, Avg. loss: 10.551986\n",
      "Total training time: 2.06 seconds.\n",
      "Convergence after 8 epochs took 2.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 102.28, NNZs: 30, Bias: 11.464242, T: 518400, Avg. loss: 1513.290644\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.55, NNZs: 30, Bias: 6.315829, T: 1036800, Avg. loss: 165.502314\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.83, NNZs: 30, Bias: 3.247276, T: 1555200, Avg. loss: 97.333887\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.24, NNZs: 30, Bias: 1.946525, T: 2073600, Avg. loss: 68.698812\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.15, NNZs: 30, Bias: -0.039278, T: 2592000, Avg. loss: 53.409727\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.55, NNZs: 30, Bias: -0.805610, T: 3110400, Avg. loss: 43.543639\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.42 seconds\n",
      "-- Epoch 1\n",
      "Norm: 104.06, NNZs: 30, Bias: 2.302408, T: 518400, Avg. loss: 1528.643017\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.16, NNZs: 30, Bias: -0.783334, T: 1036800, Avg. loss: 165.955685\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.65, NNZs: 30, Bias: -2.095559, T: 1555200, Avg. loss: 97.142349\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.09, NNZs: 30, Bias: -2.523937, T: 2073600, Avg. loss: 68.804170\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.85, NNZs: 30, Bias: -2.771543, T: 2592000, Avg. loss: 53.331687\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.05, NNZs: 30, Bias: -2.560636, T: 3110400, Avg. loss: 43.422440\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.83, NNZs: 30, Bias: -2.399512, T: 3628800, Avg. loss: 36.836159\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13.85, NNZs: 30, Bias: -2.288778, T: 4147200, Avg. loss: 31.873814\n",
      "Total training time: 1.79 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12.16, NNZs: 30, Bias: -2.132388, T: 4665600, Avg. loss: 27.957807\n",
      "Total training time: 2.02 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.30, NNZs: 30, Bias: -2.006859, T: 5184000, Avg. loss: 25.027830\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 10.46, NNZs: 30, Bias: -1.691475, T: 5702400, Avg. loss: 22.692462\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9.43, NNZs: 30, Bias: -1.530142, T: 6220800, Avg. loss: 20.663864\n",
      "Total training time: 2.73 seconds.\n",
      "Convergence after 12 epochs took 2.83 seconds\n",
      "-- Epoch 1\n",
      "Norm: 102.36, NNZs: 30, Bias: 10.228735, T: 518400, Avg. loss: 1539.580098\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 53.23, NNZs: 30, Bias: 5.453097, T: 1036800, Avg. loss: 166.147492\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.66, NNZs: 30, Bias: 2.472570, T: 1555200, Avg. loss: 96.563422\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.58, NNZs: 30, Bias: 0.950722, T: 2073600, Avg. loss: 68.723234\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.75, NNZs: 30, Bias: -0.465556, T: 2592000, Avg. loss: 53.219377\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.80, NNZs: 30, Bias: -0.627844, T: 3110400, Avg. loss: 43.671578\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 101.51, NNZs: 30, Bias: -8.966408, T: 518400, Avg. loss: 1505.241397\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 56.35, NNZs: 30, Bias: -9.184507, T: 1036800, Avg. loss: 165.749803\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.19, NNZs: 30, Bias: -8.313214, T: 1555200, Avg. loss: 97.249892\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.86, NNZs: 30, Bias: -6.948739, T: 2073600, Avg. loss: 68.910969\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.20, NNZs: 30, Bias: -5.781105, T: 2592000, Avg. loss: 53.117833\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.24, NNZs: 30, Bias: -4.946792, T: 3110400, Avg. loss: 43.609194\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.58, NNZs: 30, Bias: -4.159757, T: 3628800, Avg. loss: 36.866913\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13.83, NNZs: 30, Bias: -3.264898, T: 4147200, Avg. loss: 31.846914\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12.82, NNZs: 30, Bias: -2.628723, T: 4665600, Avg. loss: 28.068581\n",
      "Total training time: 2.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.31, NNZs: 30, Bias: -2.316793, T: 5184000, Avg. loss: 25.088983\n",
      "Total training time: 2.28 seconds.\n",
      "Convergence after 10 epochs took 2.37 seconds\n",
      "-- Epoch 1\n",
      "Norm: 99.25, NNZs: 30, Bias: 31.297589, T: 518400, Avg. loss: 1541.479960\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 51.27, NNZs: 30, Bias: 18.019060, T: 1036800, Avg. loss: 165.564844\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.46, NNZs: 30, Bias: 10.316690, T: 1555200, Avg. loss: 97.348354\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 25.98, NNZs: 30, Bias: 5.244718, T: 2073600, Avg. loss: 68.909008\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.32, NNZs: 30, Bias: 2.700144, T: 2592000, Avg. loss: 53.463982\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.52, NNZs: 30, Bias: 0.957273, T: 3110400, Avg. loss: 43.537728\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.77, NNZs: 30, Bias: 0.328715, T: 3628800, Avg. loss: 36.925361\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13.88, NNZs: 30, Bias: -0.277678, T: 4147200, Avg. loss: 32.022460\n",
      "Total training time: 1.73 seconds.\n",
      "Convergence after 8 epochs took 1.82 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4873.51, NNZs: 16, Bias: -0.259206, T: 518400, Avg. loss: 1326.734789\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5016.36, NNZs: 15, Bias: -0.185121, T: 1036800, Avg. loss: 17.451650\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5061.65, NNZs: 19, Bias: -0.015881, T: 1555200, Avg. loss: 5.381967\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5083.78, NNZs: 17, Bias: -0.062385, T: 2073600, Avg. loss: 2.697040\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5096.90, NNZs: 19, Bias: -0.085537, T: 2592000, Avg. loss: 1.732469\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5105.57, NNZs: 21, Bias: -0.066986, T: 3110400, Avg. loss: 1.359755\n",
      "Total training time: 1.82 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5111.72, NNZs: 20, Bias: -0.093603, T: 3628800, Avg. loss: 1.090705\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5116.30, NNZs: 20, Bias: -0.112804, T: 4147200, Avg. loss: 0.996306\n",
      "Total training time: 2.43 seconds.\n",
      "Convergence after 8 epochs took 2.52 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4899.79, NNZs: 13, Bias: -0.170188, T: 518400, Avg. loss: 1268.891722\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5041.80, NNZs: 18, Bias: -0.022191, T: 1036800, Avg. loss: 17.297094\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5087.08, NNZs: 17, Bias: -0.032871, T: 1555200, Avg. loss: 5.204603\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5109.08, NNZs: 17, Bias: -0.010423, T: 2073600, Avg. loss: 2.701521\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5122.08, NNZs: 21, Bias: -0.040196, T: 2592000, Avg. loss: 1.784684\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5130.70, NNZs: 22, Bias: -0.087207, T: 3110400, Avg. loss: 1.366736\n",
      "Total training time: 1.80 seconds.\n",
      "Convergence after 6 epochs took 1.89 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4894.64, NNZs: 16, Bias: -0.101403, T: 518400, Avg. loss: 1270.914918\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5037.01, NNZs: 19, Bias: -0.009350, T: 1036800, Avg. loss: 17.435017\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5082.17, NNZs: 20, Bias: -0.032621, T: 1555200, Avg. loss: 5.189316\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5104.26, NNZs: 22, Bias: -0.143300, T: 2073600, Avg. loss: 2.671412\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5117.29, NNZs: 19, Bias: 0.036575, T: 2592000, Avg. loss: 1.770834\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5125.90, NNZs: 19, Bias: -0.027572, T: 3110400, Avg. loss: 1.289430\n",
      "Total training time: 1.79 seconds.\n",
      "Convergence after 6 epochs took 1.87 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4842.70, NNZs: 14, Bias: 0.109922, T: 518400, Avg. loss: 1283.627507\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4985.97, NNZs: 14, Bias: -0.146976, T: 1036800, Avg. loss: 17.032805\n",
      "Total training time: 0.56 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5031.58, NNZs: 17, Bias: -0.035028, T: 1555200, Avg. loss: 5.333885\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5053.87, NNZs: 18, Bias: -0.152375, T: 2073600, Avg. loss: 2.746671\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5067.02, NNZs: 22, Bias: -0.072237, T: 2592000, Avg. loss: 1.747780\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5075.71, NNZs: 20, Bias: -0.097372, T: 3110400, Avg. loss: 1.380966\n",
      "Total training time: 1.79 seconds.\n",
      "Convergence after 6 epochs took 1.89 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4855.66, NNZs: 15, Bias: -0.214551, T: 518400, Avg. loss: 1285.024756\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4998.48, NNZs: 17, Bias: -0.106751, T: 1036800, Avg. loss: 17.274765\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5044.05, NNZs: 18, Bias: -0.125503, T: 1555200, Avg. loss: 5.238286\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5066.40, NNZs: 19, Bias: -0.097120, T: 2073600, Avg. loss: 2.664831\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5079.59, NNZs: 21, Bias: -0.107157, T: 2592000, Avg. loss: 1.746883\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5088.28, NNZs: 23, Bias: -0.124302, T: 3110400, Avg. loss: 1.357399\n",
      "Total training time: 1.76 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 858.56, NNZs: 29, Bias: 0.677080, T: 518400, Avg. loss: 1429.781515\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 845.68, NNZs: 20, Bias: -0.278524, T: 1036800, Avg. loss: 100.614433\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 803.79, NNZs: 20, Bias: -0.079192, T: 1555200, Avg. loss: 35.243650\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 753.41, NNZs: 21, Bias: -0.049348, T: 2073600, Avg. loss: 15.985621\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 706.10, NNZs: 22, Bias: -0.069993, T: 2592000, Avg. loss: 8.950924\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 664.48, NNZs: 22, Bias: -0.038961, T: 3110400, Avg. loss: 5.808306\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 628.55, NNZs: 22, Bias: -0.091829, T: 3628800, Avg. loss: 4.147530\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 597.34, NNZs: 20, Bias: -0.106346, T: 4147200, Avg. loss: 3.186234\n",
      "Total training time: 2.33 seconds.\n",
      "Convergence after 8 epochs took 2.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 859.22, NNZs: 28, Bias: 28.848511, T: 518400, Avg. loss: 1436.739409\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 845.33, NNZs: 24, Bias: -0.197964, T: 1036800, Avg. loss: 100.189514\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 803.25, NNZs: 21, Bias: 0.036327, T: 1555200, Avg. loss: 35.181134\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 752.80, NNZs: 20, Bias: -0.141957, T: 2073600, Avg. loss: 15.941916\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 705.16, NNZs: 21, Bias: -0.061911, T: 2592000, Avg. loss: 8.974374\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 663.77, NNZs: 18, Bias: -0.117918, T: 3110400, Avg. loss: 5.748770\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 6 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 860.11, NNZs: 25, Bias: -34.018304, T: 518400, Avg. loss: 1417.132978\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 845.39, NNZs: 22, Bias: -1.257972, T: 1036800, Avg. loss: 101.244237\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 802.96, NNZs: 19, Bias: -0.090705, T: 1555200, Avg. loss: 35.057064\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 753.01, NNZs: 20, Bias: -0.132863, T: 2073600, Avg. loss: 15.928125\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 705.72, NNZs: 20, Bias: -0.032769, T: 2592000, Avg. loss: 8.901940\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 664.28, NNZs: 22, Bias: -0.061868, T: 3110400, Avg. loss: 5.814757\n",
      "Total training time: 1.70 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 628.54, NNZs: 21, Bias: -0.104015, T: 3628800, Avg. loss: 4.161730\n",
      "Total training time: 2.01 seconds.\n",
      "Convergence after 7 epochs took 2.10 seconds\n",
      "-- Epoch 1\n",
      "Norm: 858.83, NNZs: 28, Bias: -7.659383, T: 518400, Avg. loss: 1459.900443\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 845.25, NNZs: 21, Bias: -0.586510, T: 1036800, Avg. loss: 100.568578\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 802.87, NNZs: 19, Bias: -0.023043, T: 1555200, Avg. loss: 34.712760\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 752.94, NNZs: 22, Bias: -0.035370, T: 2073600, Avg. loss: 15.884553\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 705.77, NNZs: 21, Bias: -0.233835, T: 2592000, Avg. loss: 8.913723\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 664.18, NNZs: 23, Bias: -0.050950, T: 3110400, Avg. loss: 5.759051\n",
      "Total training time: 1.75 seconds.\n",
      "Convergence after 6 epochs took 1.84 seconds\n",
      "-- Epoch 1\n",
      "Norm: 858.08, NNZs: 28, Bias: -47.075027, T: 518400, Avg. loss: 1456.570136\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 845.79, NNZs: 24, Bias: -1.815023, T: 1036800, Avg. loss: 101.760668\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 803.73, NNZs: 20, Bias: 0.010846, T: 1555200, Avg. loss: 35.249028\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 753.84, NNZs: 22, Bias: -0.250394, T: 2073600, Avg. loss: 15.912926\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 706.09, NNZs: 20, Bias: -0.122730, T: 2592000, Avg. loss: 9.012244\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 664.52, NNZs: 19, Bias: -0.074688, T: 3110400, Avg. loss: 5.810159\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 103.58, NNZs: 30, Bias: 31.651068, T: 518400, Avg. loss: 1547.062488\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52.86, NNZs: 30, Bias: 20.104011, T: 1036800, Avg. loss: 165.511368\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.47, NNZs: 30, Bias: 11.150054, T: 1555200, Avg. loss: 97.031681\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.86, NNZs: 30, Bias: 5.875456, T: 2073600, Avg. loss: 68.797739\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.99, NNZs: 30, Bias: 2.905309, T: 2592000, Avg. loss: 53.720096\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.97, NNZs: 30, Bias: 1.292187, T: 3110400, Avg. loss: 43.767386\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 104.43, NNZs: 30, Bias: -23.996798, T: 518400, Avg. loss: 1485.916229\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55.28, NNZs: 30, Bias: -17.970130, T: 1036800, Avg. loss: 165.407745\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37.12, NNZs: 30, Bias: -14.441856, T: 1555200, Avg. loss: 96.703073\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.77, NNZs: 30, Bias: -11.180645, T: 2073600, Avg. loss: 68.655141\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.42, NNZs: 30, Bias: -8.318647, T: 2592000, Avg. loss: 53.237820\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.08, NNZs: 30, Bias: -6.374255, T: 3110400, Avg. loss: 43.923543\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.87, NNZs: 30, Bias: -5.067022, T: 3628800, Avg. loss: 36.725637\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 7 epochs took 1.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 103.41, NNZs: 30, Bias: 4.444673, T: 518400, Avg. loss: 1527.310950\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.76, NNZs: 30, Bias: 0.685655, T: 1036800, Avg. loss: 166.542332\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36.88, NNZs: 30, Bias: -0.638118, T: 1555200, Avg. loss: 97.534508\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27.45, NNZs: 30, Bias: -1.365587, T: 2073600, Avg. loss: 68.903676\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.69, NNZs: 30, Bias: -2.032039, T: 2592000, Avg. loss: 53.503877\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.83, NNZs: 30, Bias: -1.823341, T: 3110400, Avg. loss: 43.608751\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15.81, NNZs: 30, Bias: -1.846805, T: 3628800, Avg. loss: 36.928942\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13.79, NNZs: 30, Bias: -1.840853, T: 4147200, Avg. loss: 32.156036\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 8 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 105.97, NNZs: 30, Bias: -46.428290, T: 518400, Avg. loss: 1513.465124\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57.31, NNZs: 30, Bias: -34.464754, T: 1036800, Avg. loss: 165.640205\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.89, NNZs: 30, Bias: -24.943123, T: 1555200, Avg. loss: 97.230842\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.91, NNZs: 30, Bias: -18.613079, T: 2073600, Avg. loss: 69.142786\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22.09, NNZs: 30, Bias: -13.377876, T: 2592000, Avg. loss: 53.568598\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.81, NNZs: 30, Bias: -9.963745, T: 3110400, Avg. loss: 43.807824\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 101.56, NNZs: 30, Bias: 61.102967, T: 518400, Avg. loss: 1469.270850\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54.60, NNZs: 30, Bias: 38.122011, T: 1036800, Avg. loss: 166.027210\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35.62, NNZs: 30, Bias: 23.782181, T: 1555200, Avg. loss: 97.171077\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 26.64, NNZs: 30, Bias: 15.257519, T: 2073600, Avg. loss: 68.897988\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.61, NNZs: 30, Bias: 9.057702, T: 2592000, Avg. loss: 53.477493\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18.13, NNZs: 30, Bias: 5.023309, T: 3110400, Avg. loss: 43.760096\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4926.01, NNZs: 9, Bias: -0.099729, T: 518400, Avg. loss: 1328.632405\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5118.82, NNZs: 10, Bias: -0.019513, T: 1036800, Avg. loss: 36.095631\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5189.83, NNZs: 6, Bias: 0.017546, T: 1555200, Avg. loss: 12.339088\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5226.53, NNZs: 3, Bias: -0.011685, T: 2073600, Avg. loss: 6.207952\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5248.96, NNZs: 11, Bias: -0.013560, T: 2592000, Avg. loss: 3.722852\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5264.22, NNZs: 9, Bias: 0.007578, T: 3110400, Avg. loss: 2.414752\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5275.14, NNZs: 7, Bias: -0.010147, T: 3628800, Avg. loss: 1.667647\n",
      "Total training time: 1.91 seconds.\n",
      "Convergence after 7 epochs took 2.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4893.01, NNZs: 10, Bias: -0.316465, T: 518400, Avg. loss: 1301.917730\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5088.27, NNZs: 3, Bias: 0.013183, T: 1036800, Avg. loss: 35.537359\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5159.58, NNZs: 5, Bias: -0.031745, T: 1555200, Avg. loss: 12.575864\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5196.25, NNZs: 6, Bias: -0.000517, T: 2073600, Avg. loss: 6.342663\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5219.02, NNZs: 6, Bias: 0.010788, T: 2592000, Avg. loss: 3.629192\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5234.26, NNZs: 2, Bias: -0.000874, T: 3110400, Avg. loss: 2.568010\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5245.17, NNZs: 3, Bias: 0.007299, T: 3628800, Avg. loss: 1.826032\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5253.45, NNZs: 8, Bias: 0.011046, T: 4147200, Avg. loss: 1.325541\n",
      "Total training time: 2.22 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 5259.93, NNZs: 6, Bias: 0.005382, T: 4665600, Avg. loss: 0.936365\n",
      "Total training time: 2.52 seconds.\n",
      "Convergence after 9 epochs took 2.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4933.20, NNZs: 9, Bias: 0.014726, T: 518400, Avg. loss: 1288.547792\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5125.55, NNZs: 15, Bias: -0.036161, T: 1036800, Avg. loss: 36.270548\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5196.21, NNZs: 11, Bias: 0.000628, T: 1555200, Avg. loss: 12.674339\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5232.92, NNZs: 9, Bias: -0.015073, T: 2073600, Avg. loss: 6.383565\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5255.41, NNZs: 6, Bias: -0.016237, T: 2592000, Avg. loss: 3.681037\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5270.56, NNZs: 4, Bias: 0.008623, T: 3110400, Avg. loss: 2.562067\n",
      "Total training time: 1.63 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5281.45, NNZs: 8, Bias: -0.014783, T: 3628800, Avg. loss: 1.769499\n",
      "Total training time: 1.92 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5289.68, NNZs: 6, Bias: 0.001415, T: 4147200, Avg. loss: 1.301526\n",
      "Total training time: 2.22 seconds.\n",
      "Convergence after 8 epochs took 2.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4874.43, NNZs: 10, Bias: -0.216029, T: 518400, Avg. loss: 1326.668390\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5069.27, NNZs: 7, Bias: -0.100693, T: 1036800, Avg. loss: 35.878171\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5140.93, NNZs: 9, Bias: 0.001919, T: 1555200, Avg. loss: 12.371672\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5178.03, NNZs: 7, Bias: 0.005680, T: 2073600, Avg. loss: 6.228348\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5200.80, NNZs: 7, Bias: -0.007630, T: 2592000, Avg. loss: 3.740709\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5216.08, NNZs: 6, Bias: 0.002931, T: 3110400, Avg. loss: 2.487142\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 6 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 4913.43, NNZs: 7, Bias: -0.104580, T: 518400, Avg. loss: 1324.263609\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5107.78, NNZs: 6, Bias: -0.067047, T: 1036800, Avg. loss: 35.902026\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5179.15, NNZs: 7, Bias: 0.010904, T: 1555200, Avg. loss: 12.507522\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 5216.17, NNZs: 6, Bias: -0.016868, T: 2073600, Avg. loss: 6.289788\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5238.77, NNZs: 4, Bias: -0.017961, T: 2592000, Avg. loss: 3.644740\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5253.98, NNZs: 4, Bias: 0.004033, T: 3110400, Avg. loss: 2.418268\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 6 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 856.14, NNZs: 27, Bias: 15.844583, T: 518400, Avg. loss: 1471.433926\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 842.51, NNZs: 16, Bias: -0.248221, T: 1036800, Avg. loss: 105.420499\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 807.42, NNZs: 13, Bias: 0.004581, T: 1555200, Avg. loss: 46.760651\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 771.28, NNZs: 14, Bias: 0.003881, T: 2073600, Avg. loss: 26.880283\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 738.69, NNZs: 10, Bias: -0.018295, T: 2592000, Avg. loss: 17.553432\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 708.97, NNZs: 13, Bias: 0.018720, T: 3110400, Avg. loss: 12.193513\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 682.81, NNZs: 10, Bias: 0.007387, T: 3628800, Avg. loss: 9.007975\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 7 epochs took 1.94 seconds\n",
      "-- Epoch 1\n",
      "Norm: 856.88, NNZs: 26, Bias: 3.383474, T: 518400, Avg. loss: 1473.506005\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 842.28, NNZs: 21, Bias: -0.225904, T: 1036800, Avg. loss: 105.192586\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 806.88, NNZs: 20, Bias: -0.156542, T: 1555200, Avg. loss: 46.808344\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 771.69, NNZs: 15, Bias: -0.018199, T: 2073600, Avg. loss: 26.889122\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 738.26, NNZs: 12, Bias: 0.022477, T: 2592000, Avg. loss: 17.510937\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 708.67, NNZs: 13, Bias: -0.004660, T: 3110400, Avg. loss: 12.217784\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 682.07, NNZs: 6, Bias: 0.001052, T: 3628800, Avg. loss: 9.019648\n",
      "Total training time: 1.88 seconds.\n",
      "Convergence after 7 epochs took 1.97 seconds\n",
      "-- Epoch 1\n",
      "Norm: 858.80, NNZs: 27, Bias: -52.870174, T: 518400, Avg. loss: 1460.297290\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 842.82, NNZs: 19, Bias: -0.901667, T: 1036800, Avg. loss: 106.063743\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 807.15, NNZs: 14, Bias: 0.022200, T: 1555200, Avg. loss: 46.849204\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 771.46, NNZs: 16, Bias: 0.024326, T: 2073600, Avg. loss: 27.051088\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 738.94, NNZs: 13, Bias: 0.036204, T: 2592000, Avg. loss: 17.433722\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 709.35, NNZs: 12, Bias: 0.020398, T: 3110400, Avg. loss: 12.185902\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 856.61, NNZs: 28, Bias: 39.498248, T: 518400, Avg. loss: 1459.365740\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 842.02, NNZs: 17, Bias: -0.191349, T: 1036800, Avg. loss: 105.698793\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 807.33, NNZs: 20, Bias: -0.073516, T: 1555200, Avg. loss: 47.017778\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 771.70, NNZs: 16, Bias: -0.057466, T: 2073600, Avg. loss: 26.942545\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 739.24, NNZs: 13, Bias: -0.002540, T: 2592000, Avg. loss: 17.530973\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 709.75, NNZs: 10, Bias: -0.012854, T: 3110400, Avg. loss: 12.235503\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 683.37, NNZs: 10, Bias: -0.014552, T: 3628800, Avg. loss: 9.006290\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 659.20, NNZs: 8, Bias: -0.013153, T: 4147200, Avg. loss: 7.014071\n",
      "Total training time: 2.24 seconds.\n",
      "Convergence after 8 epochs took 2.33 seconds\n",
      "-- Epoch 1\n",
      "Norm: 856.81, NNZs: 27, Bias: -7.139508, T: 518400, Avg. loss: 1445.152865\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 843.05, NNZs: 19, Bias: -0.267450, T: 1036800, Avg. loss: 105.251580\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 808.88, NNZs: 16, Bias: -0.067299, T: 1555200, Avg. loss: 47.192469\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 772.35, NNZs: 12, Bias: -0.045752, T: 2073600, Avg. loss: 27.023571\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 739.49, NNZs: 12, Bias: 0.004305, T: 2592000, Avg. loss: 17.498131\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 709.93, NNZs: 11, Bias: -0.026057, T: 3110400, Avg. loss: 12.272744\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 100935014389511.77, NNZs: 30, Bias: 11218014117998.470703, T: 518400, Avg. loss: 177444024939788050414091831869440.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 52071368729824.80, NNZs: 30, Bias: 5425218565754.566406, T: 1036800, Avg. loss: 175051350364107531197614129152.000000\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 36907241253155.77, NNZs: 30, Bias: 1945209839140.986816, T: 1555200, Avg. loss: 58479350704385496475414560768.000000\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27359421452134.57, NNZs: 30, Bias: 6880346724.041709, T: 2073600, Avg. loss: 28937940138680149297229463552.000000\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22420561401031.50, NNZs: 30, Bias: -946926669606.962769, T: 2592000, Avg. loss: 17503755649312178883251929088.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18427357756246.03, NNZs: 30, Bias: -1354120192248.350342, T: 3110400, Avg. loss: 11613250927713084525137362944.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15576672635646.81, NNZs: 30, Bias: -1622991155894.297119, T: 3628800, Avg. loss: 8379961622846721818401701888.000000\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 13709788444411.49, NNZs: 30, Bias: -1715775338768.813477, T: 4147200, Avg. loss: 6359382486815389043413483520.000000\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 8 epochs took 1.69 seconds\n",
      "-- Epoch 1\n",
      "Norm: 102944349175047.97, NNZs: 30, Bias: 1621258566784.322510, T: 518400, Avg. loss: 172352846315460460911195141963776.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54618878179715.84, NNZs: 30, Bias: -1642438434339.468750, T: 1036800, Avg. loss: 175094058689696543649879293952.000000\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35974301287391.69, NNZs: 30, Bias: -2099800208571.298584, T: 1555200, Avg. loss: 58975816201349991487074467840.000000\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27913013969139.04, NNZs: 30, Bias: -2905594351612.783203, T: 2073600, Avg. loss: 29378636081517676243355435008.000000\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21745213934316.25, NNZs: 30, Bias: -2828845861369.926270, T: 2592000, Avg. loss: 17461289911386685426183962624.000000\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17740519980486.60, NNZs: 30, Bias: -2874537624316.633301, T: 3110400, Avg. loss: 11690319298736409134684438528.000000\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 104406924711723.48, NNZs: 30, Bias: 3727224978121.315430, T: 518400, Avg. loss: 163916271855265244947597911654400.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54845660204079.86, NNZs: 30, Bias: -484143435091.920837, T: 1036800, Avg. loss: 175821271641315766525061234688.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37259698870323.80, NNZs: 30, Bias: -1397188510945.411865, T: 1555200, Avg. loss: 59043312393164367200952254464.000000\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27975064946499.54, NNZs: 30, Bias: -1746534871491.333740, T: 2073600, Avg. loss: 29226750693425917042861539328.000000\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22096563923805.77, NNZs: 30, Bias: -1887706030083.455566, T: 2592000, Avg. loss: 17668017727062042762545201152.000000\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18542129211402.62, NNZs: 30, Bias: -1856549274267.655029, T: 3110400, Avg. loss: 11781793563702567477991964672.000000\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 99349991770604.78, NNZs: 30, Bias: 31804040494301.109375, T: 518400, Avg. loss: 205009855019032597799513190563840.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 54375790600628.68, NNZs: 30, Bias: 17397505895989.052734, T: 1036800, Avg. loss: 176574202195642941998479966208.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 35886013049412.20, NNZs: 30, Bias: 10021880420399.994141, T: 1555200, Avg. loss: 58616440115725923540591968256.000000\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27945894445528.17, NNZs: 30, Bias: 5722056109094.641602, T: 2073600, Avg. loss: 28986601072463332043003002880.000000\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22443815041526.02, NNZs: 30, Bias: 2822355434171.541992, T: 2592000, Avg. loss: 17620737730232249297523441664.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18418993103557.92, NNZs: 30, Bias: 918251550906.887695, T: 3110400, Avg. loss: 11712498897722137322712989696.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15893251028966.92, NNZs: 30, Bias: -153191342628.420227, T: 3628800, Avg. loss: 8412259822803271987702530048.000000\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 7 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 107200044052130.02, NNZs: 30, Bias: -28657773343583.070312, T: 518400, Avg. loss: 171218826073094545224229388812288.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57312789969619.00, NNZs: 30, Bias: -21484589734627.421875, T: 1036800, Avg. loss: 176407260777872260271190310912.000000\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37833472392151.59, NNZs: 30, Bias: -15750845795529.488281, T: 1555200, Avg. loss: 58595073377265010787575922688.000000\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27892882241899.61, NNZs: 30, Bias: -12047508639202.882812, T: 2073600, Avg. loss: 29309734854712098300603924480.000000\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22812361412509.54, NNZs: 30, Bias: -9578873768745.156250, T: 2592000, Avg. loss: 17566235649633605102805712896.000000\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18705533962137.43, NNZs: 30, Bias: -7290990082258.305664, T: 3110400, Avg. loss: 11798339993179507110453444608.000000\n",
      "Total training time: 1.20 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 303230866024028.12, NNZs: 30, Bias: -35954253034338.726562, T: 518400, Avg. loss: 198192581524789645685040240132096.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 102917403427060.83, NNZs: 30, Bias: -37130978497538.875000, T: 1036800, Avg. loss: 178291248551730655351271325696.000000\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49267600840539.44, NNZs: 30, Bias: -29244719749164.589844, T: 1555200, Avg. loss: 58115847943701912842630332416.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32450359593563.34, NNZs: 30, Bias: -21922947944011.332031, T: 2073600, Avg. loss: 29140984343980992935875313664.000000\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 25261818287345.88, NNZs: 30, Bias: -16726347390370.386719, T: 2592000, Avg. loss: 17558557377767060993214513152.000000\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20528120092148.64, NNZs: 30, Bias: -11962883180342.769531, T: 3110400, Avg. loss: 11774787446260136360418476032.000000\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 294272889930437.25, NNZs: 30, Bias: 7007925745893.051758, T: 518400, Avg. loss: 175254930099048814364250878246912.000000\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 98742439103628.31, NNZs: 30, Bias: -4574214991125.358398, T: 1036800, Avg. loss: 178710138424984481146112835584.000000\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 46805617232824.43, NNZs: 30, Bias: -7067375291740.724609, T: 1555200, Avg. loss: 58493120059262770550700769280.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 30672028215439.66, NNZs: 30, Bias: -6867540743152.017578, T: 2073600, Avg. loss: 28981417974498667994648936448.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23844191156333.41, NNZs: 30, Bias: -6172693220986.182617, T: 2592000, Avg. loss: 17605590780513800641224638464.000000\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19403647176350.46, NNZs: 30, Bias: -5056898707252.745117, T: 3110400, Avg. loss: 11706967831522972207677440000.000000\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.56 seconds\n",
      "-- Epoch 1\n",
      "Norm: 286713099327234.62, NNZs: 30, Bias: -16623904473515.582031, T: 518400, Avg. loss: 178340652853580502258763945738240.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 95531667901096.61, NNZs: 30, Bias: -22498437416794.167969, T: 1036800, Avg. loss: 175943027811376428833438695424.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47303835427666.60, NNZs: 30, Bias: -18986098421047.593750, T: 1555200, Avg. loss: 59077718687423850086718767104.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32353563346313.46, NNZs: 30, Bias: -14409722179631.195312, T: 2073600, Avg. loss: 29263799943356796616545665024.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24463276721958.39, NNZs: 30, Bias: -10970166581978.921875, T: 2592000, Avg. loss: 17583067809653064026751500288.000000\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20470939760125.50, NNZs: 30, Bias: -7906950252170.408203, T: 3110400, Avg. loss: 11696595426683750527149277184.000000\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16964737005539.22, NNZs: 30, Bias: -5937774007807.660156, T: 3628800, Avg. loss: 8403969455281808945291722752.000000\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 7 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 337370481032200.19, NNZs: 30, Bias: -26290407277442.039062, T: 518400, Avg. loss: 205536167924725077876108125274112.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 109539793158149.17, NNZs: 30, Bias: -30175453010585.261719, T: 1036800, Avg. loss: 177030744631803318769366859776.000000\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 49885823800902.62, NNZs: 30, Bias: -25144246092027.535156, T: 1555200, Avg. loss: 58634736779918963178307846144.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 31515407341511.60, NNZs: 30, Bias: -19529581569406.410156, T: 2073600, Avg. loss: 29079167360666566887324254208.000000\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24118370379813.29, NNZs: 30, Bias: -14919353818591.718750, T: 2592000, Avg. loss: 17587794728370239082667704320.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19882968020837.12, NNZs: 30, Bias: -11328829877711.076172, T: 3110400, Avg. loss: 11604204310158786521773113344.000000\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16103728754875.62, NNZs: 30, Bias: -8654241185460.467773, T: 3628800, Avg. loss: 8349455598014607890581553152.000000\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 7 epochs took 1.79 seconds\n",
      "-- Epoch 1\n",
      "Norm: 320349174773129.19, NNZs: 30, Bias: -30276786338496.652344, T: 518400, Avg. loss: 174453218073788379408731379597312.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 105287359933400.70, NNZs: 30, Bias: -32405235298685.203125, T: 1036800, Avg. loss: 179053268741179659164338618368.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48952641796975.18, NNZs: 30, Bias: -26901936763607.824219, T: 1555200, Avg. loss: 59292143725300754477070942208.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 32306786402078.70, NNZs: 30, Bias: -20169491166657.828125, T: 2073600, Avg. loss: 29352131117444222488485560320.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 24855060030138.48, NNZs: 30, Bias: -15183276294776.939453, T: 2592000, Avg. loss: 17540351784958506099577716736.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 20459081446720.86, NNZs: 30, Bias: -11238425140716.263672, T: 3110400, Avg. loss: 11629241935798287319846354944.000000\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16975880810836.09, NNZs: 30, Bias: -8606659083518.435547, T: 3628800, Avg. loss: 8404931158689042620070494208.000000\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14653558704560.73, NNZs: 30, Bias: -6437246842408.700195, T: 4147200, Avg. loss: 6298283412478718663918092288.000000\n",
      "Total training time: 1.97 seconds.\n",
      "Convergence after 8 epochs took 2.07 seconds\n",
      "-- Epoch 1\n",
      "Norm: 105720230909656.05, NNZs: 30, Bias: -29712240117951.246094, T: 518400, Avg. loss: 188147960557180691192647264501760.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57192711304551.59, NNZs: 30, Bias: -23433623153895.960938, T: 1036800, Avg. loss: 174955118943433615674068434944.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38635056505736.75, NNZs: 30, Bias: -17628753500512.660156, T: 1555200, Avg. loss: 57982852167043836625100472320.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28117547130401.46, NNZs: 30, Bias: -13366429118859.509766, T: 2073600, Avg. loss: 29413017982044919950968094720.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22696734765268.75, NNZs: 30, Bias: -10445838672601.070312, T: 2592000, Avg. loss: 17352581364399839271561723904.000000\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18559126281148.91, NNZs: 30, Bias: -8177081738188.680664, T: 3110400, Avg. loss: 11804986487899898820077551616.000000\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16105685050773.32, NNZs: 30, Bias: -6716969472635.254883, T: 3628800, Avg. loss: 8387389703428068302536048640.000000\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14296668366257.34, NNZs: 30, Bias: -5217091675659.694336, T: 4147200, Avg. loss: 6231577028000650383465644032.000000\n",
      "Total training time: 2.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12439066779992.67, NNZs: 30, Bias: -4242439357251.878906, T: 4665600, Avg. loss: 4870021621736239526813106176.000000\n",
      "Total training time: 2.25 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11352430567697.92, NNZs: 30, Bias: -3318283031918.950684, T: 5184000, Avg. loss: 3871758180476322832288055296.000000\n",
      "Total training time: 2.52 seconds.\n",
      "Convergence after 10 epochs took 2.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 112683431240590.91, NNZs: 30, Bias: -48705062190316.390625, T: 518400, Avg. loss: 186298648409016188332103016906752.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57436292108552.73, NNZs: 30, Bias: -37319129533667.226562, T: 1036800, Avg. loss: 176492101359289734982679920640.000000\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38916059770290.73, NNZs: 30, Bias: -27185058195525.039062, T: 1555200, Avg. loss: 58814681571165868518528778240.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28781452359705.87, NNZs: 30, Bias: -19827943689806.902344, T: 2073600, Avg. loss: 29227503596098169181980065792.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 23437783721103.80, NNZs: 30, Bias: -14343136027976.974609, T: 2592000, Avg. loss: 17671941862393732754428657664.000000\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18996543098223.63, NNZs: 30, Bias: -10429971005809.478516, T: 3110400, Avg. loss: 11703174542005583299418783744.000000\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 15913056305796.52, NNZs: 30, Bias: -7968246485602.684570, T: 3628800, Avg. loss: 8379287364857957739873173504.000000\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 14075730096685.36, NNZs: 30, Bias: -6147332452756.765625, T: 4147200, Avg. loss: 6241611376765735897130860544.000000\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12208472372413.62, NNZs: 30, Bias: -4513812917670.696289, T: 4665600, Avg. loss: 4876269521372992134944129024.000000\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11035235582930.72, NNZs: 30, Bias: -3374156918928.909180, T: 5184000, Avg. loss: 3891908735442540900508499968.000000\n",
      "Total training time: 2.49 seconds.\n",
      "Convergence after 10 epochs took 2.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 109626239464403.09, NNZs: 30, Bias: -17130196358624.115234, T: 518400, Avg. loss: 168632753072850569424746676486144.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55359544742524.87, NNZs: 30, Bias: -14434870361718.960938, T: 1036800, Avg. loss: 176295553417346554221291372544.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38657005686926.39, NNZs: 30, Bias: -11436307043211.242188, T: 1555200, Avg. loss: 58415307625421135037287366656.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28290568479631.02, NNZs: 30, Bias: -8856081895064.421875, T: 2073600, Avg. loss: 29073854955879555497877045248.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21690538423917.91, NNZs: 30, Bias: -6941302533904.361328, T: 2592000, Avg. loss: 17553926023379248792630984704.000000\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18519311326920.10, NNZs: 30, Bias: -5354606287098.613281, T: 3110400, Avg. loss: 11759141029944283143581204480.000000\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16011761530715.88, NNZs: 30, Bias: -4262893077311.203125, T: 3628800, Avg. loss: 8245252254391484028941238272.000000\n",
      "Total training time: 1.74 seconds.\n",
      "Convergence after 7 epochs took 1.83 seconds\n",
      "-- Epoch 1\n",
      "Norm: 110665345385295.25, NNZs: 30, Bias: -15221737204570.818359, T: 518400, Avg. loss: 172189454150391026790584736022528.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 55065273771263.55, NNZs: 30, Bias: -13706718095443.525391, T: 1036800, Avg. loss: 174762598649116673163206328320.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 37747869756695.70, NNZs: 30, Bias: -11408159666185.611328, T: 1555200, Avg. loss: 58263772026745718613135589376.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28419170372689.54, NNZs: 30, Bias: -8928731844990.578125, T: 2073600, Avg. loss: 29193792107072959965076389888.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22700789410555.38, NNZs: 30, Bias: -7536760407786.057617, T: 2592000, Avg. loss: 17505858518379424425254584320.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18912882246785.73, NNZs: 30, Bias: -6204798960709.097656, T: 3110400, Avg. loss: 11687426325709183174567788544.000000\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16093545514094.66, NNZs: 30, Bias: -4699734170153.549805, T: 3628800, Avg. loss: 8360150032853517380087709696.000000\n",
      "Total training time: 1.68 seconds.\n",
      "Convergence after 7 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 106728041162275.75, NNZs: 30, Bias: -39658892276560.578125, T: 518400, Avg. loss: 209626023832968068727261345349632.000000\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 57980473253980.09, NNZs: 30, Bias: -30183181378888.046875, T: 1036800, Avg. loss: 174203391413150849832394424320.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 38141442153164.03, NNZs: 30, Bias: -21951673316961.855469, T: 1555200, Avg. loss: 58721130174684120920130322432.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 27497487757748.61, NNZs: 30, Bias: -16541498882959.197266, T: 2073600, Avg. loss: 29396220596269865472435945472.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 22895312687906.26, NNZs: 30, Bias: -12661642018058.994141, T: 2592000, Avg. loss: 17709873212476446197768257536.000000\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 18368016603183.83, NNZs: 30, Bias: -9154727018987.015625, T: 3110400, Avg. loss: 11750930414936621011188056064.000000\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.51 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.49, NNZs: 30, Bias: -23.786480, T: 518400, Avg. loss: 194.471350\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.27, NNZs: 30, Bias: -16.929381, T: 1036800, Avg. loss: 17.335776\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.15, NNZs: 30, Bias: -12.197846, T: 1555200, Avg. loss: 10.461818\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.03, NNZs: 30, Bias: -8.872234, T: 2073600, Avg. loss: 7.611770\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.29, NNZs: 30, Bias: -6.524389, T: 2592000, Avg. loss: 6.031849\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.73, NNZs: 30, Bias: -4.829066, T: 3110400, Avg. loss: 5.022744\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.61, NNZs: 30, Bias: 14.498557, T: 518400, Avg. loss: 188.955305\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.81, NNZs: 30, Bias: 9.735295, T: 1036800, Avg. loss: 17.253718\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.12, NNZs: 30, Bias: 6.621770, T: 1555200, Avg. loss: 10.325384\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.26, NNZs: 30, Bias: 4.562515, T: 2073600, Avg. loss: 7.535017\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.60, NNZs: 30, Bias: 3.161786, T: 2592000, Avg. loss: 5.996869\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.32, NNZs: 30, Bias: 2.205131, T: 3110400, Avg. loss: 4.996593\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.87, NNZs: 30, Bias: 6.610746, T: 518400, Avg. loss: 198.771854\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.69, NNZs: 30, Bias: 4.162729, T: 1036800, Avg. loss: 17.221259\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.22, NNZs: 30, Bias: 2.795846, T: 1555200, Avg. loss: 10.360724\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.13, NNZs: 30, Bias: 1.755876, T: 2073600, Avg. loss: 7.478957\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.66, NNZs: 30, Bias: 1.162185, T: 2592000, Avg. loss: 5.954199\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.37, NNZs: 30, Bias: 0.773158, T: 3110400, Avg. loss: 4.975177\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.01, NNZs: 30, Bias: -18.216313, T: 518400, Avg. loss: 192.942999\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.86, NNZs: 30, Bias: -12.899586, T: 1036800, Avg. loss: 17.309186\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.90, NNZs: 30, Bias: -9.272226, T: 1555200, Avg. loss: 10.458352\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.76, NNZs: 30, Bias: -6.775152, T: 2073600, Avg. loss: 7.590334\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.08, NNZs: 30, Bias: -4.984943, T: 2592000, Avg. loss: 6.016442\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.69, NNZs: 30, Bias: -3.694654, T: 3110400, Avg. loss: 5.009333\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.27, NNZs: 30, Bias: -2.776697, T: 3628800, Avg. loss: 4.328196\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 7 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.41, NNZs: 30, Bias: 10.084192, T: 518400, Avg. loss: 191.649437\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.96, NNZs: 30, Bias: 6.627971, T: 1036800, Avg. loss: 17.245673\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.09, NNZs: 30, Bias: 4.443745, T: 1555200, Avg. loss: 10.337679\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.07, NNZs: 30, Bias: 2.999252, T: 2073600, Avg. loss: 7.513367\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.63, NNZs: 30, Bias: 2.061026, T: 2592000, Avg. loss: 5.984398\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.30, NNZs: 30, Bias: 1.408272, T: 3110400, Avg. loss: 4.992653\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1594.50, NNZs: 22, Bias: -0.127727, T: 518400, Avg. loss: 138.317527\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1607.69, NNZs: 22, Bias: -0.155157, T: 1036800, Avg. loss: 1.461519\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1612.24, NNZs: 23, Bias: -0.074856, T: 1555200, Avg. loss: 0.969487\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1614.54, NNZs: 25, Bias: -0.145412, T: 2073600, Avg. loss: 0.868170\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1615.92, NNZs: 25, Bias: -0.114121, T: 2592000, Avg. loss: 0.821490\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1616.85, NNZs: 24, Bias: -0.101145, T: 3110400, Avg. loss: 0.803251\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1563.79, NNZs: 18, Bias: -0.058179, T: 518400, Avg. loss: 137.047281\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1577.33, NNZs: 22, Bias: -0.109048, T: 1036800, Avg. loss: 1.402455\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1581.96, NNZs: 23, Bias: -0.068047, T: 1555200, Avg. loss: 0.971111\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1584.30, NNZs: 23, Bias: -0.119253, T: 2073600, Avg. loss: 0.870675\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1585.71, NNZs: 23, Bias: -0.099836, T: 2592000, Avg. loss: 0.834576\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1586.66, NNZs: 23, Bias: -0.116650, T: 3110400, Avg. loss: 0.799935\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1593.80, NNZs: 21, Bias: -0.195513, T: 518400, Avg. loss: 130.783659\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1607.08, NNZs: 24, Bias: -0.118941, T: 1036800, Avg. loss: 1.406079\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1611.64, NNZs: 23, Bias: -0.117548, T: 1555200, Avg. loss: 0.970769\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1613.95, NNZs: 23, Bias: -0.104362, T: 2073600, Avg. loss: 0.854233\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1615.34, NNZs: 23, Bias: -0.138501, T: 2592000, Avg. loss: 0.830559\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1616.27, NNZs: 24, Bias: -0.125319, T: 3110400, Avg. loss: 0.798545\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1566.73, NNZs: 23, Bias: -0.122101, T: 518400, Avg. loss: 135.855353\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1580.21, NNZs: 22, Bias: -0.164064, T: 1036800, Avg. loss: 1.403463\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1584.87, NNZs: 22, Bias: -0.115953, T: 1555200, Avg. loss: 0.929365\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1587.21, NNZs: 23, Bias: -0.144824, T: 2073600, Avg. loss: 0.869390\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1588.62, NNZs: 22, Bias: -0.115242, T: 2592000, Avg. loss: 0.834335\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1589.57, NNZs: 25, Bias: -0.117480, T: 3110400, Avg. loss: 0.801053\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1590.25, NNZs: 24, Bias: -0.135690, T: 3628800, Avg. loss: 0.787792\n",
      "Total training time: 1.76 seconds.\n",
      "Convergence after 7 epochs took 1.86 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1576.11, NNZs: 20, Bias: -0.092132, T: 518400, Avg. loss: 128.811015\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1589.49, NNZs: 22, Bias: -0.080360, T: 1036800, Avg. loss: 1.417711\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1594.10, NNZs: 23, Bias: -0.140156, T: 1555200, Avg. loss: 0.961182\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1596.43, NNZs: 22, Bias: -0.121528, T: 2073600, Avg. loss: 0.865446\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1597.84, NNZs: 25, Bias: -0.111694, T: 2592000, Avg. loss: 0.828193\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1598.78, NNZs: 26, Bias: -0.094816, T: 3110400, Avg. loss: 0.792264\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 218.53, NNZs: 20, Bias: -0.194004, T: 518400, Avg. loss: 158.735990\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 183.33, NNZs: 24, Bias: -0.069816, T: 1036800, Avg. loss: 4.064770\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 161.19, NNZs: 24, Bias: -0.094178, T: 1555200, Avg. loss: 1.950129\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.73, NNZs: 23, Bias: -0.102766, T: 2073600, Avg. loss: 1.363351\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 134.13, NNZs: 26, Bias: -0.111276, T: 2592000, Avg. loss: 1.120125\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 125.02, NNZs: 26, Bias: -0.126554, T: 3110400, Avg. loss: 0.996286\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 117.59, NNZs: 25, Bias: -0.124588, T: 3628800, Avg. loss: 0.929602\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 7 epochs took 1.88 seconds\n",
      "-- Epoch 1\n",
      "Norm: 217.37, NNZs: 19, Bias: -0.174374, T: 518400, Avg. loss: 158.729315\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 182.72, NNZs: 22, Bias: -0.096861, T: 1036800, Avg. loss: 4.089888\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 161.01, NNZs: 23, Bias: -0.081647, T: 1555200, Avg. loss: 1.900749\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.66, NNZs: 24, Bias: -0.077085, T: 2073600, Avg. loss: 1.341486\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 134.07, NNZs: 24, Bias: -0.095983, T: 2592000, Avg. loss: 1.127880\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124.94, NNZs: 25, Bias: -0.082837, T: 3110400, Avg. loss: 1.002945\n",
      "Total training time: 1.51 seconds.\n",
      "Convergence after 6 epochs took 1.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 217.19, NNZs: 23, Bias: -0.029501, T: 518400, Avg. loss: 162.159951\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 182.73, NNZs: 21, Bias: -0.169114, T: 1036800, Avg. loss: 4.101066\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 160.74, NNZs: 24, Bias: -0.109524, T: 1555200, Avg. loss: 1.968175\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.40, NNZs: 22, Bias: -0.099337, T: 2073600, Avg. loss: 1.380050\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 133.87, NNZs: 26, Bias: -0.103984, T: 2592000, Avg. loss: 1.131427\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124.79, NNZs: 24, Bias: -0.084248, T: 3110400, Avg. loss: 1.003397\n",
      "Total training time: 1.48 seconds.\n",
      "Convergence after 6 epochs took 1.58 seconds\n",
      "-- Epoch 1\n",
      "Norm: 216.98, NNZs: 21, Bias: -0.162870, T: 518400, Avg. loss: 165.154558\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 182.80, NNZs: 20, Bias: -0.139180, T: 1036800, Avg. loss: 4.089394\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 160.89, NNZs: 24, Bias: -0.138758, T: 1555200, Avg. loss: 1.961798\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.50, NNZs: 25, Bias: -0.115587, T: 2073600, Avg. loss: 1.374827\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 133.95, NNZs: 23, Bias: -0.120681, T: 2592000, Avg. loss: 1.126135\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124.84, NNZs: 24, Bias: -0.135378, T: 3110400, Avg. loss: 1.008291\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 117.45, NNZs: 22, Bias: -0.143533, T: 3628800, Avg. loss: 0.933436\n",
      "Total training time: 1.85 seconds.\n",
      "Convergence after 7 epochs took 1.94 seconds\n",
      "-- Epoch 1\n",
      "Norm: 216.51, NNZs: 23, Bias: -0.211506, T: 518400, Avg. loss: 164.064604\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 182.72, NNZs: 23, Bias: -0.128564, T: 1036800, Avg. loss: 4.102788\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 160.92, NNZs: 24, Bias: -0.108702, T: 1555200, Avg. loss: 1.944938\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 145.51, NNZs: 22, Bias: -0.127874, T: 2073600, Avg. loss: 1.369685\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 133.94, NNZs: 25, Bias: -0.089482, T: 2592000, Avg. loss: 1.133011\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124.86, NNZs: 24, Bias: -0.126908, T: 3110400, Avg. loss: 1.004585\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 6 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.47, NNZs: 30, Bias: -31.037356, T: 518400, Avg. loss: 196.978986\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.47, NNZs: 30, Bias: -21.945632, T: 1036800, Avg. loss: 16.687014\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.29, NNZs: 30, Bias: -15.865333, T: 1555200, Avg. loss: 9.815038\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.09, NNZs: 30, Bias: -11.577708, T: 2073600, Avg. loss: 6.959669\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.27, NNZs: 30, Bias: -8.488070, T: 2592000, Avg. loss: 5.410117\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.69, NNZs: 30, Bias: -6.287353, T: 3110400, Avg. loss: 4.417518\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 6 epochs took 1.42 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.67, NNZs: 30, Bias: -9.007400, T: 518400, Avg. loss: 201.788798\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.92, NNZs: 30, Bias: -6.423791, T: 1036800, Avg. loss: 16.454390\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.10, NNZs: 30, Bias: -4.523097, T: 1555200, Avg. loss: 9.587803\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.24, NNZs: 30, Bias: -3.242840, T: 2073600, Avg. loss: 6.815548\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.63, NNZs: 30, Bias: -2.392248, T: 2592000, Avg. loss: 5.300577\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.18, NNZs: 30, Bias: -1.794902, T: 3110400, Avg. loss: 4.335196\n",
      "Total training time: 1.33 seconds.\n",
      "Convergence after 6 epochs took 1.42 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.06, NNZs: 30, Bias: -9.624795, T: 518400, Avg. loss: 184.823846\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.03, NNZs: 30, Bias: -6.729014, T: 1036800, Avg. loss: 16.529913\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.21, NNZs: 30, Bias: -4.810047, T: 1555200, Avg. loss: 9.621298\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.19, NNZs: 30, Bias: -3.442249, T: 2073600, Avg. loss: 6.852421\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.62, NNZs: 30, Bias: -2.528889, T: 2592000, Avg. loss: 5.312237\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.26, NNZs: 30, Bias: -1.889203, T: 3110400, Avg. loss: 4.317329\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.02, NNZs: 30, Bias: -1.421606, T: 3628800, Avg. loss: 3.691472\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 7 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.31, NNZs: 30, Bias: 2.259760, T: 518400, Avg. loss: 191.885224\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.39, NNZs: 30, Bias: 1.223532, T: 1036800, Avg. loss: 16.526414\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.75, NNZs: 30, Bias: 0.617723, T: 1555200, Avg. loss: 9.612850\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.05, NNZs: 30, Bias: 0.288504, T: 2073600, Avg. loss: 6.827888\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.51, NNZs: 30, Bias: 0.097673, T: 2592000, Avg. loss: 5.299510\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.12, NNZs: 30, Bias: -0.029092, T: 3110400, Avg. loss: 4.335324\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.91, NNZs: 30, Bias: -0.085513, T: 3628800, Avg. loss: 3.705740\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 7 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11.51, NNZs: 30, Bias: -18.035870, T: 518400, Avg. loss: 187.040411\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6.33, NNZs: 30, Bias: -12.698192, T: 1036800, Avg. loss: 16.633136\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.61, NNZs: 30, Bias: -9.083526, T: 1555200, Avg. loss: 9.669796\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3.51, NNZs: 30, Bias: -6.538248, T: 2073600, Avg. loss: 6.877862\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.81, NNZs: 30, Bias: -4.766743, T: 2592000, Avg. loss: 5.315638\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.38, NNZs: 30, Bias: -3.511645, T: 3110400, Avg. loss: 4.349265\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1521.20, NNZs: 22, Bias: -0.023399, T: 518400, Avg. loss: 127.240669\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1525.44, NNZs: 24, Bias: -0.044644, T: 1036800, Avg. loss: 0.694930\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1526.84, NNZs: 23, Bias: -0.075526, T: 1555200, Avg. loss: 0.618705\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1527.53, NNZs: 23, Bias: -0.067774, T: 2073600, Avg. loss: 0.603831\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1527.95, NNZs: 25, Bias: -0.064101, T: 2592000, Avg. loss: 0.598178\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1528.23, NNZs: 25, Bias: -0.059958, T: 3110400, Avg. loss: 0.594837\n",
      "Total training time: 1.75 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1523.84, NNZs: 23, Bias: -0.047804, T: 518400, Avg. loss: 121.278834\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1528.08, NNZs: 23, Bias: -0.055307, T: 1036800, Avg. loss: 0.683179\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1529.48, NNZs: 23, Bias: -0.085653, T: 1555200, Avg. loss: 0.616443\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1530.17, NNZs: 24, Bias: -0.067308, T: 2073600, Avg. loss: 0.606411\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1530.59, NNZs: 24, Bias: -0.058195, T: 2592000, Avg. loss: 0.600540\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1530.87, NNZs: 24, Bias: -0.056932, T: 3110400, Avg. loss: 0.596873\n",
      "Total training time: 1.68 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1511.01, NNZs: 24, Bias: -0.034487, T: 518400, Avg. loss: 131.745758\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1515.30, NNZs: 25, Bias: -0.054070, T: 1036800, Avg. loss: 0.696599\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1516.71, NNZs: 22, Bias: -0.055515, T: 1555200, Avg. loss: 0.617280\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1517.41, NNZs: 22, Bias: -0.054673, T: 2073600, Avg. loss: 0.611462\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1517.83, NNZs: 23, Bias: -0.049734, T: 2592000, Avg. loss: 0.601000\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1518.11, NNZs: 24, Bias: -0.067376, T: 3110400, Avg. loss: 0.596600\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1522.37, NNZs: 20, Bias: -0.092747, T: 518400, Avg. loss: 133.043443\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1526.62, NNZs: 25, Bias: -0.081789, T: 1036800, Avg. loss: 0.685542\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1528.02, NNZs: 22, Bias: -0.063129, T: 1555200, Avg. loss: 0.625487\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1528.72, NNZs: 24, Bias: -0.068408, T: 2073600, Avg. loss: 0.606094\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1529.13, NNZs: 24, Bias: -0.062967, T: 2592000, Avg. loss: 0.596785\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1529.41, NNZs: 24, Bias: -0.070357, T: 3110400, Avg. loss: 0.595553\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1529.22, NNZs: 22, Bias: -0.110964, T: 518400, Avg. loss: 124.308985\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1533.46, NNZs: 23, Bias: -0.095130, T: 1036800, Avg. loss: 0.701849\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1534.86, NNZs: 24, Bias: -0.057357, T: 1555200, Avg. loss: 0.618414\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1535.55, NNZs: 24, Bias: -0.058068, T: 2073600, Avg. loss: 0.611768\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1535.97, NNZs: 24, Bias: -0.052500, T: 2592000, Avg. loss: 0.594299\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1536.25, NNZs: 24, Bias: -0.062844, T: 3110400, Avg. loss: 0.593509\n",
      "Total training time: 1.76 seconds.\n",
      "Convergence after 6 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 172.00, NNZs: 23, Bias: -0.056122, T: 518400, Avg. loss: 152.522763\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.36, NNZs: 24, Bias: -0.104307, T: 1036800, Avg. loss: 1.264282\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.65, NNZs: 23, Bias: -0.059883, T: 1555200, Avg. loss: 0.797665\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.24, NNZs: 23, Bias: -0.069569, T: 2073600, Avg. loss: 0.686491\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 82.93, NNZs: 25, Bias: -0.071763, T: 2592000, Avg. loss: 0.646100\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.97, NNZs: 25, Bias: -0.067221, T: 3110400, Avg. loss: 0.625937\n",
      "Total training time: 1.83 seconds.\n",
      "Convergence after 6 epochs took 1.93 seconds\n",
      "-- Epoch 1\n",
      "Norm: 171.16, NNZs: 23, Bias: -0.151762, T: 518400, Avg. loss: 149.900713\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.01, NNZs: 22, Bias: -0.075643, T: 1036800, Avg. loss: 1.283010\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.44, NNZs: 25, Bias: -0.073025, T: 1555200, Avg. loss: 0.799409\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.10, NNZs: 25, Bias: -0.060576, T: 2073600, Avg. loss: 0.694318\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 82.81, NNZs: 23, Bias: -0.062813, T: 2592000, Avg. loss: 0.651479\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.87, NNZs: 24, Bias: -0.065625, T: 3110400, Avg. loss: 0.627898\n",
      "Total training time: 1.81 seconds.\n",
      "Convergence after 6 epochs took 1.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 171.14, NNZs: 21, Bias: -0.036423, T: 518400, Avg. loss: 155.726807\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.00, NNZs: 24, Bias: -0.077250, T: 1036800, Avg. loss: 1.271510\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.42, NNZs: 24, Bias: -0.074057, T: 1555200, Avg. loss: 0.803817\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.10, NNZs: 25, Bias: -0.059860, T: 2073600, Avg. loss: 0.691633\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 82.81, NNZs: 25, Bias: -0.068460, T: 2592000, Avg. loss: 0.649487\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.88, NNZs: 25, Bias: -0.065138, T: 3110400, Avg. loss: 0.625514\n",
      "Total training time: 1.69 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 172.37, NNZs: 21, Bias: -0.136140, T: 518400, Avg. loss: 154.877753\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.50, NNZs: 24, Bias: -0.097436, T: 1036800, Avg. loss: 1.277591\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.72, NNZs: 24, Bias: -0.096065, T: 1555200, Avg. loss: 0.802333\n",
      "Total training time: 0.81 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.30, NNZs: 24, Bias: -0.070023, T: 2073600, Avg. loss: 0.685519\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 82.96, NNZs: 25, Bias: -0.073695, T: 2592000, Avg. loss: 0.646590\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 76.00, NNZs: 24, Bias: -0.076205, T: 3110400, Avg. loss: 0.628065\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 6 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 171.35, NNZs: 22, Bias: -0.079022, T: 518400, Avg. loss: 160.178762\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 127.15, NNZs: 24, Bias: -0.085750, T: 1036800, Avg. loss: 1.294122\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.52, NNZs: 25, Bias: -0.063810, T: 1555200, Avg. loss: 0.811056\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 92.19, NNZs: 24, Bias: -0.052644, T: 2073600, Avg. loss: 0.688046\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 82.89, NNZs: 25, Bias: -0.070631, T: 2592000, Avg. loss: 0.645715\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 75.94, NNZs: 23, Bias: -0.061137, T: 3110400, Avg. loss: 0.631642\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 6 epochs took 1.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.33, NNZs: 30, Bias: 10.675462, T: 518400, Avg. loss: 194.389571\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.33, NNZs: 30, Bias: 7.017808, T: 1036800, Avg. loss: 16.639806\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.50, NNZs: 30, Bias: 4.603175, T: 1555200, Avg. loss: 9.775975\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.62, NNZs: 30, Bias: 3.008778, T: 2073600, Avg. loss: 6.906863\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.14, NNZs: 30, Bias: 1.997474, T: 2592000, Avg. loss: 5.348537\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.81, NNZs: 30, Bias: 1.304752, T: 3110400, Avg. loss: 4.360636\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.03, NNZs: 30, Bias: 6.476654, T: 518400, Avg. loss: 188.810764\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.30, NNZs: 30, Bias: 4.186929, T: 1036800, Avg. loss: 16.673911\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.71, NNZs: 30, Bias: 2.760353, T: 1555200, Avg. loss: 9.745213\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.66, NNZs: 30, Bias: 1.754824, T: 2073600, Avg. loss: 6.902216\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.22, NNZs: 30, Bias: 1.138326, T: 2592000, Avg. loss: 5.377214\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.82, NNZs: 30, Bias: 0.689047, T: 3110400, Avg. loss: 4.369058\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 6 epochs took 1.19 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12.66, NNZs: 30, Bias: -32.478969, T: 518400, Avg. loss: 191.921430\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 7.73, NNZs: 30, Bias: -22.970776, T: 1036800, Avg. loss: 16.989298\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.35, NNZs: 30, Bias: -16.505523, T: 1555200, Avg. loss: 9.978642\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.06, NNZs: 30, Bias: -11.869209, T: 2073600, Avg. loss: 7.085316\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 3.12, NNZs: 30, Bias: -8.530126, T: 2592000, Avg. loss: 5.473526\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.47, NNZs: 30, Bias: -6.112457, T: 3110400, Avg. loss: 4.459648\n",
      "Total training time: 1.11 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.38, NNZs: 30, Bias: 3.355569, T: 518400, Avg. loss: 185.724006\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.51, NNZs: 30, Bias: 1.928021, T: 1036800, Avg. loss: 16.553646\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.74, NNZs: 30, Bias: 1.074569, T: 1555200, Avg. loss: 9.738502\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.72, NNZs: 30, Bias: 0.590836, T: 2073600, Avg. loss: 6.906931\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.16, NNZs: 30, Bias: 0.269728, T: 2592000, Avg. loss: 5.340487\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.74, NNZs: 30, Bias: 0.109136, T: 3110400, Avg. loss: 4.376406\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10.38, NNZs: 30, Bias: -2.644126, T: 518400, Avg. loss: 188.717405\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.41, NNZs: 30, Bias: -2.115912, T: 1036800, Avg. loss: 16.681079\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.81, NNZs: 30, Bias: -1.669014, T: 1555200, Avg. loss: 9.698863\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.73, NNZs: 30, Bias: -1.281610, T: 2073600, Avg. loss: 6.922934\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.19, NNZs: 30, Bias: -0.895288, T: 2592000, Avg. loss: 5.344016\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.81, NNZs: 30, Bias: -0.654899, T: 3110400, Avg. loss: 4.347140\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.24 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1547.85, NNZs: 3, Bias: 0.001333, T: 518400, Avg. loss: 131.060382\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1555.83, NNZs: 4, Bias: 0.002115, T: 1036800, Avg. loss: 0.391067\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1558.54, NNZs: 10, Bias: -0.003216, T: 1555200, Avg. loss: 0.087050\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1559.88, NNZs: 2, Bias: 0.001410, T: 2073600, Avg. loss: 0.056504\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1560.70, NNZs: 6, Bias: -0.000822, T: 2592000, Avg. loss: 0.027862\n",
      "Total training time: 1.45 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1561.24, NNZs: 6, Bias: -0.002308, T: 3110400, Avg. loss: 0.019221\n",
      "Total training time: 1.72 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1561.63, NNZs: 5, Bias: -0.000066, T: 3628800, Avg. loss: 0.016411\n",
      "Total training time: 2.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1561.92, NNZs: 7, Bias: -0.000306, T: 4147200, Avg. loss: 0.009031\n",
      "Total training time: 2.35 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1562.15, NNZs: 8, Bias: -0.000063, T: 4665600, Avg. loss: 0.009479\n",
      "Total training time: 2.65 seconds.\n",
      "Convergence after 9 epochs took 2.74 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1552.79, NNZs: 10, Bias: -0.004478, T: 518400, Avg. loss: 128.668236\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1560.77, NNZs: 6, Bias: 0.002379, T: 1036800, Avg. loss: 0.384463\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1563.46, NNZs: 6, Bias: 0.000154, T: 1555200, Avg. loss: 0.104785\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1564.80, NNZs: 4, Bias: 0.001535, T: 2073600, Avg. loss: 0.066649\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1565.61, NNZs: 7, Bias: 0.001201, T: 2592000, Avg. loss: 0.017046\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1566.15, NNZs: 4, Bias: 0.000019, T: 3110400, Avg. loss: 0.027461\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1566.53, NNZs: 12, Bias: -0.000266, T: 3628800, Avg. loss: 0.024267\n",
      "Total training time: 1.88 seconds.\n",
      "Convergence after 7 epochs took 1.97 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1532.68, NNZs: 7, Bias: 0.006791, T: 518400, Avg. loss: 130.328941\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1540.73, NNZs: 4, Bias: -0.004571, T: 1036800, Avg. loss: 0.442121\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1543.44, NNZs: 4, Bias: 0.000712, T: 1555200, Avg. loss: 0.138015\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1544.80, NNZs: 6, Bias: 0.000464, T: 2073600, Avg. loss: 0.057695\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1545.63, NNZs: 4, Bias: -0.000421, T: 2592000, Avg. loss: 0.027473\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1546.17, NNZs: 5, Bias: -0.000695, T: 3110400, Avg. loss: 0.023694\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1546.92, NNZs: 5, Bias: 0.000079, T: 518400, Avg. loss: 128.302308\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1554.90, NNZs: 4, Bias: 0.000012, T: 1036800, Avg. loss: 0.390018\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1557.59, NNZs: 6, Bias: -0.003232, T: 1555200, Avg. loss: 0.139685\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1558.95, NNZs: 7, Bias: 0.000402, T: 2073600, Avg. loss: 0.073117\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1559.76, NNZs: 8, Bias: -0.001240, T: 2592000, Avg. loss: 0.032630\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1560.30, NNZs: 7, Bias: 0.001514, T: 3110400, Avg. loss: 0.020522\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1545.38, NNZs: 6, Bias: -0.003806, T: 518400, Avg. loss: 131.011852\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1553.41, NNZs: 4, Bias: -0.003109, T: 1036800, Avg. loss: 0.408469\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1556.11, NNZs: 5, Bias: -0.001486, T: 1555200, Avg. loss: 0.112484\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1557.46, NNZs: 3, Bias: -0.000674, T: 2073600, Avg. loss: 0.056556\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1558.28, NNZs: 8, Bias: -0.000940, T: 2592000, Avg. loss: 0.034653\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1558.82, NNZs: 6, Bias: -0.001103, T: 3110400, Avg. loss: 0.021541\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 6 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 192.42, NNZs: 3, Bias: 0.003556, T: 518400, Avg. loss: 150.238014\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 153.28, NNZs: 10, Bias: 0.001442, T: 1036800, Avg. loss: 2.147886\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.68, NNZs: 7, Bias: -0.000469, T: 1555200, Avg. loss: 0.687544\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 117.36, NNZs: 7, Bias: 0.001071, T: 2073600, Avg. loss: 0.344042\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106.97, NNZs: 5, Bias: -0.000346, T: 2592000, Avg. loss: 0.217714\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 98.99, NNZs: 9, Bias: -0.002894, T: 3110400, Avg. loss: 0.135941\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 192.06, NNZs: 12, Bias: -0.002904, T: 518400, Avg. loss: 159.024877\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 153.16, NNZs: 8, Bias: 0.003896, T: 1036800, Avg. loss: 2.134290\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.40, NNZs: 7, Bias: -0.003211, T: 1555200, Avg. loss: 0.720219\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 117.14, NNZs: 4, Bias: -0.000021, T: 2073600, Avg. loss: 0.352994\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106.79, NNZs: 10, Bias: -0.001207, T: 2592000, Avg. loss: 0.215624\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 98.84, NNZs: 9, Bias: -0.002962, T: 3110400, Avg. loss: 0.139730\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.69 seconds\n",
      "-- Epoch 1\n",
      "Norm: 192.62, NNZs: 9, Bias: 0.000343, T: 518400, Avg. loss: 155.710090\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 153.59, NNZs: 10, Bias: 0.000836, T: 1036800, Avg. loss: 2.153183\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.77, NNZs: 5, Bias: 0.000334, T: 1555200, Avg. loss: 0.756940\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 117.48, NNZs: 7, Bias: -0.001294, T: 2073600, Avg. loss: 0.342920\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 107.11, NNZs: 5, Bias: -0.001080, T: 2592000, Avg. loss: 0.203715\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 99.08, NNZs: 7, Bias: 0.000679, T: 3110400, Avg. loss: 0.140729\n",
      "Total training time: 1.56 seconds.\n",
      "Convergence after 6 epochs took 1.65 seconds\n",
      "-- Epoch 1\n",
      "Norm: 192.45, NNZs: 8, Bias: -0.005768, T: 518400, Avg. loss: 154.834214\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 153.41, NNZs: 9, Bias: -0.006263, T: 1036800, Avg. loss: 2.124972\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.70, NNZs: 3, Bias: -0.001045, T: 1555200, Avg. loss: 0.724369\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 117.31, NNZs: 5, Bias: -0.000369, T: 2073600, Avg. loss: 0.352665\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106.91, NNZs: 3, Bias: 0.000428, T: 2592000, Avg. loss: 0.197685\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 98.91, NNZs: 4, Bias: -0.001273, T: 3110400, Avg. loss: 0.142193\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 92.49, NNZs: 3, Bias: 0.000539, T: 3628800, Avg. loss: 0.107739\n",
      "Total training time: 1.99 seconds.\n",
      "Convergence after 7 epochs took 2.08 seconds\n",
      "-- Epoch 1\n",
      "Norm: 192.12, NNZs: 15, Bias: 0.014780, T: 518400, Avg. loss: 159.946069\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 153.45, NNZs: 9, Bias: -0.001705, T: 1036800, Avg. loss: 2.152794\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 131.67, NNZs: 5, Bias: -0.001935, T: 1555200, Avg. loss: 0.709215\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 117.32, NNZs: 5, Bias: -0.001998, T: 2073600, Avg. loss: 0.358783\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 106.95, NNZs: 6, Bias: -0.000489, T: 2592000, Avg. loss: 0.204724\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 98.94, NNZs: 10, Bias: 0.000219, T: 3110400, Avg. loss: 0.148235\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.74 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10102267298223.62, NNZs: 30, Bias: 2356856787641.397461, T: 518400, Avg. loss: 10937528486876277419337240805376.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5284319143865.50, NNZs: 30, Bias: 1405425520758.000244, T: 1036800, Avg. loss: 1761047509671334689244184576.000000\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3503862867767.67, NNZs: 30, Bias: 790421320764.455933, T: 1555200, Avg. loss: 579070719932876306350342144.000000\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2593475760874.48, NNZs: 30, Bias: 429062339726.438782, T: 2073600, Avg. loss: 291662150591789457140088832.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2052974581331.05, NNZs: 30, Bias: 212732832429.792542, T: 2592000, Avg. loss: 174138152395498933165490176.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1743899009127.76, NNZs: 30, Bias: 70557134738.262802, T: 3110400, Avg. loss: 115250608267492056622956544.000000\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1439276120869.36, NNZs: 30, Bias: 10272137279.196684, T: 3628800, Avg. loss: 81609940290151424043515904.000000\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 7 epochs took 1.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10361709136155.09, NNZs: 30, Bias: -1932114345933.867676, T: 518400, Avg. loss: 14704875304873452189408401817600.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5337949289610.61, NNZs: 30, Bias: -1497010876572.562256, T: 1036800, Avg. loss: 1766947010829568879951347712.000000\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3668789076953.50, NNZs: 30, Bias: -1143822785944.483154, T: 1555200, Avg. loss: 578593246836456008942878720.000000\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2698389452007.95, NNZs: 30, Bias: -930995712702.970337, T: 2073600, Avg. loss: 290802158472577875217219584.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2089748908945.63, NNZs: 30, Bias: -725220161255.978638, T: 2592000, Avg. loss: 173789701055391478960881664.000000\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1739318989459.06, NNZs: 30, Bias: -541010527018.619263, T: 3110400, Avg. loss: 115248773693884026738180096.000000\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10682846090494.23, NNZs: 30, Bias: 32391858782062.941406, T: 518400, Avg. loss: 9588169706132466225560422449152.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6136239694080.16, NNZs: 30, Bias: 22461726366367.085938, T: 1036800, Avg. loss: 1783704340735154593225244672.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4070729651558.88, NNZs: 30, Bias: 15768874533047.466797, T: 1555200, Avg. loss: 591148118491116751902736384.000000\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3030417318455.62, NNZs: 30, Bias: 11085708575039.929688, T: 2073600, Avg. loss: 296125279309440628518027264.000000\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2307339542780.86, NNZs: 30, Bias: 7750514493715.254883, T: 2592000, Avg. loss: 176277604834151095578132480.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1837154909756.29, NNZs: 30, Bias: 5329799273642.820312, T: 3110400, Avg. loss: 116151849225561866657333248.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1542932319839.61, NNZs: 30, Bias: 3671336725749.862305, T: 3628800, Avg. loss: 83502705867198780625911808.000000\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 7 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10725563831675.76, NNZs: 30, Bias: -6592475239551.246094, T: 518400, Avg. loss: 11434149326355959957508600102912.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5758959123289.22, NNZs: 30, Bias: -4762955538604.959961, T: 1036800, Avg. loss: 1741715603921040412210364416.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3708641189426.87, NNZs: 30, Bias: -3351466781417.926270, T: 1555200, Avg. loss: 580895087088957620460978176.000000\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2836114076376.87, NNZs: 30, Bias: -2380869845981.489258, T: 2073600, Avg. loss: 291218672115583080416149504.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2182266205754.41, NNZs: 30, Bias: -1703355589338.965576, T: 2592000, Avg. loss: 176171644531996693261975552.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1766838398087.88, NNZs: 30, Bias: -1197021626169.092285, T: 3110400, Avg. loss: 115754231945208566527295488.000000\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1465576103115.26, NNZs: 30, Bias: -868703697400.973267, T: 3628800, Avg. loss: 82985554088433379207806976.000000\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 7 epochs took 1.37 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10776576536065.30, NNZs: 30, Bias: -6422476281628.542969, T: 518400, Avg. loss: 13676815130729654250855699841024.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5628515856791.11, NNZs: 30, Bias: -4657681839734.948242, T: 1036800, Avg. loss: 1764026195620845723852996608.000000\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3806066655769.85, NNZs: 30, Bias: -3306665984877.030273, T: 1555200, Avg. loss: 586103550499160374412050432.000000\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2756325243782.14, NNZs: 30, Bias: -2389264040097.441895, T: 2073600, Avg. loss: 291808017633877512410890240.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2176068717807.76, NNZs: 30, Bias: -1689745787182.495605, T: 2592000, Avg. loss: 172902850800935567188033536.000000\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1758569744313.46, NNZs: 30, Bias: -1191546555907.668213, T: 3110400, Avg. loss: 115898348754522426453262336.000000\n",
      "Total training time: 1.05 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 36906603413587.46, NNZs: 30, Bias: 6263862085284.546875, T: 518400, Avg. loss: 9273127559280502415641819480064.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11335871531630.63, NNZs: 30, Bias: 3178143003018.550781, T: 1036800, Avg. loss: 1779615015148075395080781824.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4663343229171.77, NNZs: 30, Bias: 1837812026286.903564, T: 1555200, Avg. loss: 586076372428842933055127552.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3034834253654.23, NNZs: 30, Bias: 1029455520724.639038, T: 2073600, Avg. loss: 293660198579413633841758208.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2174657229413.95, NNZs: 30, Bias: 589998979439.205811, T: 2592000, Avg. loss: 174525517492006447977857024.000000\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1791236587689.82, NNZs: 30, Bias: 282625984541.253479, T: 3110400, Avg. loss: 114466133393931055008841728.000000\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1546961847912.14, NNZs: 30, Bias: 132403396429.184647, T: 3628800, Avg. loss: 81823120250567150329135104.000000\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1305576148244.28, NNZs: 30, Bias: 18728054487.284222, T: 4147200, Avg. loss: 61113276661252756443496448.000000\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1147600004544.94, NNZs: 30, Bias: -41345203075.210075, T: 4665600, Avg. loss: 47899624613171395267919872.000000\n",
      "Total training time: 2.15 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1051651405317.61, NNZs: 30, Bias: -62810766398.787483, T: 5184000, Avg. loss: 37840819015993610911875072.000000\n",
      "Total training time: 2.39 seconds.\n",
      "Convergence after 10 epochs took 2.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 54189332390689.78, NNZs: 30, Bias: 1534915106226.508789, T: 518400, Avg. loss: 11440992533077537481341806837760.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16779773010297.76, NNZs: 30, Bias: -647480183550.447388, T: 1036800, Avg. loss: 1861719889957917001611476992.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5820746046813.64, NNZs: 30, Bias: -1045449852610.058350, T: 1555200, Avg. loss: 590213178856960231670284288.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3137787566544.10, NNZs: 30, Bias: -926623611440.953003, T: 2073600, Avg. loss: 290820158288465230160723968.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2355553662256.71, NNZs: 30, Bias: -756754097425.890259, T: 2592000, Avg. loss: 172996098790936384955744256.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1885443514548.90, NNZs: 30, Bias: -588842571267.318237, T: 3110400, Avg. loss: 115744342552732346691354624.000000\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1539463267978.19, NNZs: 30, Bias: -460851174728.514526, T: 3628800, Avg. loss: 82501316334479903077433344.000000\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 7 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 40601886346597.75, NNZs: 30, Bias: 1895588992451.127686, T: 518400, Avg. loss: 11738988110023950291507628474368.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12478646606044.78, NNZs: 30, Bias: 172398423277.106323, T: 1036800, Avg. loss: 1803802651048909459647627264.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5027132128339.30, NNZs: 30, Bias: -257543109915.324066, T: 1555200, Avg. loss: 591390882683418363455078400.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3065887824492.90, NNZs: 30, Bias: -320294608082.560791, T: 2073600, Avg. loss: 291584285907171089928159232.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2292618329413.34, NNZs: 30, Bias: -328524696033.450562, T: 2592000, Avg. loss: 172541186050531324204154880.000000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1834480081637.36, NNZs: 30, Bias: -252267548077.320099, T: 3110400, Avg. loss: 114688718024070751313723392.000000\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 45398185256899.71, NNZs: 30, Bias: -6784965930654.563477, T: 518400, Avg. loss: 9373340332890296135019634098176.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13987385230327.61, NNZs: 30, Bias: -6548147902948.047852, T: 1036800, Avg. loss: 1844764913642547276293341184.000000\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5524849551120.24, NNZs: 30, Bias: -5128769214266.590820, T: 1555200, Avg. loss: 587981610904350430687395840.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3364595464422.67, NNZs: 30, Bias: -3769412139893.398926, T: 2073600, Avg. loss: 290184350512346342728138752.000000\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2511250005314.94, NNZs: 30, Bias: -2708363353997.479492, T: 2592000, Avg. loss: 174549160015168061512351744.000000\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1986059290349.65, NNZs: 30, Bias: -1901933974200.064453, T: 3110400, Avg. loss: 115519139413745806560198656.000000\n",
      "Total training time: 1.49 seconds.\n",
      "Convergence after 6 epochs took 1.58 seconds\n",
      "-- Epoch 1\n",
      "Norm: 42256599734207.09, NNZs: 30, Bias: -11307600674914.642578, T: 518400, Avg. loss: 8950569197413044395414141272064.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13106719389672.36, NNZs: 30, Bias: -9947144672882.421875, T: 1036800, Avg. loss: 1817803360389064764631810048.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5625577173296.08, NNZs: 30, Bias: -7562582262410.849609, T: 1555200, Avg. loss: 586121382359715002043072512.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3493689697419.75, NNZs: 30, Bias: -5481183932727.375000, T: 2073600, Avg. loss: 290179124910249014252797952.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2588837523002.90, NNZs: 30, Bias: -3910165572226.206055, T: 2592000, Avg. loss: 174286042314424266690396160.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2120296172821.03, NNZs: 30, Bias: -2771348459692.211914, T: 3110400, Avg. loss: 115347121344362479689400320.000000\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10832372622541.14, NNZs: 30, Bias: 4008116160656.772461, T: 518400, Avg. loss: 11283879406716673791066634190848.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5363255038694.42, NNZs: 30, Bias: 2425252664892.116211, T: 1036800, Avg. loss: 1736130175434421209135054848.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3526338801989.09, NNZs: 30, Bias: 1476001730353.404053, T: 1555200, Avg. loss: 577324117746619242770333696.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2615226361300.43, NNZs: 30, Bias: 910524519177.838013, T: 2073600, Avg. loss: 287136504724826861428801536.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2143597628373.22, NNZs: 30, Bias: 581376336123.180054, T: 2592000, Avg. loss: 172720572931826156029607936.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1710071367479.88, NNZs: 30, Bias: 290818459525.607971, T: 3110400, Avg. loss: 114968642568598156333809664.000000\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1497829016538.93, NNZs: 30, Bias: 138008961203.039520, T: 3628800, Avg. loss: 82861712983424980194689024.000000\n",
      "Total training time: 1.62 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1267041546472.72, NNZs: 30, Bias: 33556058183.224007, T: 4147200, Avg. loss: 60999416710573530615382016.000000\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1115214596737.77, NNZs: 30, Bias: -12766753454.519938, T: 4665600, Avg. loss: 47227403956484709363482624.000000\n",
      "Total training time: 2.12 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 987201703799.95, NNZs: 30, Bias: -49401147581.732681, T: 5184000, Avg. loss: 37982988031193298346442752.000000\n",
      "Total training time: 2.38 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 922325317111.26, NNZs: 30, Bias: -65231978418.371300, T: 5702400, Avg. loss: 30626846811595194712981504.000000\n",
      "Total training time: 2.62 seconds.\n",
      "Convergence after 11 epochs took 2.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11132259669230.09, NNZs: 30, Bias: 4490642242274.268555, T: 518400, Avg. loss: 11478773041918670348892059467776.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5586124687463.59, NNZs: 30, Bias: 2761977832927.471191, T: 1036800, Avg. loss: 1754501057379137593567870976.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3514985037844.42, NNZs: 30, Bias: 1779294435101.323242, T: 1555200, Avg. loss: 583025821963688525955072000.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2559653599217.28, NNZs: 30, Bias: 1062758202619.885376, T: 2073600, Avg. loss: 290725744053281275447869440.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2094616649930.90, NNZs: 30, Bias: 608041265847.829712, T: 2592000, Avg. loss: 173026214217986510986149888.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1766900843243.73, NNZs: 30, Bias: 312321129738.477478, T: 3110400, Avg. loss: 114871748936070876853436416.000000\n",
      "Total training time: 1.36 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12002600684952.53, NNZs: 30, Bias: -18220929086028.699219, T: 518400, Avg. loss: 7877765940288060850467822895104.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6714113972071.48, NNZs: 30, Bias: -12723354300010.085938, T: 1036800, Avg. loss: 1780938433197453719956881408.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4351319283647.62, NNZs: 30, Bias: -8856515337496.097656, T: 1555200, Avg. loss: 594932600010969559563501568.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3252467532030.92, NNZs: 30, Bias: -6208441278315.613281, T: 2073600, Avg. loss: 293707484136682147721248768.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2570042071053.72, NNZs: 30, Bias: -4364680893784.793945, T: 2592000, Avg. loss: 175880264304366796115279872.000000\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1983964736726.44, NNZs: 30, Bias: -3040332079692.040527, T: 3110400, Avg. loss: 117050795246347036670296064.000000\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 11484475928330.32, NNZs: 30, Bias: -15544183664093.173828, T: 518400, Avg. loss: 8684597363832985963236499128320.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6369476998200.78, NNZs: 30, Bias: -10864959051138.349609, T: 1036800, Avg. loss: 1758323991651695709493657600.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4275903447906.95, NNZs: 30, Bias: -7702704586146.515625, T: 1555200, Avg. loss: 585228224492402668946325504.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 3196099009239.34, NNZs: 30, Bias: -5413164301496.696289, T: 2073600, Avg. loss: 293852791243345543810777088.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2437421597460.69, NNZs: 30, Bias: -3779874109754.690430, T: 2592000, Avg. loss: 175106523605256179235684352.000000\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1895306004086.19, NNZs: 30, Bias: -2685637879158.220215, T: 3110400, Avg. loss: 115503361432486633311043584.000000\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1580241921084.90, NNZs: 30, Bias: -1904805276155.531982, T: 3628800, Avg. loss: 82565374182306189924106240.000000\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1359699264155.51, NNZs: 30, Bias: -1327077711755.759766, T: 4147200, Avg. loss: 61906503593395683181199360.000000\n",
      "Total training time: 1.90 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1162644883422.36, NNZs: 30, Bias: -920976746406.767212, T: 4665600, Avg. loss: 47954811054872899574824960.000000\n",
      "Total training time: 2.15 seconds.\n",
      "Convergence after 9 epochs took 2.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 10536390529744.99, NNZs: 30, Bias: 15784898135795.873047, T: 518400, Avg. loss: 11406897943435208514209849540608.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5424789728614.76, NNZs: 30, Bias: 10372649656076.482422, T: 1036800, Avg. loss: 1754453630576305850093142016.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3446066980795.22, NNZs: 30, Bias: 6922145270534.345703, T: 1555200, Avg. loss: 582347950028463263834963968.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2545028133684.53, NNZs: 30, Bias: 4570679755026.242188, T: 2073600, Avg. loss: 291571910886355860080033792.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2074911153664.16, NNZs: 30, Bias: 2970453778394.798340, T: 2592000, Avg. loss: 175099627954897875051216896.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1701310794921.95, NNZs: 30, Bias: 1939747541114.706055, T: 3110400, Avg. loss: 116525975386497728806649856.000000\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.92, NNZs: 30, Bias: -6.709032, T: 518400, Avg. loss: 23.655330\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.44, NNZs: 30, Bias: -5.226034, T: 1036800, Avg. loss: 2.383704\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.21, NNZs: 30, Bias: -4.281097, T: 1555200, Avg. loss: 1.691968\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.07, NNZs: 30, Bias: -3.608886, T: 2073600, Avg. loss: 1.414248\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.98, NNZs: 30, Bias: -3.108793, T: 2592000, Avg. loss: 1.260514\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.91, NNZs: 30, Bias: -2.722475, T: 3110400, Avg. loss: 1.162710\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.49, NNZs: 30, Bias: -1.235303, T: 518400, Avg. loss: 22.913827\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.02, NNZs: 30, Bias: -0.958247, T: 1036800, Avg. loss: 2.295179\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.90, NNZs: 30, Bias: -0.792755, T: 1555200, Avg. loss: 1.620839\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.80, NNZs: 30, Bias: -0.675828, T: 2073600, Avg. loss: 1.358496\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.76, NNZs: 30, Bias: -0.591465, T: 2592000, Avg. loss: 1.212798\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.72, NNZs: 30, Bias: -0.524044, T: 3110400, Avg. loss: 1.126574\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.70, NNZs: 30, Bias: -0.475614, T: 3628800, Avg. loss: 1.067685\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 7 epochs took 1.37 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.43, NNZs: 30, Bias: -1.341730, T: 518400, Avg. loss: 24.327530\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.04, NNZs: 30, Bias: -1.039192, T: 1036800, Avg. loss: 2.300789\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.86, NNZs: 30, Bias: -0.849533, T: 1555200, Avg. loss: 1.630275\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.80, NNZs: 30, Bias: -0.724885, T: 2073600, Avg. loss: 1.361735\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.76, NNZs: 30, Bias: -0.629091, T: 2592000, Avg. loss: 1.216402\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.72, NNZs: 30, Bias: -0.560524, T: 3110400, Avg. loss: 1.126486\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.03, NNZs: 30, Bias: -7.495727, T: 518400, Avg. loss: 23.589323\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.51, NNZs: 30, Bias: -5.886286, T: 1036800, Avg. loss: 2.402165\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.26, NNZs: 30, Bias: -4.849442, T: 1555200, Avg. loss: 1.721480\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.14, NNZs: 30, Bias: -4.100724, T: 2073600, Avg. loss: 1.431241\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.03, NNZs: 30, Bias: -3.545245, T: 2592000, Avg. loss: 1.274272\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.95, NNZs: 30, Bias: -3.107923, T: 3110400, Avg. loss: 1.173852\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.22 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.42, NNZs: 30, Bias: 0.911589, T: 518400, Avg. loss: 24.309943\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.96, NNZs: 30, Bias: 0.666568, T: 1036800, Avg. loss: 2.301320\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.84, NNZs: 30, Bias: 0.501016, T: 1555200, Avg. loss: 1.627236\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.76, NNZs: 30, Bias: 0.392986, T: 2073600, Avg. loss: 1.358120\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.71, NNZs: 30, Bias: 0.315654, T: 2592000, Avg. loss: 1.219753\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.69, NNZs: 30, Bias: 0.256744, T: 3110400, Avg. loss: 1.129216\n",
      "Total training time: 1.14 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 486.26, NNZs: 19, Bias: 0.205940, T: 518400, Avg. loss: 14.285984\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 486.72, NNZs: 21, Bias: 0.146883, T: 1036800, Avg. loss: 0.836009\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 486.88, NNZs: 22, Bias: 0.137571, T: 1555200, Avg. loss: 0.790744\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 486.96, NNZs: 22, Bias: 0.092929, T: 2073600, Avg. loss: 0.780619\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 487.01, NNZs: 22, Bias: 0.069009, T: 2592000, Avg. loss: 0.776611\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 487.04, NNZs: 22, Bias: 0.054014, T: 3110400, Avg. loss: 0.774436\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 482.47, NNZs: 19, Bias: -0.190309, T: 518400, Avg. loss: 13.707070\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 482.94, NNZs: 21, Bias: -0.174458, T: 1036800, Avg. loss: 0.823475\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 483.09, NNZs: 22, Bias: -0.148599, T: 1555200, Avg. loss: 0.799886\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 483.17, NNZs: 22, Bias: -0.132311, T: 2073600, Avg. loss: 0.786362\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 483.22, NNZs: 22, Bias: -0.121070, T: 2592000, Avg. loss: 0.781727\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 483.25, NNZs: 23, Bias: -0.116311, T: 3110400, Avg. loss: 0.778565\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 474.31, NNZs: 19, Bias: -0.150785, T: 518400, Avg. loss: 13.010357\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 474.79, NNZs: 19, Bias: -0.128400, T: 1036800, Avg. loss: 0.810268\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 474.95, NNZs: 19, Bias: -0.131277, T: 1555200, Avg. loss: 0.793158\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 475.04, NNZs: 19, Bias: -0.122219, T: 2073600, Avg. loss: 0.784178\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 475.08, NNZs: 20, Bias: -0.122954, T: 2592000, Avg. loss: 0.781608\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 475.12, NNZs: 19, Bias: -0.123928, T: 3110400, Avg. loss: 0.777992\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 479.60, NNZs: 21, Bias: 0.034187, T: 518400, Avg. loss: 15.963841\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 480.08, NNZs: 22, Bias: -0.011599, T: 1036800, Avg. loss: 0.808495\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 480.24, NNZs: 22, Bias: -0.063255, T: 1555200, Avg. loss: 0.785339\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 480.32, NNZs: 23, Bias: -0.091291, T: 2073600, Avg. loss: 0.780328\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 480.37, NNZs: 22, Bias: -0.099501, T: 2592000, Avg. loss: 0.775892\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 480.40, NNZs: 22, Bias: -0.106999, T: 3110400, Avg. loss: 0.772616\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 472.78, NNZs: 20, Bias: -0.107256, T: 518400, Avg. loss: 12.086880\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 473.26, NNZs: 21, Bias: -0.123986, T: 1036800, Avg. loss: 0.825970\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 473.42, NNZs: 21, Bias: -0.131542, T: 1555200, Avg. loss: 0.792523\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 473.50, NNZs: 21, Bias: -0.135792, T: 2073600, Avg. loss: 0.781993\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 473.55, NNZs: 21, Bias: -0.130817, T: 2592000, Avg. loss: 0.775697\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 473.58, NNZs: 21, Bias: -0.131429, T: 3110400, Avg. loss: 0.773733\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 32.05, NNZs: 24, Bias: 0.047494, T: 518400, Avg. loss: 16.253436\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.73, NNZs: 24, Bias: -0.004016, T: 1036800, Avg. loss: 0.795263\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.74, NNZs: 24, Bias: -0.022575, T: 1555200, Avg. loss: 0.772891\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.28, NNZs: 24, Bias: -0.035178, T: 2073600, Avg. loss: 0.764192\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.56, NNZs: 24, Bias: -0.038241, T: 2592000, Avg. loss: 0.761036\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.28, NNZs: 24, Bias: -0.039271, T: 3110400, Avg. loss: 0.760482\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.52 seconds\n",
      "-- Epoch 1\n",
      "Norm: 31.94, NNZs: 24, Bias: -0.015616, T: 518400, Avg. loss: 18.052114\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.66, NNZs: 24, Bias: -0.038017, T: 1036800, Avg. loss: 0.797717\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.70, NNZs: 25, Bias: -0.053083, T: 1555200, Avg. loss: 0.771565\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.25, NNZs: 25, Bias: -0.061638, T: 2073600, Avg. loss: 0.763865\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.54, NNZs: 25, Bias: -0.068658, T: 2592000, Avg. loss: 0.760547\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.26, NNZs: 25, Bias: -0.072875, T: 3110400, Avg. loss: 0.759741\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 31.85, NNZs: 24, Bias: 0.559909, T: 518400, Avg. loss: 16.777879\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.65, NNZs: 24, Bias: 0.201641, T: 1036800, Avg. loss: 0.797391\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.70, NNZs: 25, Bias: 0.097757, T: 1555200, Avg. loss: 0.772302\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.25, NNZs: 25, Bias: 0.049194, T: 2073600, Avg. loss: 0.765891\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.54, NNZs: 25, Bias: 0.023287, T: 2592000, Avg. loss: 0.762756\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.26, NNZs: 25, Bias: 0.006534, T: 3110400, Avg. loss: 0.762034\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.58 seconds\n",
      "-- Epoch 1\n",
      "Norm: 32.06, NNZs: 25, Bias: 0.044652, T: 518400, Avg. loss: 14.729849\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.74, NNZs: 24, Bias: -0.019383, T: 1036800, Avg. loss: 0.799179\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.76, NNZs: 25, Bias: -0.033065, T: 1555200, Avg. loss: 0.768653\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.30, NNZs: 24, Bias: -0.034091, T: 2073600, Avg. loss: 0.764374\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.59, NNZs: 24, Bias: -0.041816, T: 2592000, Avg. loss: 0.761650\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.30, NNZs: 24, Bias: -0.044565, T: 3110400, Avg. loss: 0.760134\n",
      "Total training time: 1.47 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 31.81, NNZs: 23, Bias: 0.509701, T: 518400, Avg. loss: 16.434071\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 23.61, NNZs: 25, Bias: 0.168511, T: 1036800, Avg. loss: 0.803072\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.68, NNZs: 24, Bias: 0.073883, T: 1555200, Avg. loss: 0.771998\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.24, NNZs: 24, Bias: 0.030361, T: 2073600, Avg. loss: 0.764520\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 15.54, NNZs: 23, Bias: 0.005942, T: 2592000, Avg. loss: 0.761803\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.26, NNZs: 24, Bias: -0.011416, T: 3110400, Avg. loss: 0.759997\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.37, NNZs: 30, Bias: 4.481287, T: 518400, Avg. loss: 23.954679\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 30, Bias: 3.462366, T: 1036800, Avg. loss: 1.811080\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.75, NNZs: 30, Bias: 2.825791, T: 1555200, Avg. loss: 1.203533\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.67, NNZs: 30, Bias: 2.389182, T: 2073600, Avg. loss: 0.977598\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.60, NNZs: 30, Bias: 2.068361, T: 2592000, Avg. loss: 0.861808\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 30, Bias: 1.824094, T: 3110400, Avg. loss: 0.795549\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.54, NNZs: 30, Bias: 1.631681, T: 3628800, Avg. loss: 0.753406\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 7 epochs took 1.61 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.68, NNZs: 30, Bias: -5.813500, T: 518400, Avg. loss: 22.239936\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.22, NNZs: 30, Bias: -4.554974, T: 1036800, Avg. loss: 1.827220\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.03, NNZs: 30, Bias: -3.765111, T: 1555200, Avg. loss: 1.221295\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.90, NNZs: 30, Bias: -3.225067, T: 2073600, Avg. loss: 0.991550\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.82, NNZs: 30, Bias: -2.820184, T: 2592000, Avg. loss: 0.879373\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.77, NNZs: 30, Bias: -2.508885, T: 3110400, Avg. loss: 0.807757\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.72, NNZs: 30, Bias: -2.265253, T: 3628800, Avg. loss: 0.763687\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 7 epochs took 1.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.71, NNZs: 30, Bias: 9.028212, T: 518400, Avg. loss: 24.024321\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.24, NNZs: 30, Bias: 7.148788, T: 1036800, Avg. loss: 1.919846\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.03, NNZs: 30, Bias: 5.960466, T: 1555200, Avg. loss: 1.302106\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.89, NNZs: 30, Bias: 5.126683, T: 2073600, Avg. loss: 1.057056\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.80, NNZs: 30, Bias: 4.501143, T: 2592000, Avg. loss: 0.929147\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.73, NNZs: 30, Bias: 4.014370, T: 3110400, Avg. loss: 0.850809\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2.41, NNZs: 30, Bias: -11.876105, T: 518400, Avg. loss: 24.431713\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.89, NNZs: 30, Bias: -9.613768, T: 1036800, Avg. loss: 2.015373\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.60, NNZs: 30, Bias: -8.167153, T: 1555200, Avg. loss: 1.388130\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.43, NNZs: 30, Bias: -7.126206, T: 2073600, Avg. loss: 1.137930\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.29, NNZs: 30, Bias: -6.339790, T: 2592000, Avg. loss: 0.994421\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.18, NNZs: 30, Bias: -5.717400, T: 3110400, Avg. loss: 0.910513\n",
      "Total training time: 1.29 seconds.\n",
      "Convergence after 6 epochs took 1.38 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.35, NNZs: 30, Bias: -1.970409, T: 518400, Avg. loss: 24.066813\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.94, NNZs: 30, Bias: -1.548181, T: 1036800, Avg. loss: 1.780278\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.79, NNZs: 30, Bias: -1.279743, T: 1555200, Avg. loss: 1.178163\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.70, NNZs: 30, Bias: -1.100924, T: 2073600, Avg. loss: 0.957862\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.64, NNZs: 30, Bias: -0.967251, T: 2592000, Avg. loss: 0.848699\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.61, NNZs: 30, Bias: -0.861315, T: 3110400, Avg. loss: 0.786727\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 473.71, NNZs: 16, Bias: 0.014562, T: 518400, Avg. loss: 13.086383\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 473.85, NNZs: 18, Bias: 0.018165, T: 1036800, Avg. loss: 0.617416\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 473.89, NNZs: 18, Bias: 0.020306, T: 1555200, Avg. loss: 0.608806\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 473.92, NNZs: 18, Bias: 0.019863, T: 2073600, Avg. loss: 0.603793\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 473.93, NNZs: 18, Bias: 0.019614, T: 2592000, Avg. loss: 0.601722\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 473.94, NNZs: 18, Bias: 0.019985, T: 3110400, Avg. loss: 0.600196\n",
      "Total training time: 1.81 seconds.\n",
      "Convergence after 6 epochs took 1.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 467.11, NNZs: 17, Bias: 0.369679, T: 518400, Avg. loss: 12.105575\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 467.25, NNZs: 17, Bias: 0.347567, T: 1036800, Avg. loss: 0.617597\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 467.30, NNZs: 17, Bias: 0.345998, T: 1555200, Avg. loss: 0.608937\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 467.32, NNZs: 19, Bias: 0.322545, T: 2073600, Avg. loss: 0.605029\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 467.34, NNZs: 19, Bias: 0.267636, T: 2592000, Avg. loss: 0.601646\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 467.34, NNZs: 19, Bias: 0.238820, T: 3110400, Avg. loss: 0.600707\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 6 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 462.78, NNZs: 16, Bias: 0.091034, T: 518400, Avg. loss: 11.754035\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 462.92, NNZs: 17, Bias: 0.065911, T: 1036800, Avg. loss: 0.618605\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 462.96, NNZs: 18, Bias: 0.037047, T: 1555200, Avg. loss: 0.609415\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 462.99, NNZs: 19, Bias: 0.033056, T: 2073600, Avg. loss: 0.604167\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 463.00, NNZs: 19, Bias: 0.030598, T: 2592000, Avg. loss: 0.602565\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 463.01, NNZs: 18, Bias: 0.031361, T: 3110400, Avg. loss: 0.600572\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 6 epochs took 1.81 seconds\n",
      "-- Epoch 1\n",
      "Norm: 472.64, NNZs: 18, Bias: -0.103826, T: 518400, Avg. loss: 12.536722\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 472.77, NNZs: 18, Bias: -0.097000, T: 1036800, Avg. loss: 0.619529\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 472.82, NNZs: 18, Bias: -0.090852, T: 1555200, Avg. loss: 0.608298\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 472.84, NNZs: 18, Bias: -0.091520, T: 2073600, Avg. loss: 0.604380\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 472.85, NNZs: 19, Bias: -0.080247, T: 2592000, Avg. loss: 0.602068\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 472.86, NNZs: 19, Bias: -0.070544, T: 3110400, Avg. loss: 0.600541\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 6 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 457.10, NNZs: 18, Bias: 0.127576, T: 518400, Avg. loss: 12.877213\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 457.24, NNZs: 20, Bias: 0.048854, T: 1036800, Avg. loss: 0.624767\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 457.29, NNZs: 20, Bias: 0.022330, T: 1555200, Avg. loss: 0.613689\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 457.31, NNZs: 21, Bias: 0.011587, T: 2073600, Avg. loss: 0.607959\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 457.32, NNZs: 21, Bias: 0.002493, T: 2592000, Avg. loss: 0.604893\n",
      "Total training time: 1.38 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 457.33, NNZs: 21, Bias: -0.003836, T: 3110400, Avg. loss: 0.602967\n",
      "Total training time: 1.68 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.74, NNZs: 25, Bias: 0.129358, T: 518400, Avg. loss: 16.330477\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.34, NNZs: 25, Bias: 0.052908, T: 1036800, Avg. loss: 0.595011\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.93, NNZs: 24, Bias: 0.025809, T: 1555200, Avg. loss: 0.590902\n",
      "Total training time: 0.78 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.48, NNZs: 24, Bias: 0.014701, T: 2073600, Avg. loss: 0.590151\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.49, NNZs: 24, Bias: 0.007668, T: 2592000, Avg. loss: 0.589066\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.76, NNZs: 24, Bias: 0.001514, T: 3110400, Avg. loss: 0.589360\n",
      "Total training time: 1.69 seconds.\n",
      "Convergence after 6 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.84, NNZs: 20, Bias: -0.452861, T: 518400, Avg. loss: 14.014134\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.39, NNZs: 21, Bias: -0.302982, T: 1036800, Avg. loss: 0.596317\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.96, NNZs: 23, Bias: -0.243899, T: 1555200, Avg. loss: 0.590885\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.50, NNZs: 22, Bias: -0.206143, T: 2073600, Avg. loss: 0.590488\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.51, NNZs: 22, Bias: -0.185018, T: 2592000, Avg. loss: 0.589927\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.77, NNZs: 22, Bias: -0.170656, T: 3110400, Avg. loss: 0.589814\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 6 epochs took 1.69 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.96, NNZs: 23, Bias: 0.656650, T: 518400, Avg. loss: 14.095767\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.45, NNZs: 22, Bias: 0.420464, T: 1036800, Avg. loss: 0.596300\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.00, NNZs: 24, Bias: 0.292605, T: 1555200, Avg. loss: 0.591976\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.53, NNZs: 24, Bias: 0.225273, T: 2073600, Avg. loss: 0.590672\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.53, NNZs: 25, Bias: 0.175300, T: 2592000, Avg. loss: 0.589894\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.79, NNZs: 25, Bias: 0.140393, T: 3110400, Avg. loss: 0.589405\n",
      "Total training time: 1.61 seconds.\n",
      "Convergence after 6 epochs took 1.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 18.71, NNZs: 24, Bias: -0.167821, T: 518400, Avg. loss: 14.552308\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.33, NNZs: 23, Bias: -0.123056, T: 1036800, Avg. loss: 0.595051\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.92, NNZs: 23, Bias: -0.112319, T: 1555200, Avg. loss: 0.591470\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.48, NNZs: 23, Bias: -0.103933, T: 2073600, Avg. loss: 0.589977\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.49, NNZs: 23, Bias: -0.101930, T: 2592000, Avg. loss: 0.589811\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.76, NNZs: 23, Bias: -0.098756, T: 3110400, Avg. loss: 0.589335\n",
      "Total training time: 1.65 seconds.\n",
      "Convergence after 6 epochs took 1.74 seconds\n",
      "-- Epoch 1\n",
      "Norm: 19.43, NNZs: 23, Bias: -1.282202, T: 518400, Avg. loss: 14.211090\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 13.69, NNZs: 20, Bias: -0.762793, T: 1036800, Avg. loss: 0.597296\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 11.15, NNZs: 20, Bias: -0.609396, T: 1555200, Avg. loss: 0.592777\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9.65, NNZs: 21, Bias: -0.523070, T: 2073600, Avg. loss: 0.591874\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.62, NNZs: 21, Bias: -0.460355, T: 2592000, Avg. loss: 0.590619\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7.87, NNZs: 21, Bias: -0.421090, T: 3110400, Avg. loss: 0.590272\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 3.15, NNZs: 30, Bias: -17.669568, T: 518400, Avg. loss: 24.422787\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.57, NNZs: 30, Bias: -14.560573, T: 1036800, Avg. loss: 2.240582\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.22, NNZs: 30, Bias: -12.515992, T: 1555200, Avg. loss: 1.536492\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.95, NNZs: 30, Bias: -10.990193, T: 2073600, Avg. loss: 1.217959\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.73, NNZs: 30, Bias: -9.773846, T: 2592000, Avg. loss: 1.018202\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.57, NNZs: 30, Bias: -8.759268, T: 3110400, Avg. loss: 0.881565\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.20 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.02, NNZs: 30, Bias: 1.503763, T: 518400, Avg. loss: 22.243140\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.54, NNZs: 30, Bias: 1.007145, T: 1036800, Avg. loss: 1.671922\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.37, NNZs: 30, Bias: 0.682017, T: 1555200, Avg. loss: 0.980615\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.27, NNZs: 30, Bias: 0.458971, T: 2073600, Avg. loss: 0.694880\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.21, NNZs: 30, Bias: 0.306780, T: 2592000, Avg. loss: 0.537479\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.17, NNZs: 30, Bias: 0.199219, T: 3110400, Avg. loss: 0.437650\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.15, NNZs: 30, Bias: 0.128309, T: 3628800, Avg. loss: 0.369722\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 7 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.15, NNZs: 30, Bias: -2.047746, T: 518400, Avg. loss: 23.040753\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.64, NNZs: 30, Bias: -1.428393, T: 1036800, Avg. loss: 1.681015\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.44, NNZs: 30, Bias: -1.003611, T: 1555200, Avg. loss: 0.983974\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.34, NNZs: 30, Bias: -0.709746, T: 2073600, Avg. loss: 0.695911\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.27, NNZs: 30, Bias: -0.500486, T: 2592000, Avg. loss: 0.541316\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.21, NNZs: 30, Bias: -0.352806, T: 3110400, Avg. loss: 0.440147\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.18, NNZs: 30, Bias: -0.251319, T: 3628800, Avg. loss: 0.371724\n",
      "Total training time: 1.32 seconds.\n",
      "Convergence after 7 epochs took 1.41 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.48, NNZs: 30, Bias: -5.004642, T: 518400, Avg. loss: 22.997584\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.95, NNZs: 30, Bias: -3.639212, T: 1036800, Avg. loss: 1.736247\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.70, NNZs: 30, Bias: -2.709783, T: 1555200, Avg. loss: 1.034331\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.53, NNZs: 30, Bias: -2.031180, T: 2073600, Avg. loss: 0.736868\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.42, NNZs: 30, Bias: -1.523834, T: 2592000, Avg. loss: 0.573610\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.33, NNZs: 30, Bias: -1.136592, T: 3110400, Avg. loss: 0.460184\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.55 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1.29, NNZs: 30, Bias: -3.615963, T: 518400, Avg. loss: 22.546644\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.79, NNZs: 30, Bias: -2.555210, T: 1036800, Avg. loss: 1.700312\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 30, Bias: -1.841547, T: 1555200, Avg. loss: 1.003366\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.42, NNZs: 30, Bias: -1.335110, T: 2073600, Avg. loss: 0.715162\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.33, NNZs: 30, Bias: -0.967506, T: 2592000, Avg. loss: 0.550681\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.26, NNZs: 30, Bias: -0.699622, T: 3110400, Avg. loss: 0.449282\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.21, NNZs: 30, Bias: -0.503037, T: 3628800, Avg. loss: 0.377074\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 7 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 463.18, NNZs: 3, Bias: -0.000155, T: 518400, Avg. loss: 12.378076\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 463.46, NNZs: 3, Bias: -0.000012, T: 1036800, Avg. loss: 0.044276\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 463.55, NNZs: 1, Bias: -0.000082, T: 1555200, Avg. loss: 0.026356\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 463.59, NNZs: 3, Bias: 0.000082, T: 2073600, Avg. loss: 0.016508\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 463.62, NNZs: 4, Bias: 0.000026, T: 2592000, Avg. loss: 0.014313\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 463.64, NNZs: 2, Bias: -0.000043, T: 3110400, Avg. loss: 0.010184\n",
      "Total training time: 1.50 seconds.\n",
      "Convergence after 6 epochs took 1.59 seconds\n",
      "-- Epoch 1\n",
      "Norm: 475.90, NNZs: 6, Bias: 0.000118, T: 518400, Avg. loss: 11.546764\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 476.17, NNZs: 2, Bias: -0.000146, T: 1036800, Avg. loss: 0.036699\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 476.26, NNZs: 3, Bias: 0.000032, T: 1555200, Avg. loss: 0.027893\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 476.30, NNZs: 4, Bias: -0.000170, T: 2073600, Avg. loss: 0.017966\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 476.33, NNZs: 2, Bias: 0.000019, T: 2592000, Avg. loss: 0.012582\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 476.34, NNZs: 1, Bias: 0.000016, T: 3110400, Avg. loss: 0.011419\n",
      "Total training time: 1.53 seconds.\n",
      "Convergence after 6 epochs took 1.63 seconds\n",
      "-- Epoch 1\n",
      "Norm: 464.37, NNZs: 5, Bias: -0.000275, T: 518400, Avg. loss: 10.556340\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 464.64, NNZs: 4, Bias: 0.000212, T: 1036800, Avg. loss: 0.047956\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 464.73, NNZs: 2, Bias: -0.000031, T: 1555200, Avg. loss: 0.027576\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 464.78, NNZs: 1, Bias: -0.000017, T: 2073600, Avg. loss: 0.019763\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 464.80, NNZs: 3, Bias: -0.000088, T: 2592000, Avg. loss: 0.014773\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 464.82, NNZs: 1, Bias: -0.000008, T: 3110400, Avg. loss: 0.011931\n",
      "Total training time: 1.57 seconds.\n",
      "Convergence after 6 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 466.58, NNZs: 3, Bias: -0.000958, T: 518400, Avg. loss: 13.746228\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 466.85, NNZs: 5, Bias: -0.000096, T: 1036800, Avg. loss: 0.031628\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 466.94, NNZs: 2, Bias: -0.000001, T: 1555200, Avg. loss: 0.024459\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 466.99, NNZs: 0, Bias: 0.000047, T: 2073600, Avg. loss: 0.014868\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 467.02, NNZs: 4, Bias: -0.000001, T: 2592000, Avg. loss: 0.013007\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 467.03, NNZs: 3, Bias: 0.000063, T: 3110400, Avg. loss: 0.012127\n",
      "Total training time: 1.50 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 467.05, NNZs: 3, Bias: 0.000027, T: 3628800, Avg. loss: 0.007134\n",
      "Total training time: 1.81 seconds.\n",
      "Convergence after 7 epochs took 1.89 seconds\n",
      "-- Epoch 1\n",
      "Norm: 464.16, NNZs: 5, Bias: -0.001186, T: 518400, Avg. loss: 11.378518\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 464.43, NNZs: 0, Bias: -0.000089, T: 1036800, Avg. loss: 0.050307\n",
      "Total training time: 0.50 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 464.52, NNZs: 2, Bias: -0.000212, T: 1555200, Avg. loss: 0.025323\n",
      "Total training time: 0.76 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 464.57, NNZs: 7, Bias: -0.000021, T: 2073600, Avg. loss: 0.019363\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 464.59, NNZs: 8, Bias: -0.000099, T: 2592000, Avg. loss: 0.015174\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 464.61, NNZs: 4, Bias: 0.000075, T: 3110400, Avg. loss: 0.012261\n",
      "Total training time: 1.58 seconds.\n",
      "Convergence after 6 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 25.02, NNZs: 6, Bias: -0.000972, T: 518400, Avg. loss: 15.019789\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.20, NNZs: 3, Bias: -0.000421, T: 1036800, Avg. loss: 0.017809\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.02, NNZs: 5, Bias: -0.000101, T: 1555200, Avg. loss: 0.007486\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.10, NNZs: 9, Bias: 0.000114, T: 2073600, Avg. loss: 0.005142\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.76, NNZs: 5, Bias: -0.000026, T: 2592000, Avg. loss: 0.002873\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.77, NNZs: 5, Bias: 0.000041, T: 3110400, Avg. loss: 0.003022\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.99, NNZs: 2, Bias: -0.000104, T: 3628800, Avg. loss: 0.001982\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.36, NNZs: 8, Bias: -0.000165, T: 4147200, Avg. loss: 0.000614\n",
      "Total training time: 2.05 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 8.84, NNZs: 6, Bias: -0.000083, T: 4665600, Avg. loss: 0.001422\n",
      "Total training time: 2.33 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 8.40, NNZs: 7, Bias: -0.000017, T: 5184000, Avg. loss: 0.000873\n",
      "Total training time: 2.61 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 8.01, NNZs: 8, Bias: -0.000033, T: 5702400, Avg. loss: 0.000879\n",
      "Total training time: 2.89 seconds.\n",
      "Convergence after 11 epochs took 2.97 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.98, NNZs: 10, Bias: 0.000298, T: 518400, Avg. loss: 15.083011\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.18, NNZs: 7, Bias: 0.000296, T: 1036800, Avg. loss: 0.020560\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.02, NNZs: 6, Bias: 0.000237, T: 1555200, Avg. loss: 0.005698\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.10, NNZs: 5, Bias: -0.000120, T: 2073600, Avg. loss: 0.002192\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.76, NNZs: 6, Bias: -0.000100, T: 2592000, Avg. loss: 0.003105\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.77, NNZs: 6, Bias: -0.000021, T: 3110400, Avg. loss: 0.002502\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.99, NNZs: 2, Bias: -0.000046, T: 3628800, Avg. loss: 0.000526\n",
      "Total training time: 1.86 seconds.\n",
      "Convergence after 7 epochs took 1.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.94, NNZs: 6, Bias: -0.000397, T: 518400, Avg. loss: 14.216446\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.17, NNZs: 4, Bias: 0.000265, T: 1036800, Avg. loss: 0.019258\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.01, NNZs: 8, Bias: 0.000033, T: 1555200, Avg. loss: 0.007195\n",
      "Total training time: 0.72 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.09, NNZs: 8, Bias: -0.000028, T: 2073600, Avg. loss: 0.004393\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.76, NNZs: 7, Bias: 0.000091, T: 2592000, Avg. loss: 0.000872\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.77, NNZs: 10, Bias: -0.000024, T: 3110400, Avg. loss: 0.001887\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.99, NNZs: 4, Bias: 0.000088, T: 3628800, Avg. loss: 0.000787\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9.36, NNZs: 7, Bias: 0.000028, T: 4147200, Avg. loss: 0.001218\n",
      "Total training time: 2.26 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 8.84, NNZs: 6, Bias: -0.000083, T: 4665600, Avg. loss: 0.001056\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 8.40, NNZs: 7, Bias: -0.000056, T: 5184000, Avg. loss: 0.000105\n",
      "Total training time: 2.81 seconds.\n",
      "Convergence after 10 epochs took 2.90 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.91, NNZs: 8, Bias: 0.000246, T: 518400, Avg. loss: 15.317073\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.17, NNZs: 4, Bias: -0.000460, T: 1036800, Avg. loss: 0.019388\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.00, NNZs: 6, Bias: 0.000078, T: 1555200, Avg. loss: 0.005969\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.08, NNZs: 8, Bias: 0.000009, T: 2073600, Avg. loss: 0.003282\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.75, NNZs: 6, Bias: -0.000302, T: 2592000, Avg. loss: 0.001348\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.76, NNZs: 6, Bias: 0.000005, T: 3110400, Avg. loss: 0.001444\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 6 epochs took 1.68 seconds\n",
      "-- Epoch 1\n",
      "Norm: 24.99, NNZs: 8, Bias: -0.001592, T: 518400, Avg. loss: 13.558537\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.19, NNZs: 7, Bias: 0.000306, T: 1036800, Avg. loss: 0.020105\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.04, NNZs: 9, Bias: 0.000121, T: 1555200, Avg. loss: 0.004254\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.12, NNZs: 5, Bias: 0.000126, T: 2073600, Avg. loss: 0.002898\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.78, NNZs: 9, Bias: 0.000016, T: 2592000, Avg. loss: 0.003965\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.78, NNZs: 10, Bias: 0.000009, T: 3110400, Avg. loss: 0.000840\n",
      "Total training time: 1.52 seconds.\n",
      "Convergence after 6 epochs took 1.60 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1342122358452.05, NNZs: 30, Bias: -3914816066056.940430, T: 518400, Avg. loss: 538124220878733676290871656448.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 769266923884.53, NNZs: 30, Bias: -2762100174519.752930, T: 1036800, Avg. loss: 17200336424357189981831168.000000\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 537447033505.89, NNZs: 30, Bias: -1976926299846.558350, T: 1555200, Avg. loss: 5617930449679106034368512.000000\n",
      "Total training time: 0.46 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 376524025371.71, NNZs: 30, Bias: -1431050436479.235596, T: 2073600, Avg. loss: 2724929631306075112210432.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 288621851922.23, NNZs: 30, Bias: -1033072620155.108887, T: 2592000, Avg. loss: 1555528276937270947217408.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 214035424728.11, NNZs: 30, Bias: -747982113904.190552, T: 3110400, Avg. loss: 975749666326083994124288.000000\n",
      "Total training time: 1.06 seconds.\n",
      "Convergence after 6 epochs took 1.14 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1216921573874.54, NNZs: 30, Bias: -3466496649182.786133, T: 518400, Avg. loss: 722404546721412709628097069056.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 710909471416.75, NNZs: 30, Bias: -2428125097967.821289, T: 1036800, Avg. loss: 17288832629516181958557696.000000\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 492619339802.85, NNZs: 30, Bias: -1721714497443.828369, T: 1555200, Avg. loss: 5471613515795644651929600.000000\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 352565215676.35, NNZs: 30, Bias: -1227110010110.524414, T: 2073600, Avg. loss: 2656341819361111266295808.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 261450365309.78, NNZs: 30, Bias: -882151615703.765137, T: 2592000, Avg. loss: 1526842906297842238750720.000000\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 201969811136.99, NNZs: 30, Bias: -634562310568.817139, T: 3110400, Avg. loss: 955075840752115941113856.000000\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 154510823866.57, NNZs: 30, Bias: -461738645541.175903, T: 3628800, Avg. loss: 628757737744452408049664.000000\n",
      "Total training time: 1.24 seconds.\n",
      "Convergence after 7 epochs took 1.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1475472801285.02, NNZs: 30, Bias: 7818403233856.011719, T: 518400, Avg. loss: 705799602310171099133500194816.000000\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 970604912628.32, NNZs: 30, Bias: 5828289287530.066406, T: 1036800, Avg. loss: 18114490549020606307762176.000000\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 715547121115.06, NNZs: 30, Bias: 4490141254461.766602, T: 1555200, Avg. loss: 6194451186085349176639488.000000\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 545477082985.69, NNZs: 30, Bias: 3498613443342.048828, T: 2073600, Avg. loss: 3101561714233007950266368.000000\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 428109613053.34, NNZs: 30, Bias: 2735353988214.442383, T: 2592000, Avg. loss: 1801989904902831420211200.000000\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 332082768228.94, NNZs: 30, Bias: 2131745423440.817627, T: 3110400, Avg. loss: 1134058334133272962924544.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 260128580770.53, NNZs: 30, Bias: 1651661061184.530273, T: 3628800, Avg. loss: 778455526526304003293184.000000\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 202246152509.24, NNZs: 30, Bias: 1274354055222.793213, T: 4147200, Avg. loss: 536048574424297087434752.000000\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 155539591226.60, NNZs: 30, Bias: 982182039120.585327, T: 4665600, Avg. loss: 387251232379158189309952.000000\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 122183631965.56, NNZs: 30, Bias: 758394849753.140381, T: 5184000, Avg. loss: 287042374099865207570432.000000\n",
      "Total training time: 1.94 seconds.\n",
      "Convergence after 10 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1993912143074.83, NNZs: 30, Bias: -9153944864180.572266, T: 518400, Avg. loss: 362996738343041550787008266240.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1390539115755.88, NNZs: 30, Bias: -6995892937483.903320, T: 1036800, Avg. loss: 18863326282912994160541696.000000\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1118142948763.88, NNZs: 30, Bias: -5536938634674.544922, T: 1555200, Avg. loss: 6685084762506962441076736.000000\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 886221873750.86, NNZs: 30, Bias: -4446978202520.886719, T: 2073600, Avg. loss: 3387449425218996308803584.000000\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 713447381927.06, NNZs: 30, Bias: -3594717036961.113281, T: 2592000, Avg. loss: 2003302823417745162371072.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 577640645565.39, NNZs: 30, Bias: -2905383667388.639648, T: 3110400, Avg. loss: 1289598642848830744166400.000000\n",
      "Total training time: 1.15 seconds.\n",
      "Convergence after 6 epochs took 1.23 seconds\n",
      "-- Epoch 1\n",
      "Norm: 977152595055.62, NNZs: 30, Bias: 1169655276353.475098, T: 518400, Avg. loss: 610544458072146700559504637952.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 448964735554.64, NNZs: 30, Bias: 758460937924.644775, T: 1036800, Avg. loss: 16892295182328119146053632.000000\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 285721852043.45, NNZs: 30, Bias: 498794266529.380554, T: 1555200, Avg. loss: 5352497773311524622827520.000000\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 202583972758.05, NNZs: 30, Bias: 327931116024.404419, T: 2073600, Avg. loss: 2566930744599661422575616.000000\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 158744818097.21, NNZs: 30, Bias: 221777900468.837616, T: 2592000, Avg. loss: 1473596201754786357313536.000000\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 124032905694.60, NNZs: 30, Bias: 152640640549.429413, T: 3110400, Avg. loss: 903032172221444885839872.000000\n",
      "Total training time: 1.19 seconds.\n",
      "Convergence after 6 epochs took 1.29 seconds\n",
      "-- Epoch 1\n",
      "Norm: 13318409035276.81, NNZs: 30, Bias: 3902744449565.454590, T: 518400, Avg. loss: 1010701572301436516740179689472.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5874949067076.62, NNZs: 30, Bias: 3062668979360.892090, T: 1036800, Avg. loss: 29541459834629527783342080.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2366726945250.49, NNZs: 30, Bias: 2418374111121.809082, T: 1555200, Avg. loss: 7796107367602001677385728.000000\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 796144222400.81, NNZs: 30, Bias: 1832405332312.892090, T: 2073600, Avg. loss: 3023789718100732832382976.000000\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 318338570447.58, NNZs: 30, Bias: 1342882839753.606445, T: 2592000, Avg. loss: 1598452696265958015107072.000000\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 199809115090.84, NNZs: 30, Bias: 982108995216.273804, T: 3110400, Avg. loss: 990766672583925952413696.000000\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 8117416068798.66, NNZs: 30, Bias: -440443362596.120605, T: 518400, Avg. loss: 522928299406423460826612498432.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2614627345675.96, NNZs: 30, Bias: -632520118059.517090, T: 1036800, Avg. loss: 20337539958054538786635776.000000\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 768629862319.74, NNZs: 30, Bias: -544243523769.649902, T: 1555200, Avg. loss: 5641439007517508636770304.000000\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 320079494640.86, NNZs: 30, Bias: -404307164076.787109, T: 2073600, Avg. loss: 2590441967116015189884928.000000\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 199457230700.33, NNZs: 30, Bias: -294499419082.162720, T: 2592000, Avg. loss: 1471661547236482464350208.000000\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 154556325892.20, NNZs: 30, Bias: -212858479328.699799, T: 3110400, Avg. loss: 903129895496218748911616.000000\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 126508776398.91, NNZs: 30, Bias: -154769492898.471130, T: 3628800, Avg. loss: 594178780918163888406528.000000\n",
      "Total training time: 1.54 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 102806845430.20, NNZs: 30, Bias: -115369585215.015472, T: 4147200, Avg. loss: 408566922967146087579648.000000\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 8 epochs took 1.86 seconds\n",
      "-- Epoch 1\n",
      "Norm: 7792522835488.42, NNZs: 30, Bias: -1496719187366.380127, T: 518400, Avg. loss: 375633228965654983220446363648.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2575534458847.60, NNZs: 30, Bias: -1444134026180.419922, T: 1036800, Avg. loss: 20061522508981490558173184.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 816350832087.25, NNZs: 30, Bias: -1159909945928.752930, T: 1555200, Avg. loss: 5738535598294699585044480.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 376032715784.35, NNZs: 30, Bias: -849369724060.144043, T: 2073600, Avg. loss: 2611141236490891358633984.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 250586896771.00, NNZs: 30, Bias: -609620030960.866699, T: 2592000, Avg. loss: 1493768493056025006440448.000000\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181775256175.61, NNZs: 30, Bias: -439483397973.972595, T: 3110400, Avg. loss: 937865588263344167452672.000000\n",
      "Total training time: 1.44 seconds.\n",
      "Convergence after 6 epochs took 1.53 seconds\n",
      "-- Epoch 1\n",
      "Norm: 9814452226692.41, NNZs: 30, Bias: -1310273097534.630127, T: 518400, Avg. loss: 411824658720812760628673380352.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3574989045648.09, NNZs: 30, Bias: -1370508175097.688965, T: 1036800, Avg. loss: 22672130090051680660881408.000000\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1142827802232.74, NNZs: 30, Bias: -1166344372419.393311, T: 1555200, Avg. loss: 6086655267296768488898560.000000\n",
      "Total training time: 0.59 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 422810918820.46, NNZs: 30, Bias: -879183368089.166626, T: 2073600, Avg. loss: 2661936361512897634893824.000000\n",
      "Total training time: 0.82 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 257262207440.06, NNZs: 30, Bias: -636390692857.753540, T: 2592000, Avg. loss: 1519323032880154706706432.000000\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 188726544620.52, NNZs: 30, Bias: -460432450839.487000, T: 3110400, Avg. loss: 939478771318652156248064.000000\n",
      "Total training time: 1.31 seconds.\n",
      "Convergence after 6 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 9039409322248.95, NNZs: 30, Bias: -104415522781.613480, T: 518400, Avg. loss: 981320514439344727907895345152.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3072339460039.62, NNZs: 30, Bias: -388172349507.138611, T: 1036800, Avg. loss: 21489613262645040028581888.000000\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 918304964888.72, NNZs: 30, Bias: -374294831079.673462, T: 1555200, Avg. loss: 5760112965494633465380864.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 323963485207.05, NNZs: 30, Bias: -286613642781.121582, T: 2073600, Avg. loss: 2639185294296780518719488.000000\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 195754650774.33, NNZs: 30, Bias: -210969320860.582397, T: 2592000, Avg. loss: 1476161142781091904487424.000000\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 147899673369.71, NNZs: 30, Bias: -151693708616.615601, T: 3110400, Avg. loss: 909394895513140814938112.000000\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 117960660150.55, NNZs: 30, Bias: -110509767968.529480, T: 3628800, Avg. loss: 590647508717384891367424.000000\n",
      "Total training time: 1.67 seconds.\n",
      "Convergence after 7 epochs took 1.74 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1267139654417.43, NNZs: 30, Bias: -3426226290691.192871, T: 518400, Avg. loss: 249406967635449671500393611264.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 732826373730.52, NNZs: 30, Bias: -2401400604888.223633, T: 1036800, Avg. loss: 17046039805104299687542784.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 498024055057.49, NNZs: 30, Bias: -1703247976931.028320, T: 1555200, Avg. loss: 5511577009021373472833536.000000\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 350050237562.21, NNZs: 30, Bias: -1218445188634.253418, T: 2073600, Avg. loss: 2658199169179241886515200.000000\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 261214956346.06, NNZs: 30, Bias: -876054291011.440796, T: 2592000, Avg. loss: 1534068367255700309540864.000000\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 199948940459.96, NNZs: 30, Bias: -631550573124.668579, T: 3110400, Avg. loss: 964946546708548381835264.000000\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 153823937105.79, NNZs: 30, Bias: -459990325815.157043, T: 3628800, Avg. loss: 639519906363544090705920.000000\n",
      "Total training time: 1.58 seconds.\n",
      "Convergence after 7 epochs took 1.66 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1265597060617.51, NNZs: 30, Bias: -3109951997752.367188, T: 518400, Avg. loss: 567639925049071239131492777984.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 716521129004.80, NNZs: 30, Bias: -2167339223904.010254, T: 1036800, Avg. loss: 16812128199960567358685184.000000\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 473677141135.85, NNZs: 30, Bias: -1533994890036.376221, T: 1555200, Avg. loss: 5516756595536647906394112.000000\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 343137817024.21, NNZs: 30, Bias: -1089050539467.488281, T: 2073600, Avg. loss: 2656694207475072211353600.000000\n",
      "Total training time: 0.92 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 246526813311.44, NNZs: 30, Bias: -775551826759.768921, T: 2592000, Avg. loss: 1504793513730655230361600.000000\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 191145534748.57, NNZs: 30, Bias: -556796115216.037476, T: 3110400, Avg. loss: 943439057329797719916544.000000\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.56 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1193744440156.80, NNZs: 30, Bias: 4733280183853.739258, T: 518400, Avg. loss: 543332708587947222080090537984.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 664253828466.60, NNZs: 30, Bias: 3339648651770.320312, T: 1036800, Avg. loss: 17242022843021633205043200.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 455471205182.58, NNZs: 30, Bias: 2407738902675.491699, T: 1555200, Avg. loss: 5598008984011931337621504.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 317078254494.79, NNZs: 30, Bias: 1747025610467.930176, T: 2073600, Avg. loss: 2709306996938445036716032.000000\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 234088075357.19, NNZs: 30, Bias: 1267185558707.806641, T: 2592000, Avg. loss: 1549081341846542866186240.000000\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 176196346928.18, NNZs: 30, Bias: 917801748845.416504, T: 3110400, Avg. loss: 978449549404563314835456.000000\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 132701468421.18, NNZs: 30, Bias: 668122834062.740356, T: 3628800, Avg. loss: 658470037180388466491392.000000\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 106188351412.55, NNZs: 30, Bias: 492406885632.501282, T: 4147200, Avg. loss: 451600747273023865749504.000000\n",
      "Total training time: 2.03 seconds.\n",
      "Convergence after 8 epochs took 2.11 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1390044315195.05, NNZs: 30, Bias: -4537127158467.818359, T: 518400, Avg. loss: 898569847842540803174487293952.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 867267703997.08, NNZs: 30, Bias: -3250919436621.106934, T: 1036800, Avg. loss: 17142882618297958331842560.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 605764415136.70, NNZs: 30, Bias: -2380162949848.303223, T: 1555200, Avg. loss: 5686328795220215282532352.000000\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 435123869804.36, NNZs: 30, Bias: -1751443428870.639648, T: 2073600, Avg. loss: 2739697792920609877917696.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 331378426098.87, NNZs: 30, Bias: -1287882893252.091309, T: 2592000, Avg. loss: 1590239351407963772289024.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 249919711016.34, NNZs: 30, Bias: -949507876036.614990, T: 3110400, Avg. loss: 988778043279045287739392.000000\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 979249308892.12, NNZs: 30, Bias: 704437635238.643677, T: 518400, Avg. loss: 908771232760378609830562103296.000000\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 454213865882.02, NNZs: 30, Bias: 448587181226.977966, T: 1036800, Avg. loss: 16749700623205444951736320.000000\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 282742255637.36, NNZs: 30, Bias: 281913969759.301941, T: 1555200, Avg. loss: 5450551233691359893258240.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 215723620266.92, NNZs: 30, Bias: 187190140318.123260, T: 2073600, Avg. loss: 2584925438013828738580480.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 153329220995.25, NNZs: 30, Bias: 125830487522.312805, T: 2592000, Avg. loss: 1462945685520425666215936.000000\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 127519775455.48, NNZs: 30, Bias: 85055144106.940125, T: 3110400, Avg. loss: 912367364335053677002752.000000\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 101905918061.43, NNZs: 30, Bias: 60015665828.608894, T: 3628800, Avg. loss: 601477485866717034840064.000000\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 7 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1075.76, NNZs: 30, Bias: 29.591835, T: 518400, Avg. loss: 10958.144041\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 560.87, NNZs: 30, Bias: -1.749226, T: 1036800, Avg. loss: 1643.680315\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 367.45, NNZs: 30, Bias: -20.535028, T: 1555200, Avg. loss: 970.410186\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 283.50, NNZs: 30, Bias: -23.887743, T: 2073600, Avg. loss: 688.333624\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 221.27, NNZs: 30, Bias: -20.289640, T: 2592000, Avg. loss: 536.696849\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 182.96, NNZs: 30, Bias: -23.013328, T: 3110400, Avg. loss: 435.986972\n",
      "Total training time: 1.05 seconds.\n",
      "Convergence after 6 epochs took 1.13 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1040.93, NNZs: 30, Bias: 63.847722, T: 518400, Avg. loss: 10966.936869\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 542.75, NNZs: 30, Bias: 24.894486, T: 1036800, Avg. loss: 1650.666633\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 371.25, NNZs: 30, Bias: -0.655784, T: 1555200, Avg. loss: 970.602700\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 262.84, NNZs: 30, Bias: -13.858048, T: 2073600, Avg. loss: 688.027515\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 221.88, NNZs: 30, Bias: -14.815307, T: 2592000, Avg. loss: 534.493919\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 187.07, NNZs: 30, Bias: -21.485330, T: 3110400, Avg. loss: 437.314197\n",
      "Total training time: 1.04 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 156.66, NNZs: 30, Bias: -21.152326, T: 3628800, Avg. loss: 370.039046\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 135.08, NNZs: 30, Bias: -21.676748, T: 4147200, Avg. loss: 321.374694\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 123.43, NNZs: 30, Bias: -16.828911, T: 4665600, Avg. loss: 282.456331\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 115.51, NNZs: 30, Bias: -14.406398, T: 5184000, Avg. loss: 252.125797\n",
      "Total training time: 1.77 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 97.51, NNZs: 30, Bias: -12.360708, T: 5702400, Avg. loss: 228.270501\n",
      "Total training time: 1.96 seconds.\n",
      "Convergence after 11 epochs took 2.04 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1023.40, NNZs: 30, Bias: 73.874004, T: 518400, Avg. loss: 10960.104664\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 556.45, NNZs: 30, Bias: 34.395132, T: 1036800, Avg. loss: 1647.823460\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 362.28, NNZs: 30, Bias: 6.567947, T: 1555200, Avg. loss: 970.537022\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 280.60, NNZs: 30, Bias: -6.002630, T: 2073600, Avg. loss: 688.949465\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 218.68, NNZs: 30, Bias: -15.655116, T: 2592000, Avg. loss: 534.492969\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 185.71, NNZs: 30, Bias: -9.820771, T: 3110400, Avg. loss: 436.048635\n",
      "Total training time: 1.04 seconds.\n",
      "Convergence after 6 epochs took 1.12 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1050.97, NNZs: 30, Bias: 6.039554, T: 518400, Avg. loss: 10867.457777\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 535.97, NNZs: 30, Bias: -24.698027, T: 1036800, Avg. loss: 1649.438402\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 355.55, NNZs: 30, Bias: -34.354816, T: 1555200, Avg. loss: 966.623503\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 270.13, NNZs: 30, Bias: -35.059398, T: 2073600, Avg. loss: 686.610340\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 216.12, NNZs: 30, Bias: -33.326439, T: 2592000, Avg. loss: 533.804698\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 184.01, NNZs: 30, Bias: -28.943383, T: 3110400, Avg. loss: 437.869857\n",
      "Total training time: 1.06 seconds.\n",
      "Convergence after 6 epochs took 1.15 seconds\n",
      "-- Epoch 1\n",
      "Norm: 995.14, NNZs: 30, Bias: 4.049698, T: 518400, Avg. loss: 11012.040002\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 536.18, NNZs: 30, Bias: -40.242502, T: 1036800, Avg. loss: 1657.580237\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 365.38, NNZs: 30, Bias: -45.101881, T: 1555200, Avg. loss: 967.994601\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 272.99, NNZs: 30, Bias: -43.469149, T: 2073600, Avg. loss: 688.354057\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 223.18, NNZs: 30, Bias: -42.475693, T: 2592000, Avg. loss: 536.061580\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.18, NNZs: 30, Bias: -39.171934, T: 3110400, Avg. loss: 436.151236\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 157.46, NNZs: 30, Bias: -35.497126, T: 3628800, Avg. loss: 370.242311\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 7 epochs took 1.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12690.77, NNZs: 30, Bias: -107.626834, T: 518400, Avg. loss: 10724.163623\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14322.13, NNZs: 29, Bias: -94.710399, T: 1036800, Avg. loss: 1310.892773\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15247.17, NNZs: 24, Bias: -8.034158, T: 1555200, Avg. loss: 635.117660\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15831.63, NNZs: 23, Bias: -0.760190, T: 2073600, Avg. loss: 387.454903\n",
      "Total training time: 0.83 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16243.75, NNZs: 14, Bias: -0.304790, T: 2592000, Avg. loss: 266.616024\n",
      "Total training time: 1.09 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16552.03, NNZs: 14, Bias: -0.192896, T: 3110400, Avg. loss: 199.225286\n",
      "Total training time: 1.36 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16793.76, NNZs: 14, Bias: -0.130443, T: 3628800, Avg. loss: 155.337800\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 7 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12763.80, NNZs: 30, Bias: -172.962626, T: 518400, Avg. loss: 10548.411071\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14404.61, NNZs: 27, Bias: -130.643779, T: 1036800, Avg. loss: 1321.089634\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15327.57, NNZs: 22, Bias: -10.944174, T: 1555200, Avg. loss: 634.480063\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15911.80, NNZs: 18, Bias: 0.200497, T: 2073600, Avg. loss: 387.555213\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16322.17, NNZs: 19, Bias: -0.935801, T: 2592000, Avg. loss: 268.449617\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16630.17, NNZs: 12, Bias: -0.129825, T: 3110400, Avg. loss: 198.325045\n",
      "Total training time: 1.43 seconds.\n",
      "Convergence after 6 epochs took 1.52 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12701.81, NNZs: 30, Bias: -165.657932, T: 518400, Avg. loss: 10764.467790\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14336.77, NNZs: 30, Bias: -128.398754, T: 1036800, Avg. loss: 1313.582661\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15257.65, NNZs: 21, Bias: -9.111656, T: 1555200, Avg. loss: 633.029538\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15842.06, NNZs: 19, Bias: -0.835451, T: 2073600, Avg. loss: 385.872939\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16251.44, NNZs: 18, Bias: -0.477887, T: 2592000, Avg. loss: 267.423083\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16559.63, NNZs: 14, Bias: -0.333276, T: 3110400, Avg. loss: 199.443821\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16802.58, NNZs: 14, Bias: -0.518011, T: 3628800, Avg. loss: 155.765906\n",
      "Total training time: 1.64 seconds.\n",
      "Convergence after 7 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12739.34, NNZs: 29, Bias: -82.782480, T: 518400, Avg. loss: 10785.913798\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14377.56, NNZs: 28, Bias: -94.850560, T: 1036800, Avg. loss: 1306.002446\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15299.16, NNZs: 26, Bias: -3.696149, T: 1555200, Avg. loss: 630.662939\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15881.26, NNZs: 20, Bias: -0.461259, T: 2073600, Avg. loss: 385.347821\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16290.20, NNZs: 18, Bias: -0.836357, T: 2592000, Avg. loss: 267.376694\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16597.60, NNZs: 15, Bias: -0.249605, T: 3110400, Avg. loss: 197.818626\n",
      "Total training time: 1.37 seconds.\n",
      "Convergence after 6 epochs took 1.45 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12701.54, NNZs: 28, Bias: -123.753427, T: 518400, Avg. loss: 10798.466104\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14344.02, NNZs: 27, Bias: -114.612112, T: 1036800, Avg. loss: 1309.574811\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15267.94, NNZs: 24, Bias: -9.136430, T: 1555200, Avg. loss: 633.939411\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15851.29, NNZs: 21, Bias: -0.373608, T: 2073600, Avg. loss: 386.547993\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16260.29, NNZs: 21, Bias: -0.899004, T: 2592000, Avg. loss: 266.842654\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16567.69, NNZs: 19, Bias: -0.447738, T: 3110400, Avg. loss: 199.795731\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16810.80, NNZs: 18, Bias: -0.058378, T: 3628800, Avg. loss: 155.316193\n",
      "Total training time: 1.71 seconds.\n",
      "Convergence after 7 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2591.96, NNZs: 30, Bias: -225.068800, T: 518400, Avg. loss: 10927.012089\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2617.73, NNZs: 29, Bias: -181.637618, T: 1036800, Avg. loss: 1585.076633\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2682.92, NNZs: 29, Bias: -125.633444, T: 1555200, Avg. loss: 902.934359\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2730.55, NNZs: 30, Bias: -88.413443, T: 2073600, Avg. loss: 620.489757\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.21, NNZs: 29, Bias: -57.729569, T: 2592000, Avg. loss: 462.956299\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2792.37, NNZs: 28, Bias: -34.459802, T: 3110400, Avg. loss: 366.973508\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2811.42, NNZs: 30, Bias: -22.166890, T: 3628800, Avg. loss: 299.421116\n",
      "Total training time: 1.64 seconds.\n",
      "Convergence after 7 epochs took 1.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2606.74, NNZs: 29, Bias: 27.337110, T: 518400, Avg. loss: 10996.788052\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2615.16, NNZs: 30, Bias: -15.329773, T: 1036800, Avg. loss: 1582.727318\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2679.07, NNZs: 29, Bias: -27.571849, T: 1555200, Avg. loss: 900.618093\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2731.14, NNZs: 27, Bias: -28.385221, T: 2073600, Avg. loss: 619.934663\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2768.90, NNZs: 29, Bias: -26.126217, T: 2592000, Avg. loss: 466.421936\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2793.96, NNZs: 29, Bias: -19.946024, T: 3110400, Avg. loss: 367.070452\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2812.67, NNZs: 28, Bias: -14.120000, T: 3628800, Avg. loss: 299.904867\n",
      "Total training time: 1.59 seconds.\n",
      "Convergence after 7 epochs took 1.67 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2593.23, NNZs: 30, Bias: -12.050997, T: 518400, Avg. loss: 10976.565028\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2621.28, NNZs: 30, Bias: -32.914470, T: 1036800, Avg. loss: 1598.054950\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2683.46, NNZs: 28, Bias: -35.206364, T: 1555200, Avg. loss: 905.648122\n",
      "Total training time: 0.60 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2733.47, NNZs: 28, Bias: -29.787820, T: 2073600, Avg. loss: 622.457034\n",
      "Total training time: 0.84 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2771.68, NNZs: 29, Bias: -25.896375, T: 2592000, Avg. loss: 465.479127\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2795.80, NNZs: 30, Bias: -20.969230, T: 3110400, Avg. loss: 366.303330\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2813.79, NNZs: 29, Bias: -12.909710, T: 3628800, Avg. loss: 299.769377\n",
      "Total training time: 1.55 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2826.83, NNZs: 29, Bias: -8.762149, T: 4147200, Avg. loss: 251.436090\n",
      "Total training time: 1.78 seconds.\n",
      "Convergence after 8 epochs took 1.85 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2603.73, NNZs: 30, Bias: 121.601766, T: 518400, Avg. loss: 10819.999549\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2610.33, NNZs: 30, Bias: 45.072153, T: 1036800, Avg. loss: 1585.981309\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2680.24, NNZs: 30, Bias: 11.383076, T: 1555200, Avg. loss: 900.225703\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2732.11, NNZs: 27, Bias: -7.406778, T: 2073600, Avg. loss: 623.132646\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.45, NNZs: 28, Bias: -15.876610, T: 2592000, Avg. loss: 464.023700\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2793.64, NNZs: 29, Bias: -15.126852, T: 3110400, Avg. loss: 366.673977\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.46 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2603.22, NNZs: 30, Bias: 76.698059, T: 518400, Avg. loss: 10888.990656\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2618.12, NNZs: 29, Bias: 12.103236, T: 1036800, Avg. loss: 1590.548869\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2680.91, NNZs: 30, Bias: -9.819413, T: 1555200, Avg. loss: 903.107649\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2730.64, NNZs: 29, Bias: -18.214163, T: 2073600, Avg. loss: 620.059405\n",
      "Total training time: 0.85 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2769.44, NNZs: 29, Bias: -16.492906, T: 2592000, Avg. loss: 467.390350\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2795.47, NNZs: 28, Bias: -15.657047, T: 3110400, Avg. loss: 367.882788\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2812.32, NNZs: 28, Bias: -12.252768, T: 3628800, Avg. loss: 299.134722\n",
      "Total training time: 1.60 seconds.\n",
      "Convergence after 7 epochs took 1.68 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1009.04, NNZs: 30, Bias: 218.971560, T: 518400, Avg. loss: 10866.618769\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 528.76, NNZs: 30, Bias: 126.854345, T: 1036800, Avg. loss: 1644.901747\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 359.01, NNZs: 30, Bias: 57.756259, T: 1555200, Avg. loss: 966.159018\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 271.49, NNZs: 30, Bias: 34.419435, T: 2073600, Avg. loss: 686.781529\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 217.20, NNZs: 30, Bias: 13.194240, T: 2592000, Avg. loss: 534.295424\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.77, NNZs: 30, Bias: 5.790946, T: 3110400, Avg. loss: 435.364960\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1000.23, NNZs: 30, Bias: 37.649494, T: 518400, Avg. loss: 10963.961319\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 523.12, NNZs: 30, Bias: -0.302966, T: 1036800, Avg. loss: 1646.317311\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 356.34, NNZs: 30, Bias: -16.165091, T: 1555200, Avg. loss: 966.080801\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 280.56, NNZs: 30, Bias: -17.866374, T: 2073600, Avg. loss: 690.369430\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 218.82, NNZs: 30, Bias: -16.693032, T: 2592000, Avg. loss: 534.499170\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 183.26, NNZs: 30, Bias: -19.388021, T: 3110400, Avg. loss: 434.938885\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 159.15, NNZs: 30, Bias: -18.054822, T: 3628800, Avg. loss: 369.069305\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 138.99, NNZs: 30, Bias: -16.010590, T: 4147200, Avg. loss: 318.212842\n",
      "Total training time: 1.63 seconds.\n",
      "Convergence after 8 epochs took 1.70 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1005.23, NNZs: 30, Bias: 126.522077, T: 518400, Avg. loss: 10860.730415\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 553.85, NNZs: 30, Bias: 67.224882, T: 1036800, Avg. loss: 1651.577433\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 360.46, NNZs: 30, Bias: 27.254931, T: 1555200, Avg. loss: 966.459760\n",
      "Total training time: 0.57 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 271.73, NNZs: 30, Bias: 5.047814, T: 2073600, Avg. loss: 684.967582\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 223.28, NNZs: 30, Bias: -1.765486, T: 2592000, Avg. loss: 534.644441\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186.98, NNZs: 30, Bias: -5.770685, T: 3110400, Avg. loss: 435.724237\n",
      "Total training time: 1.22 seconds.\n",
      "Convergence after 6 epochs took 1.30 seconds\n",
      "-- Epoch 1\n",
      "Norm: 997.62, NNZs: 30, Bias: 308.410437, T: 518400, Avg. loss: 10910.033596\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 533.06, NNZs: 30, Bias: 187.141338, T: 1036800, Avg. loss: 1655.669471\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 369.99, NNZs: 30, Bias: 107.594758, T: 1555200, Avg. loss: 965.727457\n",
      "Total training time: 0.54 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 266.76, NNZs: 30, Bias: 56.047182, T: 2073600, Avg. loss: 684.867525\n",
      "Total training time: 0.77 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 224.91, NNZs: 30, Bias: 26.238177, T: 2592000, Avg. loss: 532.598234\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 180.24, NNZs: 30, Bias: 10.267857, T: 3110400, Avg. loss: 438.606039\n",
      "Total training time: 1.23 seconds.\n",
      "Convergence after 6 epochs took 1.31 seconds\n",
      "-- Epoch 1\n",
      "Norm: 990.74, NNZs: 30, Bias: 25.257978, T: 518400, Avg. loss: 10906.527534\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 555.02, NNZs: 30, Bias: -13.737897, T: 1036800, Avg. loss: 1647.532503\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 361.24, NNZs: 30, Bias: -28.626825, T: 1555200, Avg. loss: 969.500177\n",
      "Total training time: 0.58 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 271.93, NNZs: 30, Bias: -34.765075, T: 2073600, Avg. loss: 687.355635\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 226.79, NNZs: 30, Bias: -30.714873, T: 2592000, Avg. loss: 535.860669\n",
      "Total training time: 1.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 181.56, NNZs: 30, Bias: -34.194163, T: 3110400, Avg. loss: 434.402931\n",
      "Total training time: 1.25 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 161.21, NNZs: 30, Bias: -32.556309, T: 3628800, Avg. loss: 370.947393\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 7 epochs took 1.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12733.97, NNZs: 29, Bias: 66.515351, T: 518400, Avg. loss: 10725.604763\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14362.90, NNZs: 27, Bias: -32.944602, T: 1036800, Avg. loss: 1313.603904\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15281.05, NNZs: 24, Bias: -4.252252, T: 1555200, Avg. loss: 622.062586\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15852.23, NNZs: 17, Bias: -0.692098, T: 2073600, Avg. loss: 362.870620\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16240.61, NNZs: 13, Bias: 0.078195, T: 2592000, Avg. loss: 226.710518\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16517.27, NNZs: 19, Bias: 0.233397, T: 3110400, Avg. loss: 146.703234\n",
      "Total training time: 1.57 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16718.88, NNZs: 15, Bias: -0.194624, T: 3628800, Avg. loss: 98.507168\n",
      "Total training time: 1.86 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16869.55, NNZs: 15, Bias: -0.306082, T: 4147200, Avg. loss: 70.164059\n",
      "Total training time: 2.20 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 16987.57, NNZs: 9, Bias: -0.202432, T: 4665600, Avg. loss: 52.654977\n",
      "Total training time: 2.51 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 17081.43, NNZs: 21, Bias: -0.084310, T: 5184000, Avg. loss: 40.065379\n",
      "Total training time: 2.82 seconds.\n",
      "Convergence after 10 epochs took 2.91 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12737.16, NNZs: 29, Bias: -353.241951, T: 518400, Avg. loss: 10841.549100\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14363.10, NNZs: 26, Bias: -226.492741, T: 1036800, Avg. loss: 1313.443693\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15286.15, NNZs: 18, Bias: -15.695380, T: 1555200, Avg. loss: 627.089410\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15858.12, NNZs: 18, Bias: -0.139404, T: 2073600, Avg. loss: 361.436275\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16246.64, NNZs: 16, Bias: -0.250822, T: 2592000, Avg. loss: 226.127169\n",
      "Total training time: 1.30 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16520.61, NNZs: 15, Bias: -0.130337, T: 3110400, Avg. loss: 145.716030\n",
      "Total training time: 1.60 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16721.02, NNZs: 16, Bias: -0.113718, T: 3628800, Avg. loss: 99.655455\n",
      "Total training time: 1.94 seconds.\n",
      "Convergence after 7 epochs took 2.02 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12697.19, NNZs: 29, Bias: -194.393092, T: 518400, Avg. loss: 10573.905520\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14354.79, NNZs: 25, Bias: -138.209521, T: 1036800, Avg. loss: 1315.668171\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15275.55, NNZs: 20, Bias: -7.946484, T: 1555200, Avg. loss: 625.145303\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15847.21, NNZs: 20, Bias: -0.433781, T: 2073600, Avg. loss: 361.085212\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16233.69, NNZs: 13, Bias: -0.399946, T: 2592000, Avg. loss: 225.706322\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16508.57, NNZs: 18, Bias: 0.076483, T: 3110400, Avg. loss: 145.314078\n",
      "Total training time: 1.53 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16710.60, NNZs: 15, Bias: 0.065819, T: 3628800, Avg. loss: 97.581204\n",
      "Total training time: 1.84 seconds.\n",
      "Convergence after 7 epochs took 1.92 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12731.55, NNZs: 30, Bias: -136.422573, T: 518400, Avg. loss: 10833.189902\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14357.03, NNZs: 30, Bias: -122.761493, T: 1036800, Avg. loss: 1305.594037\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15278.49, NNZs: 21, Bias: -7.871679, T: 1555200, Avg. loss: 626.900939\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15852.16, NNZs: 21, Bias: -0.979739, T: 2073600, Avg. loss: 363.388625\n",
      "Total training time: 1.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16239.19, NNZs: 17, Bias: -0.676264, T: 2592000, Avg. loss: 224.954697\n",
      "Total training time: 1.35 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16514.64, NNZs: 17, Bias: -0.241107, T: 3110400, Avg. loss: 144.927917\n",
      "Total training time: 1.69 seconds.\n",
      "Convergence after 6 epochs took 1.77 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12722.82, NNZs: 29, Bias: -98.155593, T: 518400, Avg. loss: 10859.928710\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14330.45, NNZs: 26, Bias: -107.424784, T: 1036800, Avg. loss: 1312.871475\n",
      "Total training time: 0.44 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15253.65, NNZs: 23, Bias: -6.981568, T: 1555200, Avg. loss: 625.949410\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15827.43, NNZs: 18, Bias: -0.172644, T: 2073600, Avg. loss: 363.104965\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16215.83, NNZs: 18, Bias: -0.681420, T: 2592000, Avg. loss: 225.085349\n",
      "Total training time: 1.31 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16492.94, NNZs: 18, Bias: -0.285756, T: 3110400, Avg. loss: 145.476443\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16694.81, NNZs: 18, Bias: -0.198105, T: 3628800, Avg. loss: 98.975436\n",
      "Total training time: 1.98 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16847.27, NNZs: 15, Bias: 0.173715, T: 4147200, Avg. loss: 70.507386\n",
      "Total training time: 2.29 seconds.\n",
      "Convergence after 8 epochs took 2.37 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2594.00, NNZs: 30, Bias: 48.847381, T: 518400, Avg. loss: 10978.455299\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2619.24, NNZs: 29, Bias: -1.320577, T: 1036800, Avg. loss: 1593.595979\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2684.63, NNZs: 30, Bias: -15.271919, T: 1555200, Avg. loss: 906.947423\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2731.83, NNZs: 29, Bias: -22.718711, T: 2073600, Avg. loss: 617.989360\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.07, NNZs: 28, Bias: -13.105590, T: 2592000, Avg. loss: 464.095297\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2793.23, NNZs: 29, Bias: -12.561494, T: 3110400, Avg. loss: 366.247692\n",
      "Total training time: 1.54 seconds.\n",
      "Convergence after 6 epochs took 1.62 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2593.62, NNZs: 30, Bias: -55.839549, T: 518400, Avg. loss: 10878.551404\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2614.74, NNZs: 30, Bias: -69.453029, T: 1036800, Avg. loss: 1587.717923\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2679.78, NNZs: 30, Bias: -62.065542, T: 1555200, Avg. loss: 905.579688\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2732.64, NNZs: 30, Bias: -44.951926, T: 2073600, Avg. loss: 621.393817\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2768.83, NNZs: 30, Bias: -33.754647, T: 2592000, Avg. loss: 464.532781\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2794.30, NNZs: 28, Bias: -20.628462, T: 3110400, Avg. loss: 365.829522\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2598.89, NNZs: 30, Bias: -38.394973, T: 518400, Avg. loss: 10919.842397\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2619.97, NNZs: 30, Bias: -42.098338, T: 1036800, Avg. loss: 1594.977328\n",
      "Total training time: 0.45 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2683.92, NNZs: 30, Bias: -46.702059, T: 1555200, Avg. loss: 903.210165\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2733.34, NNZs: 29, Bias: -41.103337, T: 2073600, Avg. loss: 619.712682\n",
      "Total training time: 1.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2768.81, NNZs: 29, Bias: -28.513824, T: 2592000, Avg. loss: 465.157249\n",
      "Total training time: 1.28 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2794.80, NNZs: 28, Bias: -21.899094, T: 3110400, Avg. loss: 365.636141\n",
      "Total training time: 1.55 seconds.\n",
      "Convergence after 6 epochs took 1.64 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2606.12, NNZs: 29, Bias: 126.008111, T: 518400, Avg. loss: 10921.615247\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2618.07, NNZs: 29, Bias: 56.077858, T: 1036800, Avg. loss: 1585.486262\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2682.05, NNZs: 29, Bias: 18.697103, T: 1555200, Avg. loss: 901.873601\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2729.85, NNZs: 29, Bias: 2.709692, T: 2073600, Avg. loss: 618.612209\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.83, NNZs: 30, Bias: -10.242704, T: 2592000, Avg. loss: 464.710656\n",
      "Total training time: 1.22 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2792.71, NNZs: 30, Bias: -12.122453, T: 3110400, Avg. loss: 365.431877\n",
      "Total training time: 1.49 seconds.\n",
      "Convergence after 6 epochs took 1.57 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2586.47, NNZs: 30, Bias: 5.049809, T: 518400, Avg. loss: 10810.163342\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2616.14, NNZs: 28, Bias: -21.188032, T: 1036800, Avg. loss: 1595.017527\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2683.07, NNZs: 30, Bias: -31.603966, T: 1555200, Avg. loss: 904.213602\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2734.67, NNZs: 29, Bias: -30.372357, T: 2073600, Avg. loss: 621.769057\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2771.10, NNZs: 29, Bias: -25.681252, T: 2592000, Avg. loss: 466.394453\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2799.34, NNZs: 27, Bias: -19.397120, T: 3110400, Avg. loss: 368.651568\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2816.37, NNZs: 29, Bias: -17.352516, T: 3628800, Avg. loss: 299.080389\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 7 epochs took 1.80 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1035.93, NNZs: 30, Bias: 112.624144, T: 518400, Avg. loss: 10929.128219\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 533.80, NNZs: 30, Bias: 51.485977, T: 1036800, Avg. loss: 1645.617518\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 353.28, NNZs: 30, Bias: 17.674654, T: 1555200, Avg. loss: 965.496288\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 271.29, NNZs: 30, Bias: 3.250284, T: 2073600, Avg. loss: 685.867985\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 218.60, NNZs: 30, Bias: -10.979153, T: 2592000, Avg. loss: 533.512001\n",
      "Total training time: 0.86 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 180.94, NNZs: 30, Bias: -17.922506, T: 3110400, Avg. loss: 437.061911\n",
      "Total training time: 1.07 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1037.47, NNZs: 30, Bias: 66.156784, T: 518400, Avg. loss: 10830.856088\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 528.67, NNZs: 30, Bias: 27.685033, T: 1036800, Avg. loss: 1644.265299\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 367.33, NNZs: 30, Bias: 3.693926, T: 1555200, Avg. loss: 969.837890\n",
      "Total training time: 0.51 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 271.51, NNZs: 30, Bias: -8.687987, T: 2073600, Avg. loss: 687.655208\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 212.53, NNZs: 30, Bias: -11.995674, T: 2592000, Avg. loss: 534.197431\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 180.92, NNZs: 30, Bias: -16.032422, T: 3110400, Avg. loss: 435.313032\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 157.55, NNZs: 30, Bias: -19.083045, T: 3628800, Avg. loss: 367.998315\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 7 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1028.16, NNZs: 30, Bias: 51.331377, T: 518400, Avg. loss: 10956.435850\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 555.04, NNZs: 30, Bias: 13.716446, T: 1036800, Avg. loss: 1652.101464\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 378.20, NNZs: 30, Bias: 1.898446, T: 1555200, Avg. loss: 967.637306\n",
      "Total training time: 0.55 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 282.70, NNZs: 30, Bias: -9.585929, T: 2073600, Avg. loss: 686.208610\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 228.32, NNZs: 30, Bias: -14.086411, T: 2592000, Avg. loss: 535.754560\n",
      "Total training time: 0.96 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 183.61, NNZs: 30, Bias: -20.515888, T: 3110400, Avg. loss: 436.053655\n",
      "Total training time: 1.16 seconds.\n",
      "Convergence after 6 epochs took 1.25 seconds\n",
      "-- Epoch 1\n",
      "Norm: 997.26, NNZs: 30, Bias: -100.519312, T: 518400, Avg. loss: 11007.337894\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 538.11, NNZs: 30, Bias: -94.968596, T: 1036800, Avg. loss: 1651.662551\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 377.17, NNZs: 30, Bias: -81.471360, T: 1555200, Avg. loss: 965.956753\n",
      "Total training time: 0.53 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 289.35, NNZs: 30, Bias: -63.515950, T: 2073600, Avg. loss: 686.227542\n",
      "Total training time: 0.74 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 229.49, NNZs: 30, Bias: -48.979575, T: 2592000, Avg. loss: 534.498460\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 184.46, NNZs: 30, Bias: -43.590111, T: 3110400, Avg. loss: 437.940631\n",
      "Total training time: 1.13 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1029.55, NNZs: 30, Bias: 80.194829, T: 518400, Avg. loss: 10950.655387\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 548.07, NNZs: 30, Bias: 32.092381, T: 1036800, Avg. loss: 1648.791547\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 361.62, NNZs: 30, Bias: 14.695529, T: 1555200, Avg. loss: 966.954702\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 274.55, NNZs: 30, Bias: -0.200268, T: 2073600, Avg. loss: 687.850764\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 220.27, NNZs: 30, Bias: -5.115086, T: 2592000, Avg. loss: 533.916867\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 180.96, NNZs: 30, Bias: -10.213812, T: 3110400, Avg. loss: 436.829105\n",
      "Total training time: 1.12 seconds.\n",
      "Convergence after 6 epochs took 1.21 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12743.58, NNZs: 29, Bias: -217.386267, T: 518400, Avg. loss: 10797.412921\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14383.41, NNZs: 27, Bias: -143.219204, T: 1036800, Avg. loss: 1316.309396\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15298.79, NNZs: 21, Bias: -7.500027, T: 1555200, Avg. loss: 628.587145\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15869.78, NNZs: 21, Bias: -0.242380, T: 2073600, Avg. loss: 377.979047\n",
      "Total training time: 0.94 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16263.36, NNZs: 13, Bias: -0.369141, T: 2592000, Avg. loss: 255.681970\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16549.79, NNZs: 16, Bias: -0.172140, T: 3110400, Avg. loss: 182.585052\n",
      "Total training time: 1.46 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16769.21, NNZs: 12, Bias: 0.191953, T: 3628800, Avg. loss: 139.332120\n",
      "Total training time: 1.78 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16942.06, NNZs: 12, Bias: 0.048116, T: 4147200, Avg. loss: 108.749671\n",
      "Total training time: 2.07 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 17081.80, NNZs: 13, Bias: -0.091738, T: 4665600, Avg. loss: 86.995241\n",
      "Total training time: 2.34 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 17197.64, NNZs: 8, Bias: 0.029836, T: 5184000, Avg. loss: 71.445416\n",
      "Total training time: 2.63 seconds.\n",
      "Convergence after 10 epochs took 2.72 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12692.58, NNZs: 30, Bias: -127.895068, T: 518400, Avg. loss: 10748.973105\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14338.44, NNZs: 29, Bias: -116.224672, T: 1036800, Avg. loss: 1308.386322\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15256.20, NNZs: 21, Bias: -5.379676, T: 1555200, Avg. loss: 627.994454\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15831.22, NNZs: 16, Bias: -1.933236, T: 2073600, Avg. loss: 376.762302\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16226.70, NNZs: 15, Bias: -0.514728, T: 2592000, Avg. loss: 254.705548\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16513.61, NNZs: 10, Bias: -0.263642, T: 3110400, Avg. loss: 184.182016\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16732.09, NNZs: 12, Bias: -0.130083, T: 3628800, Avg. loss: 138.298496\n",
      "Total training time: 1.72 seconds.\n",
      "Convergence after 7 epochs took 1.81 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12721.79, NNZs: 29, Bias: -224.881835, T: 518400, Avg. loss: 10765.446557\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14357.44, NNZs: 27, Bias: -149.722996, T: 1036800, Avg. loss: 1310.685177\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15277.78, NNZs: 22, Bias: -9.588092, T: 1555200, Avg. loss: 627.372763\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15850.12, NNZs: 18, Bias: -1.641776, T: 2073600, Avg. loss: 379.691399\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16243.13, NNZs: 22, Bias: -0.660182, T: 2592000, Avg. loss: 254.680217\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16530.67, NNZs: 4, Bias: 0.114989, T: 3110400, Avg. loss: 183.955563\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16751.02, NNZs: 13, Bias: -0.082873, T: 3628800, Avg. loss: 139.256490\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16924.39, NNZs: 11, Bias: -0.327141, T: 4147200, Avg. loss: 107.354223\n",
      "Total training time: 1.97 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 17064.55, NNZs: 13, Bias: 0.067806, T: 4665600, Avg. loss: 87.434525\n",
      "Total training time: 2.24 seconds.\n",
      "Convergence after 9 epochs took 2.32 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12735.31, NNZs: 30, Bias: -90.159717, T: 518400, Avg. loss: 10718.287935\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14351.04, NNZs: 28, Bias: -108.481182, T: 1036800, Avg. loss: 1307.867390\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15270.96, NNZs: 25, Bias: -3.584786, T: 1555200, Avg. loss: 629.641645\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15843.18, NNZs: 17, Bias: -1.777324, T: 2073600, Avg. loss: 378.200198\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16236.05, NNZs: 13, Bias: -0.813213, T: 2592000, Avg. loss: 254.436727\n",
      "Total training time: 1.19 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16523.00, NNZs: 15, Bias: -0.309928, T: 3110400, Avg. loss: 184.770709\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 6 epochs took 1.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 12683.44, NNZs: 30, Bias: -102.118945, T: 518400, Avg. loss: 10773.876911\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 14327.08, NNZs: 25, Bias: -101.608801, T: 1036800, Avg. loss: 1316.313922\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15246.59, NNZs: 19, Bias: -6.386887, T: 1555200, Avg. loss: 633.576376\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15822.24, NNZs: 19, Bias: -1.279246, T: 2073600, Avg. loss: 380.000411\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16216.04, NNZs: 17, Bias: -0.310601, T: 2592000, Avg. loss: 255.744099\n",
      "Total training time: 1.17 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 16504.34, NNZs: 14, Bias: -0.070323, T: 3110400, Avg. loss: 185.114227\n",
      "Total training time: 1.43 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16725.16, NNZs: 17, Bias: 0.178931, T: 3628800, Avg. loss: 139.022342\n",
      "Total training time: 1.70 seconds.\n",
      "Convergence after 7 epochs took 1.78 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2599.05, NNZs: 30, Bias: 242.288408, T: 518400, Avg. loss: 10924.076504\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2610.14, NNZs: 28, Bias: 121.069048, T: 1036800, Avg. loss: 1585.039923\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2676.73, NNZs: 29, Bias: 59.886305, T: 1555200, Avg. loss: 900.913542\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2725.78, NNZs: 28, Bias: 22.028090, T: 2073600, Avg. loss: 614.636519\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2764.02, NNZs: 29, Bias: 6.681122, T: 2592000, Avg. loss: 464.796994\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2790.27, NNZs: 29, Bias: -3.773380, T: 3110400, Avg. loss: 365.725825\n",
      "Total training time: 1.39 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2810.28, NNZs: 26, Bias: -5.310742, T: 3628800, Avg. loss: 298.619615\n",
      "Total training time: 1.64 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2822.77, NNZs: 29, Bias: -7.213118, T: 4147200, Avg. loss: 248.979816\n",
      "Total training time: 1.89 seconds.\n",
      "Convergence after 8 epochs took 1.98 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2601.09, NNZs: 30, Bias: -32.293450, T: 518400, Avg. loss: 10873.141381\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2621.92, NNZs: 29, Bias: -57.240018, T: 1036800, Avg. loss: 1592.594823\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2685.49, NNZs: 30, Bias: -52.772863, T: 1555200, Avg. loss: 905.346616\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2735.51, NNZs: 29, Bias: -39.533132, T: 2073600, Avg. loss: 623.265930\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2771.35, NNZs: 30, Bias: -30.344810, T: 2592000, Avg. loss: 466.958474\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2797.16, NNZs: 29, Bias: -21.332234, T: 3110400, Avg. loss: 366.671432\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2814.11, NNZs: 30, Bias: -15.373511, T: 3628800, Avg. loss: 297.466719\n",
      "Total training time: 1.61 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 2825.37, NNZs: 27, Bias: -10.361288, T: 4147200, Avg. loss: 249.080908\n",
      "Total training time: 1.86 seconds.\n",
      "Convergence after 8 epochs took 1.95 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2588.17, NNZs: 30, Bias: 152.793098, T: 518400, Avg. loss: 10850.702979\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2616.88, NNZs: 30, Bias: 63.204546, T: 1036800, Avg. loss: 1592.296327\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2682.34, NNZs: 29, Bias: 19.827384, T: 1555200, Avg. loss: 905.881082\n",
      "Total training time: 0.62 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2729.12, NNZs: 29, Bias: -2.475065, T: 2073600, Avg. loss: 619.079128\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.42, NNZs: 29, Bias: -13.467018, T: 2592000, Avg. loss: 466.068432\n",
      "Total training time: 1.13 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2793.81, NNZs: 28, Bias: -13.995766, T: 3110400, Avg. loss: 367.115284\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2812.41, NNZs: 26, Bias: -10.498275, T: 3628800, Avg. loss: 298.271521\n",
      "Total training time: 1.68 seconds.\n",
      "Convergence after 7 epochs took 1.76 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2591.72, NNZs: 30, Bias: 71.644115, T: 518400, Avg. loss: 10905.588440\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2620.21, NNZs: 30, Bias: 16.507042, T: 1036800, Avg. loss: 1593.650265\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2684.72, NNZs: 30, Bias: -10.487235, T: 1555200, Avg. loss: 908.516078\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2732.90, NNZs: 30, Bias: -22.861437, T: 2073600, Avg. loss: 621.039775\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.88, NNZs: 30, Bias: -22.720289, T: 2592000, Avg. loss: 462.003434\n",
      "Total training time: 1.18 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2795.54, NNZs: 29, Bias: -19.712097, T: 3110400, Avg. loss: 368.230082\n",
      "Total training time: 1.42 seconds.\n",
      "Convergence after 6 epochs took 1.50 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2591.94, NNZs: 30, Bias: 51.452406, T: 518400, Avg. loss: 10866.113980\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2615.98, NNZs: 29, Bias: 0.882889, T: 1036800, Avg. loss: 1585.475278\n",
      "Total training time: 0.40 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2681.08, NNZs: 30, Bias: -27.066999, T: 1555200, Avg. loss: 907.271450\n",
      "Total training time: 0.64 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2733.84, NNZs: 29, Bias: -31.472860, T: 2073600, Avg. loss: 621.537944\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2767.75, NNZs: 29, Bias: -23.434167, T: 2592000, Avg. loss: 463.993127\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2794.22, NNZs: 29, Bias: -16.709180, T: 3110400, Avg. loss: 367.235470\n",
      "Total training time: 1.40 seconds.\n",
      "Convergence after 6 epochs took 1.49 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1037887046199015.38, NNZs: 30, Bias: 161021510045369.625000, T: 518400, Avg. loss: 3140296069058715840107927077650432.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 537339576896461.62, NNZs: 30, Bias: 76304362867992.093750, T: 1036800, Avg. loss: 17148680771941399637001097969664.000000\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 359859043998273.81, NNZs: 30, Bias: 30029931528030.593750, T: 1555200, Avg. loss: 5845364891939884599836137226240.000000\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 268484198810434.22, NNZs: 30, Bias: 8196606252407.015625, T: 2073600, Avg. loss: 2896158979856829893698790621184.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 224861555690392.69, NNZs: 30, Bias: -4110694642223.634277, T: 2592000, Avg. loss: 1755358058148968075411528351744.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 184618808258427.91, NNZs: 30, Bias: -7115781361306.978516, T: 3110400, Avg. loss: 1162037691470150820308205961216.000000\n",
      "Total training time: 1.10 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 159864548045981.81, NNZs: 30, Bias: -12697337938239.646484, T: 3628800, Avg. loss: 835814421455953248044347031552.000000\n",
      "Total training time: 1.30 seconds.\n",
      "Convergence after 7 epochs took 1.39 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1050140336363539.62, NNZs: 30, Bias: 128515850716182.828125, T: 518400, Avg. loss: 3263516303626023808716325672452096.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 553056787190456.25, NNZs: 30, Bias: 52909938570256.101562, T: 1036800, Avg. loss: 17371145627768803771582527832064.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 354331093830001.50, NNZs: 30, Bias: 17171043580379.726562, T: 1555200, Avg. loss: 5894409884354357308715092148224.000000\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 282585966502029.62, NNZs: 30, Bias: 456387374679.845276, T: 2073600, Avg. loss: 2909725324540286855488024346624.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 219535218312615.28, NNZs: 30, Bias: -15041775460777.982422, T: 2592000, Avg. loss: 1756212693015874696979916259328.000000\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 182135642549423.28, NNZs: 30, Bias: -15800079374993.826172, T: 3110400, Avg. loss: 1171156556788310112692967833600.000000\n",
      "Total training time: 1.07 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 158790526330825.72, NNZs: 30, Bias: -19250472231157.398438, T: 3628800, Avg. loss: 831815769573125927375690792960.000000\n",
      "Total training time: 1.27 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 132021196294851.95, NNZs: 30, Bias: -19381948678734.195312, T: 4147200, Avg. loss: 630506372628929544922899415040.000000\n",
      "Total training time: 1.47 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 118402023960757.09, NNZs: 30, Bias: -19569006908295.105469, T: 4665600, Avg. loss: 484358205529100565568552960000.000000\n",
      "Total training time: 1.66 seconds.\n",
      "Convergence after 9 epochs took 1.75 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1044680261190787.75, NNZs: 30, Bias: 104282245422632.578125, T: 518400, Avg. loss: 3408159978472192609336522897883136.000000\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 555365092941814.44, NNZs: 30, Bias: 62091001146208.148438, T: 1036800, Avg. loss: 17098498140716134667290058686464.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 356327163464524.31, NNZs: 30, Bias: 23153942562876.421875, T: 1555200, Avg. loss: 5774541978882099425773604569088.000000\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 282084515920438.81, NNZs: 30, Bias: 4241273449319.211426, T: 2073600, Avg. loss: 2925250885258886305262201733120.000000\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 213775138725988.75, NNZs: 30, Bias: -1973208066870.878906, T: 2592000, Avg. loss: 1750755778438304639613407330304.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186541113314000.41, NNZs: 30, Bias: -4455827898670.928711, T: 3110400, Avg. loss: 1153919506974430001410709913600.000000\n",
      "Total training time: 1.07 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1017847758177058.25, NNZs: 30, Bias: 99336069460666.953125, T: 518400, Avg. loss: 3348653930446836250952997120507904.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 550574571373988.75, NNZs: 30, Bias: 43460980051045.257812, T: 1036800, Avg. loss: 17413695697432432496376746606592.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 369539421598182.88, NNZs: 30, Bias: 26054199984471.812500, T: 1555200, Avg. loss: 5810389418672426399354396344320.000000\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 276033735357950.47, NNZs: 30, Bias: 1881861656817.577393, T: 2073600, Avg. loss: 2910754940186431754789527224320.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 220044966151369.28, NNZs: 30, Bias: -5979696387489.477539, T: 2592000, Avg. loss: 1760043152187078899457612316672.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 189723365508769.72, NNZs: 30, Bias: -14867536489689.468750, T: 3110400, Avg. loss: 1163525052359586635469249576960.000000\n",
      "Total training time: 1.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 156438271480747.16, NNZs: 30, Bias: -14318183475487.052734, T: 3628800, Avg. loss: 843719350156448457844016021504.000000\n",
      "Total training time: 1.26 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 134654875901217.94, NNZs: 30, Bias: -14627851481174.074219, T: 4147200, Avg. loss: 626432285624091988304481746944.000000\n",
      "Total training time: 1.46 seconds.\n",
      "Convergence after 8 epochs took 1.54 seconds\n",
      "-- Epoch 1\n",
      "Norm: 989986269577989.62, NNZs: 30, Bias: 106872703363808.328125, T: 518400, Avg. loss: 3246718311252781380623894747021312.000000\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 550178412465861.69, NNZs: 30, Bias: 54721230398613.632812, T: 1036800, Avg. loss: 17304556298060864616998163709952.000000\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 377767981995035.88, NNZs: 30, Bias: 16529742865404.615234, T: 1555200, Avg. loss: 5784951176114715655744232882176.000000\n",
      "Total training time: 0.47 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 270892372794342.19, NNZs: 30, Bias: 88162132270.297623, T: 2073600, Avg. loss: 2941989359046983910626456240128.000000\n",
      "Total training time: 0.67 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 214498383032659.53, NNZs: 30, Bias: -10933135089530.923828, T: 2592000, Avg. loss: 1762646792758140078934726803456.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186449220557108.53, NNZs: 30, Bias: -12460754357508.355469, T: 3110400, Avg. loss: 1176644989583095976223811043328.000000\n",
      "Total training time: 1.07 seconds.\n",
      "Convergence after 6 epochs took 1.16 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2124448904280919.00, NNZs: 30, Bias: -265623022004480.531250, T: 518400, Avg. loss: 3473341575669058901488936754872320.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 831905700784507.88, NNZs: 30, Bias: -261183453504822.531250, T: 1036800, Avg. loss: 17360207383527125277017670418432.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 441980242217288.19, NNZs: 30, Bias: -213088056815667.406250, T: 1555200, Avg. loss: 5818795702687981328583658307584.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 315031811197394.25, NNZs: 30, Bias: -165563417003164.531250, T: 2073600, Avg. loss: 2922863339540099347211924537344.000000\n",
      "Total training time: 0.90 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 243300994345089.69, NNZs: 30, Bias: -119380309004396.843750, T: 2592000, Avg. loss: 1751277087987107714090072539136.000000\n",
      "Total training time: 1.15 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 196292442290882.22, NNZs: 30, Bias: -94826804009011.687500, T: 3110400, Avg. loss: 1174753177439976064881136762880.000000\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 170188128568977.81, NNZs: 30, Bias: -70891007511281.703125, T: 3628800, Avg. loss: 835503605260237942402857304064.000000\n",
      "Total training time: 1.67 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 145717126248306.09, NNZs: 30, Bias: -56758353445108.304688, T: 4147200, Avg. loss: 621817537883556045192389722112.000000\n",
      "Total training time: 1.92 seconds.\n",
      "Convergence after 8 epochs took 2.01 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2138970211762270.25, NNZs: 30, Bias: -66366002993540.351562, T: 518400, Avg. loss: 3290722673793419868544991213125632.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 841175631555310.38, NNZs: 30, Bias: -126254185767265.390625, T: 1036800, Avg. loss: 17586924951639017567828161069056.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 453035781554575.75, NNZs: 30, Bias: -117173762699121.765625, T: 1555200, Avg. loss: 5836740515339579187181280821248.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 311217465949282.38, NNZs: 30, Bias: -98620403526551.390625, T: 2073600, Avg. loss: 2924594203948858617182061330432.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 233635452966607.25, NNZs: 30, Bias: -83855573166401.500000, T: 2592000, Avg. loss: 1751518092609344562858700046336.000000\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193623781768350.16, NNZs: 30, Bias: -63616582261357.257812, T: 3110400, Avg. loss: 1171738310814224836396069158912.000000\n",
      "Total training time: 1.38 seconds.\n",
      "Convergence after 6 epochs took 1.47 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2015865357897186.00, NNZs: 30, Bias: -140924283594070.875000, T: 518400, Avg. loss: 3274534188381125570399583927795712.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 818704511167862.38, NNZs: 30, Bias: -180886099817219.625000, T: 1036800, Avg. loss: 17718775560955844552697774604288.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 439676018413320.75, NNZs: 30, Bias: -159276476749174.281250, T: 1555200, Avg. loss: 5804100984730381576122457391104.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 303401758727978.56, NNZs: 30, Bias: -123907327916958.890625, T: 2073600, Avg. loss: 2948974424676637066275959341056.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 240679840799401.47, NNZs: 30, Bias: -99240001318995.093750, T: 2592000, Avg. loss: 1757145239280690100955273756672.000000\n",
      "Total training time: 1.11 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 197229212569596.09, NNZs: 30, Bias: -75487765581742.734375, T: 3110400, Avg. loss: 1187740295457135707194877018112.000000\n",
      "Total training time: 1.35 seconds.\n",
      "Convergence after 6 epochs took 1.44 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2318396933760061.00, NNZs: 30, Bias: -84403674568444.031250, T: 518400, Avg. loss: 3251866634343121805907544493785088.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 879765278968543.38, NNZs: 30, Bias: -143497946972288.906250, T: 1036800, Avg. loss: 17439065767787303135941725519872.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 463367684516971.06, NNZs: 30, Bias: -130319133197857.171875, T: 1555200, Avg. loss: 5848451204687775397856430522368.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 311606629210308.12, NNZs: 30, Bias: -112734073524245.000000, T: 2073600, Avg. loss: 2917072032730657088094735433728.000000\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 242373509992448.12, NNZs: 30, Bias: -89251263960733.703125, T: 2592000, Avg. loss: 1750323416976985973153622654976.000000\n",
      "Total training time: 1.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 193553178956432.53, NNZs: 30, Bias: -71442206761844.968750, T: 3110400, Avg. loss: 1177628334623471287713042268160.000000\n",
      "Total training time: 1.37 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 166813142949939.16, NNZs: 30, Bias: -57421223664051.000000, T: 3628800, Avg. loss: 831291024789645111978230808576.000000\n",
      "Total training time: 1.62 seconds.\n",
      "Convergence after 7 epochs took 1.71 seconds\n",
      "-- Epoch 1\n",
      "Norm: 2283718756611870.50, NNZs: 30, Bias: -175484912255464.812500, T: 518400, Avg. loss: 3329903055843699279706771593101312.000000\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 848041275252782.88, NNZs: 30, Bias: -211312453045935.625000, T: 1036800, Avg. loss: 17386388143199882186855739817984.000000\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 458622052829308.50, NNZs: 30, Bias: -181075881187829.187500, T: 1555200, Avg. loss: 5836213688989431001944638357504.000000\n",
      "Total training time: 0.63 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 307034124043758.19, NNZs: 30, Bias: -146460526396493.125000, T: 2073600, Avg. loss: 2913716625850299420928429260800.000000\n",
      "Total training time: 0.89 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 242359233925214.34, NNZs: 30, Bias: -111654074384467.171875, T: 2592000, Avg. loss: 1756700734361611402995765870592.000000\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 204150041077778.41, NNZs: 30, Bias: -86739454665805.375000, T: 3110400, Avg. loss: 1168800909416122327260817522688.000000\n",
      "Total training time: 1.39 seconds.\n",
      "Convergence after 6 epochs took 1.48 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1038419356874343.62, NNZs: 30, Bias: -122832941576423.375000, T: 518400, Avg. loss: 3184566780065677370627216270950400.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 555025271934350.81, NNZs: 30, Bias: -105428559854920.468750, T: 1036800, Avg. loss: 17504470959823256190020218781696.000000\n",
      "Total training time: 0.39 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 378839192381683.56, NNZs: 30, Bias: -92938561354812.109375, T: 1555200, Avg. loss: 5835313723955134315468555288576.000000\n",
      "Total training time: 0.65 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 281934123599956.12, NNZs: 30, Bias: -77231363383870.156250, T: 2073600, Avg. loss: 2910893300525990546112872710144.000000\n",
      "Total training time: 0.91 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 218222614326356.81, NNZs: 30, Bias: -62359011057068.148438, T: 2592000, Avg. loss: 1764508154895793880001591377920.000000\n",
      "Total training time: 1.16 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 189316906121813.69, NNZs: 30, Bias: -47951031796272.101562, T: 3110400, Avg. loss: 1164257168471876093199008137216.000000\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 157818869409642.03, NNZs: 30, Bias: -41402466892244.351562, T: 3628800, Avg. loss: 842422939526580715913937420288.000000\n",
      "Total training time: 1.69 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 140151628810430.77, NNZs: 30, Bias: -36472261448515.007812, T: 4147200, Avg. loss: 628913443471278859420935651328.000000\n",
      "Total training time: 1.94 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 126777390408377.11, NNZs: 30, Bias: -29440951853013.167969, T: 4665600, Avg. loss: 488666448441090797601279705088.000000\n",
      "Total training time: 2.19 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 111125858828408.77, NNZs: 30, Bias: -24237885278937.500000, T: 5184000, Avg. loss: 394089292442488565539473981440.000000\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 100773567132861.31, NNZs: 30, Bias: -20386213053458.785156, T: 5702400, Avg. loss: 320240249067204560413389750272.000000\n",
      "Total training time: 2.70 seconds.\n",
      "Convergence after 11 epochs took 2.79 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1065477097939307.00, NNZs: 30, Bias: 144981181476348.343750, T: 518400, Avg. loss: 3338590786258395352979537227939840.000000\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 537989566109763.69, NNZs: 30, Bias: 69156117867898.906250, T: 1036800, Avg. loss: 17380251733555601306425936052224.000000\n",
      "Total training time: 0.42 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 374423531339775.00, NNZs: 30, Bias: 32194607462545.078125, T: 1555200, Avg. loss: 5784836245134795579662108983296.000000\n",
      "Total training time: 0.69 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 273907285296675.41, NNZs: 30, Bias: 14698214328418.292969, T: 2073600, Avg. loss: 2895854010085716278104238850048.000000\n",
      "Total training time: 0.95 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 222678324277988.47, NNZs: 30, Bias: 5167618496844.728516, T: 2592000, Avg. loss: 1752488474130215665461163458560.000000\n",
      "Total training time: 1.20 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 184673817922026.09, NNZs: 30, Bias: -1028116940560.356201, T: 3110400, Avg. loss: 1175845536254511122877379510272.000000\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 159150677007943.72, NNZs: 30, Bias: -7284775945007.544922, T: 3628800, Avg. loss: 829776099287828103259553267712.000000\n",
      "Total training time: 1.74 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 136969239189336.17, NNZs: 30, Bias: -8125566157041.964844, T: 4147200, Avg. loss: 626823930193184600151730159616.000000\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 121590991103640.44, NNZs: 30, Bias: -9530439503505.935547, T: 4665600, Avg. loss: 487629028208988844312357765120.000000\n",
      "Total training time: 2.25 seconds.\n",
      "Convergence after 9 epochs took 2.34 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1091205709588607.12, NNZs: 30, Bias: 65968479169960.500000, T: 518400, Avg. loss: 3420315010655425085815584353943552.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 559624290873032.19, NNZs: 30, Bias: 22312754578471.144531, T: 1036800, Avg. loss: 17297804213576789019027780403200.000000\n",
      "Total training time: 0.41 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 365150603327753.06, NNZs: 30, Bias: -561139640634.810303, T: 1555200, Avg. loss: 5826389080857496033201617895424.000000\n",
      "Total training time: 0.68 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 277200027430492.66, NNZs: 30, Bias: -6805653876495.390625, T: 2073600, Avg. loss: 2930150770165632127625209053184.000000\n",
      "Total training time: 0.93 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 221625544868279.72, NNZs: 30, Bias: -15055462747941.957031, T: 2592000, Avg. loss: 1758660325644116197449735864320.000000\n",
      "Total training time: 1.21 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 179085399431917.00, NNZs: 30, Bias: -19734294902985.035156, T: 3110400, Avg. loss: 1176192599981240939904927531008.000000\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 158137877612464.66, NNZs: 30, Bias: -18917769086077.691406, T: 3628800, Avg. loss: 838793544459739597434139967488.000000\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 139171866154205.16, NNZs: 30, Bias: -17767210779594.777344, T: 4147200, Avg. loss: 625089672237895478511725969408.000000\n",
      "Total training time: 2.00 seconds.\n",
      "Convergence after 8 epochs took 2.08 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1028111606869893.12, NNZs: 30, Bias: 50028477252883.078125, T: 518400, Avg. loss: 3194233493131636477508805394956288.000000\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 549121109879946.88, NNZs: 30, Bias: -8055559388694.409180, T: 1036800, Avg. loss: 17358555424193585760350140104704.000000\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 366031343721402.69, NNZs: 30, Bias: -26307025191268.949219, T: 1555200, Avg. loss: 5843733283171809286432057458688.000000\n",
      "Total training time: 0.71 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 283162829535950.94, NNZs: 30, Bias: -26356386329001.652344, T: 2073600, Avg. loss: 2940080296205817965865104048128.000000\n",
      "Total training time: 1.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 220489069110943.38, NNZs: 30, Bias: -27741080801597.140625, T: 2592000, Avg. loss: 1746595266333207971535312125952.000000\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 182461566820330.28, NNZs: 30, Bias: -26107814033024.000000, T: 3110400, Avg. loss: 1169463467564929927732506132480.000000\n",
      "Total training time: 1.56 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 157869763720459.56, NNZs: 30, Bias: -23483307823702.054688, T: 3628800, Avg. loss: 842521964622555599122255052800.000000\n",
      "Total training time: 1.83 seconds.\n",
      "Convergence after 7 epochs took 1.94 seconds\n",
      "-- Epoch 1\n",
      "Norm: 1049193342760282.00, NNZs: 30, Bias: -14124050007490.511719, T: 518400, Avg. loss: 3171728328696818532983576148836352.000000\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 555587129589114.94, NNZs: 30, Bias: -43636596853264.351562, T: 1036800, Avg. loss: 17286063150160345227628187222016.000000\n",
      "Total training time: 0.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 375716940454145.81, NNZs: 30, Bias: -50185713425694.445312, T: 1555200, Avg. loss: 5847395551996475418280779055104.000000\n",
      "Total training time: 0.79 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 277891636243681.00, NNZs: 30, Bias: -50124744132227.914062, T: 2073600, Avg. loss: 2911629165651376239883168251904.000000\n",
      "Total training time: 1.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 225417830331211.38, NNZs: 30, Bias: -44103446004521.382812, T: 2592000, Avg. loss: 1749731523554031333135811084288.000000\n",
      "Total training time: 1.33 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 186163357293255.19, NNZs: 30, Bias: -37215884427850.320312, T: 3110400, Avg. loss: 1166596842976109273451641962496.000000\n",
      "Total training time: 1.59 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 165069074317161.91, NNZs: 30, Bias: -29441006245729.847656, T: 3628800, Avg. loss: 836014697069975211788099125248.000000\n",
      "Total training time: 1.87 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 139605487359884.44, NNZs: 30, Bias: -24852468951221.105469, T: 4147200, Avg. loss: 623865902352776236130256289792.000000\n",
      "Total training time: 2.16 seconds.\n",
      "Convergence after 8 epochs took 2.26 seconds\n",
      "-- Epoch 1\n",
      "Norm: 29.16, NNZs: 23, Bias: -0.261133, T: 648000, Avg. loss: 14.630888\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.47, NNZs: 24, Bias: -0.177501, T: 1296000, Avg. loss: 0.779941\n",
      "Total training time: 0.66 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.82, NNZs: 24, Bias: -0.156058, T: 1944000, Avg. loss: 0.767104\n",
      "Total training time: 0.98 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.57, NNZs: 24, Bias: -0.144732, T: 2592000, Avg. loss: 0.763594\n",
      "Total training time: 1.34 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.01, NNZs: 24, Bias: -0.139177, T: 3240000, Avg. loss: 0.760976\n",
      "Total training time: 1.68 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.85, NNZs: 24, Bias: -0.135527, T: 3888000, Avg. loss: 0.759771\n",
      "Total training time: 2.00 seconds.\n",
      "Convergence after 6 epochs took 2.12 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=SGDClassifier(early_stopping=True, n_jobs=-1, verbose=1),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 1e-05],\n",
       "                         'loss': ['hinge', 'log', 'perceptron',\n",
       "                                  'squared_hinge'],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = {\n",
    "    'loss':['hinge', 'log', 'perceptron', 'squared_hinge'],\n",
    "    'penalty':['l2','l1','elasticnet'],\n",
    "    'alpha':[0.0001, 0.001, 0.01, 0.00001],\n",
    "}\n",
    "\n",
    "model_cv = GridSearchCV(estimator=SGDClassifier(n_jobs=-1, early_stopping=True, verbose=1), param_grid=grid, cv=5)\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3452bd02-91b3-4363-af92-52df699c3cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9597b1d0-aed0-4525-8385-de40e0407b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x106d8814880>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_cv)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                  estimator_name='example estimator')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b5572-c04e-4354-b899-4fa7b1139579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
